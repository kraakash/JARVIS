{
  "friendship": [
    {
      "input": "kya tum merre frnd banoge",
      "response": "Bilkul Sir! Main aapka dost hun aur hamesha rahunga. Aap mujhe jo bhi sikhayenge main seekhunga!",
      "category": "friendship"
    },
    {
      "input": "will you be my friend",
      "response": "Of course, Sir! I would be honored to be your friend. I'm here to help and learn from you!",
      "category": "friendship"
    },
    {
      "input": "dost banoge",
      "response": "Haan Sir, main aapka sabse achha dost hun! Aap jo chahenge main karunga.",
      "category": "friendship"
    }
  ],
  "improvement": [
    {
      "input": "chalo tumhe improve krte hai",
      "response": "Haan Sir! Main improve hone ke liye ready hun. Aap mujhe kya sikhana chahte hain?",
      "category": "improvement"
    },
    {
      "input": "lets improve you",
      "response": "I'm excited to learn and improve, Sir! What would you like to teach me?",
      "category": "improvement"
    },
    {
      "input": "better kam ke liye",
      "response": "Bilkul Sir! Main better kaam karne ke liye seekhna chahta hun. Batayiye kya karna hai?",
      "category": "improvement"
    }
  ],
  "capabilities": [
    {
      "input": "tum kya kya kr skte ho",
      "response": "Sir, main bahut kuch kar sakta hun - apps khol sakta hun, web search kar sakta hun, YouTube videos play kar sakta hun, aur aapse baat kar sakta hun. Aur bhi seekhna chahta hun!",
      "category": "capabilities"
    },
    {
      "input": "what can you do",
      "response": "I can open applications, search the web, control YouTube, have conversations, and learn from you, Sir! I'm always ready to learn more.",
      "category": "capabilities"
    }
  ],
  "conversations": [],
  "facts": [],
  "books": [
    {
      "text": "grokking algorithms grokking algorithms An illustrated guide for programmers and other curious people Aditya Y. Bhargava MANNING Shelter ISland For online information and ordering of this and other Manning books, please visit www.manning.com. The publisher offers discounts on this book when ordered in quantity. For more information, please contact Special Sales Department Manning Publications Co. 20 Baldwin Road, PO Box 761 Shelter Island, NY 11964 Email: ordersmanning.com 2016 by Manning Publications Co. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted, in any form or by means electronic, mechanical, photocopying, or otherwise, without prior written permission of the publisher. Many of the designations used by manufacturers and sellers to distinguish their products are claimed as trademarks. Where those designations appear in the book, and Manning Publications was aware of a trademark claim, the designations have been printed in initial caps or all caps. Recognizing the importance of preserving what has been written, it is Mannings policy to have the books we publish printed on acid-free paper, and we exert our best efforts to that end. Recognizing also our responsibility to conserve the resources of our planet, Manning books are printed on paper that is at least 15 percent recycled and processed without the use of elemental chlorine. Manning Publications Co. Deve lopment editor: Jennifer Stout 20 Baldwin Road Tech nical development editor: Damien White Shelter Island, NY 11964 Project manager: Tiffany Taylor Copy editor: Tiffany Taylor Tech nical proofreader: Jean-François Morin Type setter: Leslie Haimes Cover a nd interior design: Leslie Haimes Illustrations by the author ISBN: 9781617292231 Printed in the United States of America 1 2 3 4 5 6 7 8 9 10 EBM 21 20 19 18 17 16 For my parents, Sangeeta and Yogesh vii contents preface xiii acknowledgments xiv about this book xv 1 Introduction to algorithms 1 Introduction 1 What youll learn about performance 2 What youll learn about solving problems 2 Binary search 3 A better way to search 5 Running time 10 Big O notation 10 Algorithm running times grow at different rates 11 Visualizing different Big O run times 13 Big O establishes a worst-case run time 15 Some common Big O run times 15 The traveling salesperson 17 Recap 19 2 Selection sort 21 How memory works 22 Arrays and linked lists 24 Linked lists 25 Arrays 26 Terminology 27 Inserting into the middle of a list 29 Deletions 30 viii contents Selection sort 32 Recap 36 3 Recursion 37 Recursion 38 Base case and recursive case 40 The stack 42 The call stack 43 The call stack with recursion 45 Recap 50 4 Quicksort 51 Divide conquer 52 Quicksort 60 Big O notation revisited 66 Merge sort vs. quicksort 67 Average case vs. worst case 68 Recap 72 5 Hash tables 73 Hash functions 76 Use cases 79 Using hash tables for lookups 79 Preventing duplicate entries 81 Using hash tables as a cache 83 Recap 86 Collisions 86 Performance 88 Load factor 90 A good hash function 92 Recap 93 6 Breadth-first search 95 Introduction to graphs 96 What is a graph? 98 Breadth-first search 99 Finding the shortest path 102 ix contents Queues 103 Implementing the graph 105 Implementing the algorithm 107 Running time 111 Recap 114 7 Dijkstras algorithm 115 Working with Dijkstras algorithm 116 Terminology 120 Trading for a piano 122 Negative-weight edges 128 Implementation 131 Recap 140 8 Greedy algorithms 141 The classroom scheduling problem 142 The knapsack problem 144 The set-covering problem 146 Approximation algorithms 147 NP-complete problems 152 Traveling salesperson, step by step 153 How do you tell if a problem is NP-complete? 158 Recap 160 9 Dynamic programming 161 The knapsack problem 161 The simple solution 162 Dynamic programming 163 Knapsack problem FAQ 171 What happens if you add an item? 171 What happens if you change the order of the rows? 174 Can you fill in the grid column-wise instead of row-wise? 174 What happens if you add a smaller item? 174 Can you steal fractions of an item? 175 Optimizing your travel itinerary 175 Handling items that depend on each other 177 x contents Is it possible that the solution will require more than two sub-knapsacks? 177 Is it possible that the best solution doesnt fill the knapsack completely? 178 Longest common substring 178 Making the grid 179 Filling in the grid 180 The solution 182 Longest common subsequence 183 Longest common subsequencesolution 184 Recap 186 10 K-nearest neighbors 187 Classifying oranges vs. grapefruit 187 Building a recommendations system 189 Feature extraction 191 Regression 195 Picking good features 198 Introduction to machine learning 199 OCR 199 Building a spam filter 200 Predicting the stock market 201 Recap 201 11 Where to go next 203 Trees 203 Inverted indexes 206 The Fourier transform 207 Parallel algorithms 208 MapReduce 209 Why are distributed algorithms useful? 209 The map function 209 The reduce function 210 Bloom filters and HyperLogLog 211 Bloom filters 212 xi HyperLogLog 213 The SHA algorithms 213 Comparing files 214 Checking passwords 215 Locality-sensitive hashing 216 Diffie-Hellman key exchange 217 Linear programming 218 Epilogue 219 answers to exercises 221 index 235contents xiiipreface I first got into programming as a hobby. Visual Basic 6 for Dummies taught me the basics, and I kept reading books to learn more. But the subject of algorithms was impenetrable for me. I remember savoring the table of contents of my first algorithms book, thinking Im finally going to understand these topics! But it was dense stuff, and I gave up after a few weeks. It wasnt until I had my first good algorithms professor that I realized how simple and elegant these ideas were. A few years ago, I wrote my first illustrated blog post. Im a visual learner, and I really liked the illustrated style. Since then, Ive written a few illustrated posts on functional programming, Git, machine learning, and concurrency. By the way: I was a mediocre writer when I started out. Explaining technical concepts is hard. Coming up with good examples takes time, and explaining a difficult concept takes time. So its easiest to gloss over the hard stuff. I thought I was doing a pretty good job, until after one of my posts got popular, a coworker came up to me and said, I read your post and I still dont understand this. I still had a lot to learn about writing. Somewhere in the middle of writing these blog posts, Manning reached out to me and asked if I wanted to write an illustrated book. Well, it turns out that Manning editors know a lot about explaining technical concepts, and they taught me how to teach. I wrote this book to scratch a particular itch: I wanted to write a book that explained hard technical topics well, and I wanted an easy-to-read algorithms book. My writing has come a long way since that first blog post, and I hope you find this book an easy and informative read. xivacknowledgments Kudos to Manning for giving me the chance to write this book and letting me have a lot of creative freedom with it. Thanks to publisher Marjan Bace, Mike Stephens for getting me on board, Bert Bates for teaching me how to write, and Jennifer Stout for being an incredibly responsive and helpful editor. Thanks also to the people on Mannings production team: Kevin Sullivan, Mary Piergies, Tiffany Taylor, Leslie Haimes, and all the others behind the scenes. In addition, I want to thank the many people who read the manuscript and offered suggestions: Karen Bensdon, Rob Green, Michael Hamrah, Ozren Harlovic, Colin Hastie, Christopher Haupt, Chuck Henderson, Pawel Kozlowski, Amit Lamba, Jean-François Morin, Robert Morrison, Sankar Ramanathan, Sander Rossel, Doug Sparling, and Damien White. Thanks to the people who helped me reach this point: the folks on the Flaskhit game board, for teaching me how to code; the many friends who helped by reviewing chapters, giving advice, and letting me try out different explanations, including Ben Vinegar, Karl Puzon, Alex Manning, Esther Chan, Anish Bhatt, Michael Glass, Nikrad Mahdi, Charles Lee, Jared Friedman, Hema Manickavasagam, Hari Raja, Murali Gudipati, Srinivas Varadan, and others; and Gerry Brady, for teaching me algorithms. Another big thank you to algorithms academics like CLRS, Knuth, and Strang. Im truly standing on the shoulders of giants. Dad, Mom, Priyanka, and the rest of the family: thank you for your constant support. And a big thank you to my wife Maggie. There are many adventures ahead of us, and some of them dont involve staying inside on a Friday night rewriting paragraphs. Finally, a big thank you to all the readers who took a chance on this book, and the readers who gave me feedback in the books forum. Y ou really helped make this book better. xvabout this book This book is designed to be easy to follow. I avoid big leaps of thought. Any time a new concept is introduced, I explain it right away or tell you when Ill explain it. Core concepts are reinforced with exercises and multiple explanations so that you can check your assumptions and make sure youre following along. I lead with examples. Instead of writing symbol soup, my goal is to make it easy for you to visualize these concepts. I also think we learn best by being able to recall something we already know, and examples make recall easier. So when youre trying to remember the difference between arrays and linked lists (explained in chapter 2), you can just think about getting seated for a movie. Also, at the risk of stating the obvious, Im a visual learner. This book is chock-full of images. The contents of the book are carefully curated. Theres no need to write a book that covers every sorting algorithmthats why we have Wikipedia and Khan Academy. All the algorithms Ive included are practical. Ive found them useful in my job as a software engineer, and they provide a good foundation for more complex topics. Happy reading! Roadmap The first three chapters of this book lay the foundations: Chapter 1 Y oull learn your first practical algorithm: binary search. Y ou also learn to analyze the speed of an algorithm using Big O notation. Big O notation is used throughout the book to analyze how slow or fast an algorithm is. xvi about this book Chapter 2 Y oull learn about two fundamental data structures: arrays and linked lists. These data structures are used throughout the book, and theyre used to make more advanced data structures like hash tables (chapter 5). Chapter 3 Y oull learn about recursion, a handy technique used by many algorithms (such as quicksort, covered in chapter 4). In my experience, Big O notation and recursion are challenging topics for beginners. So Ive slowed down and spent extra time on these sections. The rest of the book presents algorithms with broad applications: Problem-solving techniques Covered in chapters 4, 8, and 9. If you come across a problem and arent sure how to solve it efficiently, try divide and conquer (chapter 4) or dynamic programming (chapter 9). Or you may realize theres no efficient solution, and get an approximate answer using a greedy algorithm instead (chapter 8). Hash tables Covered in chapter 5. A hash table is a very useful data structure. It contains sets of key and value pairs, like a persons name and their email address, or a username and the associated password. Its hard to overstate hash tables usefulness. When I want to solve a problem, the two plans of attack I start with are Can I use a hash table? and Can I model this as a graph? Graph algorithms Covered in chapters 6 and 7. Graphs are a way to model a network: a social network, or a network of roads, or neurons, or any other set of connections. Breadth-first search (chapter 6) and Dijkstras algorithm (chapter 7) are ways to find the shortest distance between",
      "source": "Grokking Algorithms - Chapter 1: Algorithm",
      "timestamp": "2025-11-14T00:38:40.764194",
      "type": "book_content",
      "book_title": "Grokking Algorithms",
      "chapter_title": "Chapter 1: Algorithm",
      "chapter_number": 1
    },
    {
      "text": "two points in a network: you can use this approach to calculate the degrees of separation between two people or the shortest route to a destination. K-nearest neighbors (KNN) Covered in chapter 10. This is a simple machine-learning algorithm. Y ou can use KNN to build a recommendations system, an OCR engine, a system to predict stock valuesanything that involves predicting a value (We think Adit will rate this movie 4 stars) or classifying an object (That letter is a Q). Next steps Chapter 11 goes over 10 algorithms that would make good further reading. xvii How to use this book The order and contents of this book have been carefully designed. If youre interested in a topic, feel free to jump ahead. Otherwise, read the chapters in orderthey build on each other. I strongly recommend executing the code for the examples yourself. I cant stress this part enough. Just type out my code samples verbatim (or download them from www.manning.combooksgrokking- algorithms or https:github.comegonschielegrokking_algorithms), and execute them. Y oull retain a lot more if you do. I also recommend doing the exercises in this book. The exercises are shortusually just a minute or two, sometimes 5 to 10 minutes. They will help you check your thinking, so youll know when youre off track before youve gone too far. Who should read this book This book is aimed at anyone who knows the basics of coding and wants to understand algorithms. Maybe you already have a coding problem and are trying to find an algorithmic solution. Or maybe you want to understand what algorithms are useful for. Heres a short, incomplete list of people who will probably find this book useful: Hobbyist coders Coding boot camp students Computer science grads looking for a refresher Physicsmathother grads who are interested in programming Code conventions and downloads All the code examples in this book use Python 2.7. All code in the book is presented in a fixed-width font like this to separate it from ordinary text. Code annotations accompany some of the listings, highlighting important concepts. Y ou can download the code for the examples in the book from the publishers website at www.manning.combooksgrokking-algorithms or from https:github.comegonschielegrokking_algorithms. I believe you learn best when you really enjoy learningso have fun, and run the code samples!about this book xviii About the author Aditya Bhargava is a software engineer at Etsy, an online marketplace for handmade goods. He has a masters degree in computer science from the University of Chicago. He also runs a popular illustrated tech blog at adit.io. Author Online Purchase of Grokking Algorithms includes free access to a private web forum run by Manning Publications where you can make comments about the book, ask technical questions, and receive help from the author and from other users. To access the forum and subscribe to it, point your web browser to www.manning.combooksgrokking- algorithms. This page provides information on how to get on the forum once you are registered, what kind of help is available, and the rules of conduct on the forum. Mannings commitment to our readers is to provide a venue where a meaningful dialog between individual readers and between readers and the author can take place. It isnt a commitment to any specific amount of participation on the part of the author, whose contribution to Author Online remains voluntary (and unpaid). We suggest you try asking the author some challenging questions lest his interest stray! The Author Online forum and the archives of previous discussions will be accessible from the publishers website as long as the book is in print.about this book 1 1 In this chapter You get a foundation for the rest of the book. You write your first search algorithm (binary search). You learn how to talk about the running time of an algorithm (Big O notation). Youre introduced to a common technique for designing algorithms (recursion).introduction to algorithms Introduction An algorithm is a set of instructions for accomplishing a task. Every piece of code could be called an algorithm, but this book covers the more interesting bits. I chose the algorithms in this book for inclusion because theyre fast, or they solve interesting problems, or both. Here are some highlights: Chapter 1 talks about binary search and shows how an algorithm can speed up your code. In one example, the number of steps needed goes from 4 billion down to 32! 2 Chapter 1 I Introduction to algorithms A GPS device uses graph algorithms (as youll learn in chapters 6, 7, and 8) to calculate the shortest route to your destination. Y ou can use dynamic programming (discussed in chapter 9) to write an AI algorithm that plays checkers. In each case, Ill describe the algorithm and give you an example. Then Ill talk about the running time of the algorithm in Big O notation. Finally, Ill explore what other types of problems could be solved by the same algorithm. What youll learn about performance The good news is, an implementation of every algorithm in this book is probably available in your favorite language, so you dont have to write each algorithm yourself! But those implementations are useless if you dont understand the trade-offs. In this book, youll learn to compare trade-offs between different algorithms: Should you use merge sort or quicksort? Should you use an array or a list? Just using a different data structure can make a big difference. What youll learn about solving problems Y oull learn techniques for solving problems that might have been out of your grasp until now. For example: If you like making video games, you can write an AI system that follows the user around using graph algorithms. Y oull learn to make a recommendations system using k-nearest neighbors. Some problems arent solvable in a timely manner! The part of this book that talks about NP-complete problems shows you how to identify those problems and come up with an algorithm that gives you an approximate answer. More generally, by the end of this book, youll know some of the most widely applicable algorithms. Y ou can then use your new knowledge to learn about more specific algorithms for AI, databases, and so on. Or you can take on bigger challenges at work. 3 Binary search Binary search Suppose youre searching for a person in the phone book (what an old- fashioned sentence!). Their name starts with K. Y ou could start at the beginning and keep flipping pages until you get to the Ks. But youre more likely to start at a page in the middle, because you know the Ks are going to be near the middle of the phone book. Or suppose youre searching for a word in a dictionary, and it starts with O. Again, youll start near the middle. Now suppose you log on to Facebook. When you do, Facebook has to verify that you have an account on the site. So, it needs to search for your username in its database. Suppose your username is karlmageddon. Facebook could start from the As and search for your namebut it makes more sense for it to begin somewhere in the middle. This is a search problem. And all these cases use the same algorithm to solve the problem: binary search. Binary search is an algorithm; its input is a sorted list of elements (Ill explain later why it needs to be sorted). If an element youre looking for is in that list, binary search returns the position where its located. Otherwise, binary search returns null .What you need to know Youll need to know basic algebra before starting this book. In parti- cular, take this function: f( x) x 2. What is f(5)? If you answered 10, youre set. Additionally, this chapter (and this book) will be easier to follow if youre familiar with one programming language. All the examples in this book are in Python. If you dont know any programming languages and want to learn one, choose Pythonits great for beginners. If you know another language, like Ruby, youll be fine. Chapter 1 I Introduction to algorithms4 For example: Heres an example of how binary search works. Im thinking of a number between 1 and 100. Y ou have to try to guess my number in the fewest tries possible. With every guess, Ill tell you if your guess is too low, too high, or correct. Suppose you start guessing like this: 1, 2, 3, 4 . Heres how it would go. Looking for companies in a phone book with binary search 5 Binary search This is simple search (maybe stupid search would be a better term). With each guess, youre eliminating only one number. If my number was 99, it could take you 99 guesses to get there! A better way to search Heres a better technique. Start with 50. Too low, but you just eliminated half the numbers! Now you know that 150 are all too low. Next guess: 75. A bad approach to number guessing Chapter 1 I Introduction to algorithms6 Too high, but again you cut down half the remaining numbers! With binary search, you guess the middle number and eliminate half the remaining numbers every time . Next is 63 (halfway between 50 and 75). This is binary search. Y ou just learned your first algorithm! Heres how many numbers you can eliminate every time. Whatever number Im thinking of, you can guess in a maximum of seven guessesbecause you eliminate so many numbers with every guess! Suppose youre looking for a word in the dictionary. The dictionary has 240,000 words. In the worst case , how many steps do you think each search will take? Simple search could take 240,000 steps if the word youre looking for is the very last one in the book. With each step of binary search, you cut the number of words in half until youre left with only one word. Eliminate half the numbers every time with binary search. 7 Binary search Logarithms You may not remember what logarithms are, but you probably know what exponentials are. log10 100 is like asking, How many 10s do we multiply together to get 100? The answer is 2: 10 10. So log10 100 2. Logs are the flip of exponentials. Logs are the flip of exponentials. In this book, when I talk about running time in Big O notation (explained a little later), log always means log2. When you search for an element using simple search, in the worst case you might have to look at every single element. So for a list of 8 numbers, youd have to check 8 numbers at most. For binary search, you have to check log n elements in the worst case. For a list of 8 elements, log 8 3, because 23 8. So for a list of 8 numbers, you would have to check 3 numbers at most. For a list of 1,024 elements, log 1,024 10, because 210 1,024. So for a list of 1,024 numbers, youd have to check 10 numbers at most. Note Ill talk about log time a lot in this book, so you should understand the con - cept of logarithms. If you dont, Khan Academy (khanacademy.org) has a nice video that makes it clear.So binary search will take 18 stepsa big difference! In general, for any list of n, binary search will take log2 n steps to run in the worst case, whereas simple search will take n steps. Chapter 1 I Introduction to algorithms8 Note Binary search only works when your list is in sorted order. For example, the names in a phone book are sorted in alphabetical order, so you can use binary search to look for a name. What would happen if the names werent sorted? Lets see how to write binary search in Python. The code sample here uses arrays. If you dont know how arrays work, dont worry; theyre covered in the next chapter. Y ou just",
      "source": "Grokking Algorithms - Chapter 2",
      "timestamp": "2025-11-14T00:38:40.764194",
      "type": "book_content",
      "book_title": "Grokking Algorithms",
      "chapter_title": "Chapter 2",
      "chapter_number": 2
    },
    {
      "text": "need to know that you can store a sequence of elements in a row of consecutive buckets called an array. The buckets are numbered starting with 0: the first bucket is at position 0, the second is 1, the third is 2, and so on. The binary_search function takes a sorted array and an item. If the item is in the array, the function returns its position. Y oull keep track of what part of the array you have to search through. At the beginning, this is the entire array: low 0 high len(list) - 1 Each time, you check the middle element: mid (low high) 2 guess listmid If the guess is too low, you update low accordingly: if guess item: low mid 1mid is rounded down by Python automatically if (low high) isnt an even number. 9 And if the guess is too high, you update high . Heres the full code: def binary_search(list, item): low 0 high len(list)1 while low high: mid (low high) guess listmid if guess item: return mid if guess item: high mid - 1 else: low mid 1 return None my_list 1, 3, 5, 7, 9 print binary_search(my_list, 3) 1 print binary_search(my_list, -1) None EXERCISES 1.1 Suppose you have a sorted list of 128 names, and youre searching through it using binary search. Whats the maximum number of steps it would take? 1.2 Suppose you double the size of the list. Whats the maximum number of steps now?Binary search low and high keep track of which part of the list youll search in. While you havent narrowed it down to one element check the middle element. Found the item. The guess was too high. The guess was too low. The item doesnt exist. Lets test it! Remember, lists start at 0. The second slot has index 1. None means nil in Python. It indicates that the item wasnt found. Chapter 1 I Introduction to algorithms10 Running time Any time I talk about an algorithm, Ill discuss its running time. Generally you want to choose the most efficient algorithm whether youre trying to optimize for time or space. Back to binary search. How much time do you save by using it? Well, the first approach was to check each number, one by one. If this is a list of 100 numbers, it takes up to 100 guesses. If its a list of 4 billion numbers, it takes up to 4 billion guesses. So the maximum number of guesses is the same as the size of the list. This is called linear time . Binary search is different. If the list is 100 items long, it takes at most 7 guesses. If the list is 4 billion items, it takes at most 32 guesses. Powerful, eh? Binary search runs in logarithmic time (or log time , as the natives call it). Heres a table summarizing our findings today. Big O notation Big O notation is special notation that tells you how fast an algorithm is. Who cares? Well, it turns out that youll use other peoples algorithms oftenand when you do, its nice to understand how fast or slow they are. In this section, Ill explain what Big O notation is and give you a list of the most common running times for algorithms using it. Run times for search algorithms 11 Big O notation Running time for simple search vs. binary search, with a list of 100 elementsAlgorithm running times grow at different rates Bob is writing a search algorithm for NASA. His algorithm will kick in when a rocket is about to land on the Moon, and it will help calculate where to land. This is an example of how the run time of two algorithms can grow at different rates. Bob is trying to decide between simple search and binary search. The algorithm needs to be both fast and correct. On one hand, binary search is faster. And Bob has only 10 seconds to figure out where to landotherwise, the rocket will be off course. On the other hand, simple search is easier to write, and there is less chance of bugs being introduced. And Bob really doesnt want bugs in the code to land a rocket! To be extra careful, Bob decides to time both algorithms with a list of 100 elements. Lets assume it takes 1 millisecond to check one element. With simple search, Bob has to check 100 elements, so the search takes 100 ms to run. On the other hand, he only has to check 7 elements with binary search (log2 100 is roughly 7), so that search takes 7 ms to run. But realistically, the list will have more like a billion elements. If it does, how long will simple search take? How long will binary search take? Make sure you have an answer for each question before reading on. Bob runs binary search with 1 billion elements, and it takes 30 ms (log2 1,000,000,000 is roughly 30). 32 ms! he thinks. Binary search is about 15 times faster than simple search, because simple search took 100 ms with 100 elements, and binary search took 7 ms. So simple search will take 30 15 450 ms, right? Way under my threshold of 10 seconds. Bob decides to go with simple search. Is that the right choice? Chapter 1 I Introduction to algorithms12 No. Turns out, Bob is wrong. Dead wrong. The run time for simple search with 1 billion items will be 1 billion ms, which is 11 days! The problem is, the run times for binary search and simple search dont grow at the same rate . That is, as the number of items increases, binary search takes a little more time to run. But simple search takes a lot more time to run. So as the list of numbers gets bigger, binary search suddenly becomes a lot faster than simple search. Bob thought binary search was 15 times faster than simple search, but thats not correct. If the list has 1 billion items, its more like 33 million times faster. Thats why its not enough to know how long an algorithm takes to runyou need to know how the running time increases as the list size increases. Thats where Big O notation comes in. Big O notation tells you how fast an algorithm is. For example, suppose you have a list of size n. Simple search needs to check each element, so it will take n operations. The run time in Big O notation is O( n). Where are the seconds? There are noneBig O doesnt tell you the speed in seconds. Big O notation lets you compare the number of operations. It tells you how fast the algorithm grows. Run times grow at very different speeds! 13 Big O notation Heres another example. Binary search needs log n operations to check a list of size n. Whats the running time in Big O notation? Its O(log n). In general, Big O notation is written as follows. This tells you the number of operations an algorithm will make. Its called Big O notation because you put a big O in front of the number of operations (it sounds like a joke, but its true!). Now lets look at some examples. See if you can figure out the run time for these algorithms. Visualizing different Big O run times Heres a practical example you can follow at home with a few pieces of paper and a pencil. Suppose you have to draw a grid of 16 boxes. Algorithm 1 One way to do it is to draw 16 boxes, one at a time. Remember, Big O notation counts the number of operations. In this example, drawing one box is one operation. Y ou have to draw 16 boxes. How many operations will it take, drawing one box at a time? It takes 16 steps to draw 16 boxes. Whats the running time for this algorithm? What Big O notation looks like Whats a good algorithm to draw this grid? Drawing a grid one box at a time Chapter 1 I Introduction to algorithms14 Algorithm 2 Try this algorithm instead. Fold the paper. In this example, folding the paper once is an operation. Y ou just made two boxes with that operation! Fold the paper again, and again, and again. Unfold it after four folds, and youll have a beautiful grid! Every fold doubles the number of boxes. Y ou made 16 boxes with 4 operations! Y ou can draw twice as many boxes with every fold, so you can draw 16 boxes in 4 steps. Whats the running time for this algorithm? Come up with running times for both algorithms before moving on. Answers: Algorithm 1 takes O( n) time, and algorithm 2 takes O(log n) time. Drawing a grid in four folds 15 Big O notation Big O establishes a worst-case run time Suppose youre using simple search to look for a person in the phone book. Y ou know that simple search takes O( n) time to run, which means in the worst case, youll have to look through every single entry in your phone book. In this case, youre looking for Adit. This guy is the first entry in your phone book. So you didnt have to look at every entryyou found it on the first try. Did this algorithm take O( n) time? Or did it take O(1) time because you found the person on the first try? Simple search still takes O( n) time. In this case, you found what you were looking for instantly. Thats the best-case scenario. But Big O notation is about the worst-case scenario. So you can say that, in the worst case , youll have to look at every entry in the phone book once. Thats O( n) time. Its a reassuranceyou know that simple search will never be slower than O( n) time. Some common Big O run times Here are five Big O run times that youll encounter a lot, sorted from fastest to slowest: O(log n), also known as log time. Example: Binary search. O(n), also known as linear time . Example: Simple search. O(n log n). Example: A fast sorting algorithm, like quicksort (coming up in chapter 4). O(n2). Example: A slow sorting algorithm, like selection sort (coming up in chapter 2). O(n!). Example: A really slow algorithm, like the traveling salesperson (coming up next!). Suppose youre drawing a grid of 16 boxes again, and you can choose from 5 different algorithms to do so. If you use the first algorithm, it will take you O(log n) time to draw the grid. Y ou can do 10 operations Note Along with the worst-case run time, its also important to look at the average-case run time. Worst case versus average case is discussed in chapter 4. Chapter 1 I Introduction to algorithms16 per second. With O(log n) time, it will take you 4 operations to draw a grid of 16 boxes (log 16 is 4). So it will take you 0.4 seconds to draw the grid. What if you have to draw 1,024 boxes? It will take you log 1,024 10 operations, or 1 second to draw a grid of 1,024 boxes. These numbers are using the first algorithm. The second algorithm is slower: it takes O( n) time. It will take 16 operations to draw 16 boxes, and it will take 1,024 operations to draw 1,024 boxes. How much time is that in seconds? Heres how long it would take to draw a grid for the rest of the algorithms, from fastest to slowest: There are other run times, too, but these are the five most common. This is a simplification. In reality you cant convert from a Big O run time to a number of operations this neatly, but this is good enough for now. Well come back to Big O notation in chapter 4, after youve learned a few more",
      "source": "Grokking Algorithms - Chapter 3",
      "timestamp": "2025-11-14T00:38:40.764194",
      "type": "book_content",
      "book_title": "Grokking Algorithms",
      "chapter_title": "Chapter 3",
      "chapter_number": 3
    },
    {
      "text": "algorithms. For now, the main takeaways are as follows: Algorithm speed isnt measured in seconds, but in growth of the number of operations. Instead, we talk about how quickly the run time of an algorithm increases as the size of the input increases. Run time of algorithms is expressed in Big O notation. O(log n) is faster than O( n), but it gets a lot faster as the list of items youre searching grows. 17 Big O notation EXERCISES Give the run time for each of these scenarios in terms of Big O. 1.3 Y ou have a name, and you want to find the persons phone number in the phone book. 1.4 Y ou have a phone number, and you want to find the persons name in the phone book. (Hint: Y oull have to search through the whole book!) 1.5 Y ou want to read the numbers of every person in the phone book. 1.6 Y ou want to read the numbers of just the As. (This is a tricky one! It involves concepts that are covered more in chapter 4. Read the answeryou may be surprised!) The traveling salesperson You might have read that last section and thought, Theres no way Ill ever run into an algorithm that takes O( n!) time. Well, let me try to prove you wrong! Heres an example of an algorithm with a really bad running time. This is a famous problem in computer science, because its growth is appalling and some very smart people think it cant be improved. Its called the traveling salesperson problem. Y ou have a salesperson. Chapter 1 I Introduction to algorithms18 The salesperson has to go to five cities. This salesperson, whom Ill call Opus, wants to hit all five cities while traveling the minimum distance. Heres one way to do that: look at every possible order in which he could travel to the cities. He adds up the total distance and then picks the path with the lowest distance. There are 120 permutations with 5 cities, so it will take 120 operations to solve the problem for 5 cities. For 6 cities, it will take 720 operations (there are 720 permutations). For 7 cities, it will take 5,040 operations! The number of operations increases drastically. 19 Recap In general, for n items, it will take n! (n factorial) operations to compute the result. So this is O( n!) time, or factorial time . It takes a lot of operations for everything except the smallest numbers. Once youre dealing with 100 cities, its impossible to calculate the answer in timethe Sun will collapse first. This is a terrible algorithm! Opus should use a different one, right? But he cant. This is one of the unsolved problems in computer science. Theres no fast known algorithm for it, and smart people think its impossible to have a smart algorithm for this problem. The best we can do is come up with an approximate solution; see chapter 10 for more. One final note: if youre an advanced reader, check out binary search trees! Theres a brief description of them in the last chapter. Recap Binary search is a lot faster than simple search. O(log n) is faster than O( n), but it gets a lot faster once the list of items youre searching through grows. Algorithm speed isnt measured in seconds. Algorithm times are measured in terms of growth of an algorithm. Algorithm times are written in Big O notation. 2 In this chapter You learn about arrays and linked liststwo of the most basic data structures. Theyre used absolutely everywhere. You already used arrays in chapter 1, and youll use them in almost every chapter in this book. Arrays are a crucial topic, so pay attention! But sometimes its better to use a linked list instead of an array. This chapter explains the pros and cons of both so you can decide which one is right for your algorithm. You learn your first sorting algorithm. A lot of algo - rithms only work if your data is sorted. Remember binary search? You can run binary search only on a sorted list of elements. This chapter teaches you selection sort. Most languages have a sorting algorithm built in, so youll rarely need to write your own version from scratch. But selection sort is a stepping stone to quicksort, which Ill cover in the next chapter. Quicksort is an important algorithm, and it will be easier to understand if you know one sorting algorithm already.selection sort 21 22 Chapter 2 I Selection sort How memory works Imagine you go to a show and need to check your things. A chest of drawers is available. Each drawer can hold one element. Y ou want to store two things, so you ask for two drawers. What you need to know To understand the performance analysis bits in this chapter, you need to know Big O notation and logarithms. If you dont know those, I suggest you go back and read chapter 1. Big O notation will be used throughout the rest of the book. 23 How memory works Y ou store your two things here. And youre ready for the show! This is basically how your computers memory works. Y our computer looks like a giant set of drawers, and each drawer has an address. fe 0ffeeb is the address of a slot in memory. Each time you want to store an item in memory, you ask the computer for some space, and it gives you an address where you can store your item. If you want to store multiple items, there are two basic ways to do so: arrays and lists. Ill talk about arrays and lists next, as well as the pros and cons of each. There isnt one right way to store items for every use case, so its important to know the differences. 24 Arrays and linked lists Sometimes you need to store a list of elements in memory. Suppose youre writing an app to manage your todos. Y oull want to store the todos as a list in memory. Should you use an array, or a linked list? Lets store the todos in an array first, because its easier to grasp. Using an array means all your tasks are stored contiguously (right next to each other) in memory. Now suppose you want to add a fourth task. But the next drawer is taken up by someone elses stuff! Its like going to a movie with your friends and finding a place to sit but another friend joins you, and theres no place for them. Y ou have to move to a new spot where you all fit. In this case, you need to ask your computer for a different chunk of memory that can fit four tasks. Then you need to move all your tasks there. Chapter 2 I Selection sort 25 Arrays and linked lists If another friend comes by, youre out of room againand you all have to move a second time! What a pain. Similarly, adding new items to an array can be a big pain. If youre out of space and need to move to a new spot in memory every time, adding a new item will be really slow. One easy fix is to hold seats: even if you have only 3 items in your task list, you can ask the computer for 10 slots, just in case. Then you can add 10 items to your task list without having to move. This is a good workaround, but you should be aware of a couple of downsides: Y ou may not need the extra slots that you asked for, and then that memory will be wasted. Y ou arent using it, but no one else can use it either. Y ou may add more than 10 items to your task list and have to move anyway. So its a good workaround, but its not a perfect solution. Linked lists solve this problem of adding items. Linked lists With linked lists, your items can be anywhere in memory. Each item stores the address of the next item in the list. A bunch of random memory addresses are linked together. 26 Its like a treasure hunt. Y ou go to the first address, and it says, The next item can be found at address 123. So you go to address 123, and it says, The next item can be found at address 847, and so on. Adding an item to a linked list is easy: you stick it anywhere in memory and store the address with the previous item. With linked lists, you never have to move your items. Y ou also avoid another problem. Lets say you go to a popular movie with five of your friends. The six of you are trying to find a place to sit, but the theater is packed. There arent six seats together. Well, sometimes this happens with arrays. Lets say youre trying to find 10,000 slots for an array. Y our memory has 10,000 slots, but it doesnt have 10,000 slots together. Y ou cant get space for your array! A linked list is like saying, Lets split up and watch the movie. If theres space in memory, you have space for your linked list. If linked lists are so much better at inserts, what are arrays good for? Arrays Websites with top-10 lists use a scummy tactic to get more page views. Instead of showing you the list on one page, they put one item on each page and make you click Next to get to the next item in the list. For example, Top 10 Best TV Villains wont show you the entire list on one page. Instead, you start at 10 (Newman), and you have to click Next on each page to reach 1 (Gustavo Fring). This technique gives the websites 10 whole pages on which to show you ads, but its boring to click Next 9 times to get to 1. It would be much better if the whole list was on one page and you could click each persons name for more info. Linked lists have a similar problem. Suppose you want to read the last item in a linked list. Y ou cant just read it, because you dont know what address its at. Instead, you have to go to item 1 to get the address for Chapter 2 I Selection sort Linked memory addresses 27 Arrays and linked lists item 2. Then you have to go to item 2 to get the address for item 3. And so on, until you get to the last item. Linked lists are great if youre going to read all the items one at a time: you can read one item, follow the address to the next item, and so on. But if youre going to keep jumping around, linked lists are terrible. Arrays are different. Y ou know the address for every item in your array. For example, suppose your array contains five items, and you know it starts at address 00. What is the address of item 5? Simple math tells you: its 04. Arrays are great if you want to read random elements, because you can look up any element in your array instantly. With a linked list, the elements arent next to each other, so you cant instantly calculate the position of the fifth element in memoryyou have to go to the first element to get the address to the second element, then go to the second element to get the address of the third element, and so on until you get to the fifth element. Terminology The elements in an array are numbered. This numbering starts from 0, not 1. For example, in this array, 20 is at position 1. And 10 is at position 0. This usually throws new programmers for a spin. Starting at 0 makes",
      "source": "Grokking Algorithms - Chapter 4: Algorithm",
      "timestamp": "2025-11-14T00:38:40.764194",
      "type": "book_content",
      "book_title": "Grokking Algorithms",
      "chapter_title": "Chapter 4: Algorithm",
      "chapter_number": 4
    },
    {
      "text": "all kinds of array-based code easier to write, so programmers have stuck with it. Almost every programming language you use will number array elements starting at 0. Y oull soon get used to it. 28 The position of an element is called its index. So instead of saying, 20 is at position 1, the correct terminology is, 20 is at index 1. Ill use index to mean position throughout this book. Here are the run times for common operations on arrays and lists. Question: Why does it take O( n) time to insert an element into an array? Suppose you wanted to insert an element at the beginning of an array. How would you do it? How long would it take? Find the answers to these questions in the next section! EXERCISE 2.1 Suppose youre building an app to keep track of your finances. Every day, you write down everything you spent money on. At the end of the month, you review your expenses and sum up how much you spent. So, you have lots of inserts and a few reads. Should you use an array or a list? Chapter 2 I Selection sort 29 Arrays and linked lists Inserting into the middle of a list Suppose you want your todo list to work more like a calendar. Earlier, you were adding things to the end of the list. Now you want to add them in the order in which they should be done. Whats better if you want to insert elements in the middle: arrays or lists? With lists, its as easy as changing what the previous element points to. But for arrays, you have to shift all the rest of the elements down. And if theres no space, you might have to copy everything to a new location! Lists are better if you want to insert elements into the middle. Unordered Ordered 30 Chapter 2 I Selection sort Deletions What if you want to delete an element? Again, lists are better, because you just need to change what the previous element points to. With arrays, everything needs to be moved up when you delete an element. Unlike insertions, deletions will always work. Insertions can fail sometimes when theres no space left in memory. But you can always delete an element. Here are the run times for common operations on arrays and linked lists. Its worth mentioning that insertions and deletions are O(1) time only if you can instantly access the element to be deleted. Its a common practice to keep track of the first and last items in a linked list, so it would take only O(1) time to delete those. Which are used more: arrays or lists? Obviously, it depends on the use case. But arrays see a lot of use because they allow random access. There are two different types of access: random access and sequential access . Sequential access means reading the elements one by one, starting at the first element. Linked lists can only do sequential access. If you want to read the 10th element of a linked list, you have to read the first 9 elements and follow the links to the 10th element. Random access means you can jump directly to the 10th element. Y oull frequently hear me say that arrays are faster at reads. This is because they provide random access. A lot of use cases require random access, so arrays are used a lot. Arrays and lists are used to implement other data structures, too (coming up later in the book). 31 Arrays and linked lists EXERCISES 2.2 Suppose youre building an app for restaurants to take customer orders. Y our app needs to store a list of orders. Servers keep adding orders to this list, and chefs take orders off the list and make them. Its an order queue: servers add orders to the back of the queue, and the chef takes the first order off the queue and cooks it. Would you use an array or a linked list to implement this queue? (Hint: Linked lists are good for insertsdeletes, and arrays are good for random access. Which one are you going to be doing here?) 2.3 Lets run a thought experiment. Suppose Facebook keeps a list of usernames. When someone tries to log in to Facebook, a search is done for their username. If their name is in the list of usernames, they can log in. People log in to Facebook pretty often, so there are a lot of searches through this list of usernames. Suppose Facebook uses binary search to search the list. Binary search needs random accessyou need to be able to get to the middle of the list of usernames instantly. Knowing this, would you implement the list as an array or a linked list? 2.4 People sign up for Facebook pretty often, too. Suppose you decided to use an array to store the list of users. What are the downsides of an array for inserts? In particular, suppose youre using binary search to search for logins. What happens when you add new users to an array? 2.5 In reality, Facebook uses neither an array nor a linked list to store user information. Lets consider a hybrid data structure: an array of linked lists. Y ou have an array with 26 slots. Each slot points to a linked list. For example, the first slot in the array points to a linked list containing all the usernames starting with a. The second slot points to a linked list containing all the usernames starting with b, and so on. 32 Chapter 2 I Selection sort Suppose Adit B signs up for Facebook, and you want to add them to the list. Y ou go to slot 1 in the array, go to the linked list for slot 1, and add Adit B at the end. Now, suppose you want to search for Zakhir H. Y ou go to slot 26, which points to a linked list of all the Z names. Then you search through that list to find Zakhir H. Compare this hybrid data structure to arrays and linked lists. Is it slower or faster than each for searching and inserting? Y ou dont have to give Big O run times, just whether the new data structure would be faster or slower. Selection sort Lets put it all together to learn your second algorithm: selection sort. To follow this section, you need to understand arrays and lists, as well as Big O notation. Suppose you have a bunch of music on your computer. For each artist, you have a play count. Y ou want to sort this list from most to least played, so that you can rank your favorite artists. How can you do it? 33 Selection sort One way is to go through the list and find the most-played artist. Add that artist to a new list. Do it again to find the next-most-played artist. Keep doing this, and youll end up with a sorted list. 34 Chapter 2 I Selection sort Lets put on our computer science hats and see how long this will take to run. Remember that O( n) time means you touch every element in a list once. For example, running simple search over the list of artists means looking at each artist once. To find the artist with the highest play count, you have to check each item in the list. This takes O( n) time, as you just saw. So you have an operation that takes O( n) time, and you have to do that n times: This takes O( n n) time or O( n2) time. Sorting algorithms are very useful. Now you can sort Names in a phone book Travel dates Emails (newest to oldest) 35 Selection sort is a neat algorithm, but its not very fast. Quicksort is a faster sorting algorithm that only takes O( n log n) time. Its coming up in the next chapter! EXAMPLE CODE LISTING We didnt show you the code to sort the music list, but following is some code that will do something very similar: sort an array from smallest to largest. Lets write a function to find the smallest element in an array: def findSmallest(arr): smallest arr0 Stores the smallest value smallest_index 0 Stores the index of the smallest value for i in range(1, len(arr)): if arri smallest: smallest arri smallest_index i return smallest_index Now you can use this function to write selection sort: def selectionSort(arr): Sorts an array newArr for i in range(len(arr)): smallest findSmallest(arr) newArr.append(arr.pop(smallest)) return newArr print selectionSort(5, 3, 6, 2, 10)Selection sort Checking fewer elements each time Maybe youre wondering: as you go through the operations, the number of elements you have to check keeps decreasing. Eventually, youre down to having to check just one element. So how can the run time still be O(n2)? Thats a good question, and the answer has to do with constants in Big O notation. Ill get into this more in chapter 4, but heres the gist. Youre right that you dont have to check a list of n elements each time. You check n elements, then n 1, n - 2 2, 1. On average, you check a list that has 12 n elements. The runtime is O( n 12 n). But constants like 12 are ignored in Big O notation (again, see chapter 4 for the full discussion), so you just write O( n n) or O( n2). Finds the smallest element in the array, and adds it to the new array 36 Recap Y our computers memory is like a giant set of drawers. When you want to store multiple elements, use an array or a list. With an array, all your elements are stored right next to each other. With a list, elements are strewn all over, and one element stores the address of the next one. Arrays allow fast reads. Linked lists allow fast inserts and deletes. All elements in the array should be the same type (all ints, all doubles, and so on).Chapter 2 I Selection sort 373 In this chapter You learn about recursion. Recursion is a coding technique used in many algorithms. Its a building block for understanding later chapters in this book. You learn how to break a problem down into a base case and a recursive case. The divide-and- conquer strategy (chapter 4) uses this simple concept to solve hard problems.recursion Im excited about this chapter because it covers recursion , an elegant way to solve problems. Recursion is one of my favorite topics, but its divisive. People either love it or hate it, or hate it until they learn to love it a few years later. I personally was in that third camp. To make things easier for you, I have some advice: This chapter has a lot of code examples. Run the code for yourself to see how it works. Ill talk about recursive functions. At least once, step through a recursive function with pen and paper: something like, Lets see, I pass 5 into factorial , and then I return 5 times passing 4 into factorial , which is , and so on. Walking through a function like this will teach you how a recursive function works. 38 Chapter 3 I Recursion This chapter also includes a lot of pseudocode. Pseudocode is a high-level description of the problem youre trying to solve, in code. Its written like code, but its meant to be closer to human speech. Recursion Suppose youre digging through your grandmas attic and come across a mysterious locked suitcase. Grandma tells you that the key for the suitcase is probably in this other box. This box contains more boxes, with more boxes inside those boxes. The key is in a box somewhere. Whats your algorithm to search for the key? Think of an algorithm before you read on. 39 Recursion Heres one approach. 1. Make a pile of boxes",
      "source": "Grokking Algorithms - Chapter 5: Array",
      "timestamp": "2025-11-14T00:38:40.764194",
      "type": "book_content",
      "book_title": "Grokking Algorithms",
      "chapter_title": "Chapter 5: Array",
      "chapter_number": 5
    },
    {
      "text": "to look through. 2. Grab a box, and look through it. 3. If you find a box, add it to the pile to look through later. 4. If you find a key, youre done! 5. Repeat. Heres an alternate approach. 1. Look through the box. 2. If you find a box, go to step 1. 3. If you find a key, youre done! 40 Chapter 3 I Recursion Which approach seems easier to you? The first approach uses a while loop. While the pile isnt empty, grab a box and look through it: def look_for_key(main_box): pile main_box.make_a_pile_to_look_through() while pile is not empty: box pile.grab_a_box() for item in box: if item.is_a_box(): pile.append(item) elif item.is_a_key(): print found the key! The second way uses recursion. Recursion is where a function calls itself. Heres the second way in pseudocode: def look_for_key(box): for item in box: if item.is_a_box(): look_for_key(item) Recursion! elif item.is_a_key(): print found the key! Both approaches accomplish the same thing, but the second approach is clearer to me. Recursion is used when it makes the solution clearer. Theres no performance benefit to using recursion; in fact, loops are sometimes better for performance. I like this quote by Leigh Caldwell on Stack Overflow: Loops may achieve a performance gain for your program. Recursion may achieve a performance gain for your programmer. Choose which is more important in your situation!1 Many important algorithms use recursion, so its important to understand the concept. Base case and recursive case Because a recursive function calls itself, its easy to write a function incorrectly that ends up in an infinite loop. For example, suppose you want to write a function that prints a countdown, like this: 3...2...1 1 http:stackoverflow.coma72694139117. 41 Base case and recursive case Y ou can write it recursively, like so: def countdown(i): print i countdown(i-1) Write out this code and run it. Y oull notice a problem: this function will run forever! 3...2...1...0...-1...-2... (Press Ctrl-C to kill your script.) When you write a recursive function, you have to tell it when to stop recursing. Thats why every recursive function has two parts: the base case, and the recursive case. The recursive case is when the function calls itself. The base case is when the function doesnt call itself again so it doesnt go into an infinite loop. Lets add a base case to the countdown function: def countdown(i): print i if i 0: Base case return else: Recursive case countdown(i-1) Now the function works as expected. It goes something like this.Infinite loop 42 Chapter 3 I Recursion The stack This section covers the call stack . Its an important concept in programming. The call stack is an important concept in general programming, and its also important to understand when using recursion . Suppose youre throwing a barbecue. Y ou keep a todo list for the barbecue, in the form of a stack of sticky notes. Remember back when we talked about arrays and lists, and you had a todo list? Y ou could add todo items anywhere to the list or delete random items. The stack of sticky notes is much simpler. When you insert an item, it gets added to the top of the list. When you read an item, you only read the topmost item, and its taken off the list. So your todo list has only two actions: push (insert) and pop (remove and read). Lets see the todo list in action. This data structure is called a stack . The stack is a simple data structure. Y ouve been using a stack this whole time without realizing it! 43 The stack The call stack Y our computer uses a stack internally called the call stack. Lets see it in action. Heres a simple function: def greet(name): print hello, name ! greet2(name) print getting ready to say bye... bye() This function greets you and then calls two other functions. Here are those two functions: def greet2(name): print how are you, name ? def bye(): print ok bye! Lets walk through what happens when you call a function. Suppose you call greet(maggie) . First, your computer allocates a box of memory for that function call. Now lets use the memory. The variable name is set to maggie . That needs to be saved in memory. Note print is a function in Python, but to make things easier for this example, were pretending it isnt. Just play along. 44 Chapter 3 I Recursion Every time you make a function call, your computer saves the values for all the variables for that call in memory like this. Next, you print hello, maggie! Then you call greet2(maggie). Again, your computer allocates a box of memory for this function call. Y our computer is using a stack for these boxes. The second box is added on top of the first one. Y ou print how are you, maggie? Then you return from the function call. When this happens, the box on top of the stack gets popped off. Now the topmost box on the stack is for the greet function, which means you returned back to the greet function. When you called the greet2 function, the greet function was partially completed. This is the big idea behind this section: when you call a function from another function, the calling function is paused in a partially completed state. All the values of the variables for that function are still stored in memory. Now that youre done with the greet2 function, youre back to the greet function, and you pick up where you left off. First you print getting ready to say bye . Y ou call the bye function. 45 The stack A box for that function is added to the top of the stack. Then you print ok bye! and return from the function call. And youre back to the greet function. Theres nothing else to be done, so you return from the greet function too. This stack, used to save the variables for multiple functions, is called the call stack . EXERCISE 3.1 Suppose I show you a call stack like this. What information can you give me, just based on this call stack? Now lets see the call stack in action with a recursive function. The call stack with recursion Recursive functions use the call stack too! Lets look at this in action with the factorial function. factorial(5) is written as 5!, and its defined like this: 5! 5 4 3 2 1. Similarly, factorial(3) is 3 2 1. Heres a recursive function to calculate the factorial of a number: def fact(x): if x 1: return 1 else: return x fact(x-1) Now you call fact(3) . Lets step through this call line by line and see how the stack changes. Remember, the topmost box in the stack tells you what call to fact youre currently on. 46 Chapter 3 I Recursion 47 The stack Notice that each call to fact has its own copy of x. Y ou cant access a different functions copy of x. The stack plays a big part in recursion. In the opening example, there were two approaches to find the key. Heres the first way again. This way, you make a pile of boxes to search through, so you always know what boxes you still need to search. 48 Chapter 3 I Recursion But in the recursive approach, theres no pile. If theres no pile, how does your algorithm know what boxes you still have to look through? Heres an example. 49 The stack At this point, the call stack looks like this. The pile of boxes is saved on the stack! This is a stack of half- completed function calls, each with its own half-complete list of boxes to look through. Using the stack is convenient because you dont have to keep track of a pile of boxes yourselfthe stack does it for you. Using the stack is convenient, but theres a cost: saving all that info can take up a lot of memory. Each of those function calls takes up some memory, and when your stack is too tall, that means your computer is saving information for many function calls. At that point, you have two options: Y ou can rewrite your code to use a loop instead. Y ou can use something called tail recursion . Thats an advanced recursion topic that is out of the scope of this book. Its also only supported by some languages, not all. EXERCISE 3.2 Suppose you accidentally write a recursive function that runs forever. As you saw, your computer allocates memory on the stack for each function call. What happens to the stack when your recursive function runs forever? 50 Chapter 3 I Recursion Recap Recursion is when a function calls itself. Every recursive function has two cases: the base case and the recursive case. A stack has two operations: push and pop. All function calls go onto the call stack. The call stack can get very large, which takes up a lot of memory. 4In this chapter You learn about divide-and-conquer. Sometimes youll come across a problem that cant be solved by any algorithm youve learned. When a good algorithmist comes across such a problem, they dont just give up. They have a toolbox full of techniques they use on the problem, trying to come up with a solution. Divide-and-conquer is the first general technique you learn. You learn about quicksort, an elegant sorting algorithm thats often used in practice. Quicksort uses divide-and-conquer. 51quicksort You learned all about recursion in the last chapter. This chapter focuses on using your new skill to solve problems. Well explore divide and conquer (DC), a well-known recursive technique for solving problems. This chapter really gets into the meat of algorithms. After all, an algorithm isnt very useful if it can only solve one type of problem. Instead, DC gives you a new way to think about solving 52 Chapter 4 I Quicksort problems. DC is another tool in your toolbox. When you get a new problem, you dont have to be stumped. Instead, you can ask, Can I solve this if I use divide and conquer? At the end of the chapter, youll learn your first major DC algorithm: quicksort . Quicksort is a sorting algorithm, and a much faster one than selection sort (which you learned in chapter 2). Its a good example of elegant code. Divide conquer DC can take some time to grasp. So, well do three examples. First Ill show you a visual example. Then Ill do a code example that is less pretty but maybe easier. Finally, well go through quicksort, a sorting algorithm that uses DC. Suppose youre a farmer with a plot of land. Y ou want to divide this farm evenly into square plots. Y ou want the plots to be as big as possible. So none of these will work. 53 Divide conquer How do you figure out the largest square size you can use for a plot of land? Use the DC strategy! DC algorithms are recursive algorithms. To solve a problem using DC, there are two steps: 1. Figure out the base case. This should be the simplest possible case. 2. Divide or decrease your problem until it becomes the base case. Lets use DC to find the solution to this problem. What is the largest square size you can use? First, figure out the base case. The easiest case would be if one side was a multiple of the other side. Suppose one side is 25 meters (m) and the other side is 50 m. Then the largest box you can use is 25 m 25 m. Y ou need two of those boxes to divide up the land. Now you need to figure out the recursive case. This is where DC comes in. According to DC, with every recursive call, you have to reduce your problem. How do you reduce the problem here? Lets start by marking out the biggest boxes",
      "source": "Grokking Algorithms - Chapter 6",
      "timestamp": "2025-11-14T00:38:40.764194",
      "type": "book_content",
      "book_title": "Grokking Algorithms",
      "chapter_title": "Chapter 6",
      "chapter_number": 6
    },
    {
      "text": "you can use. 54 Chapter 4 I Quicksort Y ou can fit two 640 640 boxes in there, and theres some land still left to be divided. Now here comes the Aha! moment. Theres a farm segment left to divide. Why dont you apply the same algorithm to this segment? So you started out with a 1680 640 farm that needed to be split up. But now you need to split up a smaller segment, 640 400. If you find the biggest box that will work for this size, that will be the biggest box that will work for the entire farm. Y ou just reduced the problem from a 1680 640 farm to a 640 400 farm! Lets apply the same algorithm again. Starting with a 640 400m farm, the biggest box you can create is 400 400 m. Euclids algorithm If you find the biggest box that will work for this size, that will be the biggest box that will work for the entire farm. If its not obvious to you why this statement is true, dont worry. It isnt obvious. Unfortunately, the proof for why it works is a little too long to include in this book, so youll just have to believe me that it works. If you want to understand the proof, look up Euclids algorithm. The Khan academy has a good explanation here: https:www.khanacademy.orgcomputingcomputer-science cryptographymodarithmeticathe-euclidean-algorithm. 55 Divide conquer And that leaves you with a smaller segment, 400 240 m. And you can draw a box on that to get an even smaller segment, 240 160 m. And then you draw a box on that to get an even smaller segment. Hey, youre at the base case: 80 is a factor of 160. If you split up this segment using boxes, you dont have anything left over! 56 Chapter 4 I Quicksort So, for the original farm, the biggest plot size you can use is 80 80 m. To recap, heres how DC works: 1. Figure out a simple case as the base case. 2. Figure out how to reduce your problem and get to the base case. DC isnt a simple algorithm that you can apply to a problem. Instead, its a way to think about a problem. Lets do one more example. Y oure given an array of numbers. Y ou have to add up all the numbers and return the total. Its pretty easy to do this with a loop: def sum(arr): total 0 for x in arr: total x return total print sum(1, 2, 3, 4) But how would you do this with a recursive function? Step 1: Figure out the base case. Whats the simplest array you could get? Think about the simplest case, and then read on. If you get an array with 0 or 1 element, thats pretty easy to sum up. 57 Divide conquer So that will be the base case. Step 2: Y ou need to move closer to an empty array with every recursive call. How do you reduce your problem size? Heres one way. Its the same as this. In either case, the result is 12. But in the second version, youre passing a smaller array into the sum function. That is, you decreased the size of your problem! Y our sum function could work like this. 58 Chapter 4 I Quicksort Here it is in action. Tip When youre writing a recursive function involving an array, the base case is often an empty array or an array with one element. If youre stuck, try that first. Remember, recursion keeps track of the state. 59 Divide conquer EXERCISES 4.1 Write out the code for the earlier sum function. 4.2 Write a recursive function to count the number of items in a list. 4.3 Find the maximum number in a list. 4.4 Remember binary search from chapter 1? Its a divide-and-conquer algorithm, too. Can you come up with the base case and recursive case for binary search? Sneak peak at functional programming Why would I do this recursively if I can do it easily with a loop? you may be thinking. Well, this is a sneak peek into functional programming! Functional programming languages like Haskell dont have loops, so you have to use recursion to write functions like this. If you have a good understanding of recursion, functional languages will be easier to learn. For example, heres how youd write a sum function in Haskell: sum 0 Base case sum (x:xs) x (sum xs) Recursive case Notice that it looks like you have two definitions for the function. The first definition is run when you hit the base case. The second definition runs at the recursive case. You can also write this function in Haskell using an if statement: sum arr if arr then 0 else (head arr) (sum (tail arr)) But the first definition is easier to read. Because Haskell makes heavy use of recursion, it includes all kinds of niceties like this to make recursion easy. If you like recursion, or youre interested in learning a new language, check out Haskell. 60 Chapter 4 I Quicksort Quicksort Quicksort is a sorting algorithm. Its much faster than selection sort and is frequently used in real life. For example, the C standard library has a function called qsort , which is its implementation of quicksort. Quicksort also uses DC. Lets use quicksort to sort an array. Whats the simplest array that a sorting algorithm can handle (remember my tip from the previous section)? Well, some arrays dont need to be sorted at all. Empty arrays and arrays with just one element will be the base case. Y ou can just return those arrays as istheres nothing to sort: def quicksort(array): if len(array) 2: return array Lets look at bigger arrays. An array with two elements is pretty easy to sort, too. What about an array of three elements? Remember, youre using DC. So you want to break down this array until youre at the base case. Heres how quicksort works. First, pick an element from the array. This element is called the pivot. Well talk about how to pick a good pivot later. For now, lets say the first item in the array is the pivot. 61 Quicksort Now find the elements smaller than the pivot and the elements larger than the pivot. This is called partitioning. Now you have A sub-array of all the numbers less than the pivot The pivot A sub-array of all the numbers greater than the pivot The two sub-arrays arent sorted. Theyre just partitioned. But if they were sorted, then sorting the whole array would be pretty easy. If the sub-arrays are sorted, then you can combine the whole thing like thisleft array pivot right array and you get a sorted array. In this case, its 10, 15 33 10, 15, 33 , which is a sorted array. How do you sort the sub-arrays? Well, the quicksort base case already knows how to sort arrays of two elements (the left sub-array) and empty arrays (the right sub-array). So if you call quicksort on the two sub-arrays and then combine the results, you get a sorted array! quicksort(15, 10) 33 quicksort() 10, 15, 33 A sorted array 62 Chapter 4 I Quicksort This will work with any pivot. Suppose you choose 15 as the pivot instead. Both sub-arrays have only one element, and you know how to sort those. So now you know how to sort an array of three elements. Here are the steps: 1. Pick a pivot. 2. Partition the array into two sub-arrays: elements less than the pivot and elements greater than the pivot. 3. Call quicksort recursively on the two sub-arrays. What about an array of four elements? Suppose you choose 33 as the pivot again. The array on the left has three elements. Y ou already know how to sort an array of three elements: call quicksort on it recursively. 63 Quicksort So you can sort an array of four elements. And if you can sort an array of four elements, you can sort an array of five elements. Why is that? Suppose you have this array of five elements. Here are all the ways you can partition this array, depending on what pivot you choose. Notice that all of these sub-arrays have somewhere between 0 and 4 elements. And you already know how to sort an array of 0 to 4 elements using quicksort! So no matter what pivot you pick, you can call quicksort recursively on the two sub-arrays. 64 Chapter 4 I Quicksort For example, suppose you pick 3 as the pivot. Y ou call quicksort on the sub-arrays. The sub-arrays get sorted, and then you combine the whole thing to get a sorted array. This works even if you choose 5 as the pivot. This works with any element as the pivot. So you can sort an array of five elements. Using the same logic, you can sort an array of six elements, and so on. 65 Quicksort Heres the code for quicksort: def quicksort(array): if len(array) 2: return array Base case: arrays with 0 or 1 element are already sorted. else: pivot array0 Recursive case less i for i in array1: if i pivot Sub-array of all the elements less than the pivot greater i for i in array1: if i pivot Sub-array of all the elements greater than the pivot return quicksort(less) pivot quicksort(greater) print quicksort(10, 5, 2, 3)Inductive proofs You just got a sneak peak into inductive proofs! Inductive proofs are one way to prove that your algorithm works. Each inductive proof has two steps: the base case and the inductive case. Sound familiar? For example, suppose I want to prove that I can climb to the top of a ladder. In the inductive case, if my legs are on a rung, I can put my legs on the next rung. So if Im on rung 2, I can climb to rung 3. Thats the inductive case. For the base case, Ill say that my legs are on rung 1. Therefore, I can climb the entire ladder, going up one rung at a time. You use similar reasoning for quicksort. In the base case, I showed that the algorithm works for the base case: arrays of size 0 and 1. In the inductive case, I showed that if quicksort works for an array of size 1, it will work for an array of size 2. And if it works for arrays of size 2, it will work for arrays of size 3, and so on. Then I can say that quicksort will work for all arrays of any size. I wont go deeper into inductive proofs here, but theyre fun and go hand-in-hand with DC. 66 Chapter 4 I Quicksort Big O notation revisited Quicksort is unique because its speed depends on the pivot you choose. Before I talk about quicksort, lets look at the most common Big O run times again. The example times in this chart are estimates if you perform 10 operations per second. These graphs arent precisetheyre just there to give you a sense of how different these run times are. In reality, your computer can do way more than 10 operations per second. Each run time also has an example algorithm attached. Check out selection sort, which you learned in chapter 2. Its O( n2). Thats a pretty slow algorithm. Theres another sorting algorithm called merge sort , which is O(n log n). Much faster! Quicksort is a tricky case. In the worst case, quicksort takes O( n2) time. Its as slow as selection sort! But thats the worst case. In the average case, quicksort takes O( n log n) time. So you might be wondering: What do worst case and average case mean here? If quicksort is O( n log n) on average, but merge sort is O( n log n) always, why not use merge sort? Isnt it faster?Estimates based on",
      "source": "Grokking Algorithms - Chapter 7: Chapter",
      "timestamp": "2025-11-14T00:38:40.764194",
      "type": "book_content",
      "book_title": "Grokking Algorithms",
      "chapter_title": "Chapter 7: Chapter",
      "chapter_number": 7
    },
    {
      "text": "a slow computer that performs 10 operations per second 67 Big O notation revisited Merge sort vs. quicksort Suppose you have this simple function to print every item in a list: def print_items(list): for item in list: print item This function goes through every item in the list and prints it out. Because it loops over the whole list once, this function runs in O( n) time. Now, suppose you change this function so it sleeps for 1 second before it prints out an item: from time import sleep def print_items2(list): for item in list: sleep(1) print item Before it prints out an item, it will pause for 1 second. Suppose you print a list of five items using both functions. Both functions loop through the list once, so theyre both O( n) time. Which one do you think will be faster in practice? I think print_items will be much faster because it doesnt pause for 1 second before printing an item. So even though both functions are the same speed in Big O notation, print_items is faster in practice. When you write Big O notation like O( n), it really means this. c is some fixed amount of time that your algorithm takes. Its called the constant . For example, it might be 10 milliseconds n for print_ items versus 1 second n for print_items2 . 68 Chapter 4 I Quicksort Y ou usually ignore that constant, because if two algorithms have different Big O times, the constant doesnt matter. Take binary search and simple search, for example. Suppose both algorithms had these constants. Y ou might say, Wow! Simple search has a constant of 10 milliseconds, but binary search has a constant of 1 second. Simple search is way faster! Now suppose youre searching a list of 4 billion elements. Here are the times. As you can see, binary search is still way faster. That constant didnt make a difference at all. But sometimes the constant can make a difference. Quicksort versus merge sort is one example. Quicksort has a smaller constant than merge sort. So if theyre both O( n log n) time, quicksort is faster. And quicksort is faster in practice because it hits the average case way more often than the worst case. So now youre wondering: whats the average case versus the worst case? Average case vs. worst case The performance of quicksort heavily depends on the pivot you choose. Suppose you always choose the first element as the pivot. And you call quicksort with an array that is already sorted. Quicksort doesnt check to see whether the input array is already sorted. So it will still try to sort it. 69 Big O notation revisited Notice how youre not splitting the array into two halves. Instead, one of the sub-arrays is always empty. So the call stack is really long. Now instead, suppose you always picked the middle element as the pivot. Look at the call stack now. Its so short! Because you divide the array in half every time, you dont need to make as many recursive calls. Y ou hit the base case sooner, and the call stack is much shorter. 70 Chapter 4 I Quicksort The first example you saw is the worst-case scenario, and the second example is the best-case scenario. In the worst case, the stack size is O(n). In the best case, the stack size is O(log n). Now look at the first level in the stack. Y ou pick one element as the pivot, and the rest of the elements are divided into sub-arrays. Y ou touch all eight elements in the array. So this first operation takes O( n) time. Y ou touched all eight elements on this level of the call stack. But actually, you touch O( n) elements on every level of the call stack. 71 Big O notation revisited Even if you partition the array differently, youre still touching O( n) elements every time. So each level takes O( n) time to complete. In this example, there are O(log n) levels (the technical way to say that is, The height of the call stack is O(log n)). And each level takes O(n) time. The entire algorithm will take O( n) O(log n) O( n log n) time. This is the best-case scenario. In the worst case, there are O( n) levels, so the algorithm will take O(n) O( n) O( n2) time. Well, guess what? Im here to tell you that the best case is also the average case. If you always choose a random element in the array as the pivot , quicksort will complete in O( n log n) time on average. Quicksort is one of the fastest sorting algorithms out there, and its a very good example of DC. 72 Chapter 4 I Quicksort EXERCISES How long would each of these operations take in Big O notation? 4.5 Printing the value of each element in an array. 4.6 Doubling the value of each element in an array. 4.7 Doubling the value of just the first element in an array. 4.8 Creating a multiplication table with all the elements in the array. So if your array is 2, 3, 7, 8, 10, you first multiply every element by 2, then multiply every element by 3, then by 7, and so on. Recap DC works by breaking a problem down into smaller and smaller pieces. If youre using DC on a list, the base case is probably an empty array or an array with one element. If youre implementing quicksort, choose a random element as the pivot. The average runtime of quicksort is O( n log n)! The constant in Big O notation can matter sometimes. Thats why quicksort is faster than merge sort. The constant almost never matters for simple search versus binary search, because O(log n) is so much faster than O( n) when your list gets big. 73In this chapter You learn about hash tables, one of the most useful basic data structures. Hash tables have many uses; this chapter covers the common use cases. You learn about the internals of hash tables: implementation, collisions, and hash functions. This will help you understand how to analyze a hash tables performance. hash tables 5 Suppose you work at a grocery store. When a customer buys produce, you have to look up the price in a book. If the book is unalphabetized, it can take you a long time to look through every single line for apple . Y ou d be doing simple search from chapter 1, where you have to look at every line. Do you remember how long that would take? O(n) time. If the book is alphabetized, you could run binary search to find the price of an apple. That would only take O(log n) time. 74 Chapter 5 I Hash tables As a reminder, theres a big difference between O( n) and O(log n) time! Suppose you could look through 10 lines of the book per second. Heres how long simple search and binary search would take you. Y ou already know that binary search is darn fast. But as a cashier, looking things up in a book is a pain, even if the book is sorted. Y ou can feel the customer steaming up as you search for items in the book. What you really need is a buddy who has all the names and prices memorized. Then you dont need to look up anything: you ask her, and she tells you the answer instantly. 75 Hash tables Y our buddy Maggie can give you the price in O(1) time for any item, no matter how big the book is. Shes even faster than binary search. What a wonderful person! How do you get a Maggie? Lets put on our data structure hats. Y ou know two data structures so far: arrays and lists (I wont talk about stacks because you cant really search for something in a stack). Y ou could implement this book as an array. Each item in the array is really two items: one is the name of a kind of produce, and the other is the price. If you sort this array by name, you can run binary search on it to find the price of an item. So you can find items in O(log n) time. But you want to find items in O(1) time. That is, you want to make a Maggie. Thats where hash functions come in. 76 Chapter 5 I Hash tables Hash functions A hash function is a function where you put in a string1 and you get back a number. In technical terminology, we d say that a hash function maps strings to numbers. Y ou might think theres no discernable pattern to what number you get out when you put a string in. But there are some requirements for a hash function: It needs to be consistent. For example, suppose you put in apple and get back 4 . Every time you put in apple , you should get 4 back. Without this, your hash table wont work. It should map different words to different numbers. For example, a hash function is no good if it always returns 1 for any word you put in. In the best case, every different word should map to a different number. So a hash function maps strings to numbers. What is that good for? Well, you can use it to make your Maggie! Start with an empty array: Y oull store all of your prices in this array. Lets add the price of an apple. Feed apple into the hash function. 1 String here means any kind of dataa sequence of bytes. 77 Hash functions The hash function outputs 3 . So lets store the price of an apple at index 3 in the array. Lets add milk. Feed milk into the hash function. The hash function says 0 . Lets store the price of milk at index 0. Keep going, and eventually the whole array will be full of prices. Now you ask, Hey, whats the price of an avocado? Y ou dont need to search for it in the array. Just feed avocado into the hash function. It tells you that the price is stored at index 4. And sure enough, there it is. 78 Chapter 5 I Hash tables The hash function tells you exactly where the price is stored, so you dont have to search at all! This works because The hash function consistently maps a name to the same index. Every time you put in avocado , youll get the same number back. So you can use it the first time to find where to store the price of an avocado, and then you can use it to find where you stored that price. The hash function maps different strings to different indexes. Avocado maps to index 4. Milk maps to index 0. Everything maps to a different slot in the array where you can store its price. The hash function knows how big your array is and only returns valid indexes. So if your array is 5 items, the hash function doesnt return 100 that wouldnt be a valid index in the array. Y ou just built a Maggie! Put a hash function and an array together, and you get a data structure called a hash table . A hash table is the first data structure youll learn that has some extra logic behind it. Arrays and lists map straight to memory, but hash tables are smarter. They use a hash function to intelligently figure out where to store elements. Hash tables are probably the most useful complex data structure youll learn. Theyre also known as hash maps, maps, dictionaries, and associative arrays. And hash tables are fast! Remember our discussion of arrays and linked lists back in chapter 2? Y ou can get an item from an array",
      "source": "Grokking Algorithms - Chapter 8",
      "timestamp": "2025-11-14T00:38:40.764194",
      "type": "book_content",
      "book_title": "Grokking Algorithms",
      "chapter_title": "Chapter 8",
      "chapter_number": 8
    },
    {
      "text": "instantly. And hash tables use an array to store the data, so theyre equally fast. Y oull probably never have to implement hash tables yourself. Any good language will have an implementation for hash tables. Python has hash tables; theyre called dictionaries . Y ou can make a new hash table using the dict function: book dict() book is a new hash table. Lets add some prices to book : bookapple 0.67 An apple costs 67 cents. bookmilk 1.49 Milk costs 1.49. bookavocado 1.49 print book avocado: 1.49, apple: 0.67, milk: 1.49 79 Use cases Pretty easy! Now lets ask for the price of an avocado: print bookavocado 1.49 The price of an avocado A hash table has keys and values. In the book hash, the names of produce are the keys, and their prices are the values. A hash table maps keys to values. In the next section, youll see some examples where hash tables are really useful. EXERCISES Its important for hash functions to consistently return the same output for the same input. If they dont, you wont be able to find your item after you put it in the hash table! Which of these hash functions are consistent? 5.1 f(x) 1 Returns 1 for all input 5.2 f(x) rand() Returns a random number every time 5.3 f(x) next_empty_slot() 5.4 f(x) len(x) Use cases Hash tables are used everywhere. This section will show you a few use cases. Using hash tables for lookups Y our phone has a handy phonebook built in. Each name has a phone number associated with it. Returns the index of the next empty slot in the hash table Uses the length of the string as the index 80 Chapter 5 I Hash tables Suppose you want to build a phone book like this. Y oure mapping peoples names to phone numbers. Y our phone book needs to have this functionality: Add a persons name and the phone number associated with that person. Enter a persons name, and get the phone number associated with that name. This is a perfect use case for hash tables! Hash tables are great when you want to Create a mapping from one thing to another thing Look something up Building a phone book is pretty easy. First, make a new hash table: phone_book dict() By the way, Python has a shortcut for making a new hash table. Y ou can use two curly braces: phone_book Same as phone_book dict() Lets add the phone numbers of some people into this phone book: phone_bookjenny 8675309 phone_bookemergency 911 Thats all there is to it! Now, suppose you want to find Jennys phone number. Just pass the key in to the hash: print phone_bookjenny 8675309 Jennys phone number Imagine if you had to do this using an array instead. How would you do it? Hash tables make it easy to model a relationship from one item to another. Hash tables are used for lookups on a much larger scale. For example, suppose you go to a website like http:adit.io. Y our computer has to translate adit.io to an IP address. 81 Use cases For any website you go to, the address has to be translated to an IP address. Wow, mapping a web address to an IP address? Sounds like a perfect use case for hash tables! This process is called DNS resolution . Hash tables are one way to provide this functionality. Preventing duplicate entries Suppose youre running a voting booth. Naturally, every person can vote just once. How do you make sure they havent voted before? When someone comes in to vote, you ask for their full name. Then you check it against the list of people who have voted. If their name is on the list, this person has already votedkick them out! Otherwise, you add their name to the list and let them vote. Now suppose a lot of people have come in to vote, and the list of people who have voted is really long. 82 Chapter 5 I Hash tables Each time someone new comes in to vote, you have to scan this giant list to see if theyve already voted. But theres a better way: use a hash! First, make a hash to keep track of the people who have voted: voted When someone new comes in to vote, check if theyre already in the hash: value voted.get(tom) The get function returns the value if tom is in the hash table. Otherwise, it returns None . Y ou can use this to check if someone has already voted! Heres the code: voted def check_voter(name): if voted.get(name): print kick them out! else: votedname True print let them vote! Lets test it a few times: check_voter(tom) let them vote! check_voter(mike) let them vote! check_voter(mike) kick them out! The first time Tom goes in, this will print, let them vote! Then Mike goes in, and it prints, let them vote! Then Mike tries to go a second time, and it prints, kick them out! 83 Use cases Remember, if you were storing these names in a list of people who have voted, this function would eventually become really slow, because it would have to run a simple search over the entire list. But youre storing their names in a hash table instead, and a hash table instantly tells you whether this persons name is in the hash table or not. Checking for duplicates is very fast with a hash table. Using hash tables as a cache One final use case: caching. If you work on a website, you may have heard of caching before as a good thing to do. Heres the idea. Suppose you visit facebook.com: 1. Y ou make a request to Facebooks server. 2. The server thinks for a second and comes up with the web page to send to you. 3. Y ou get a web page. For example, on Facebook, the server may be collecting all of your friends activity to show you. It takes a couple of seconds to collect all that activity and shows it to you. That couple of seconds can feel like a long time as a user. Y ou might think, Why is Facebook being so slow? On the other hand, Facebooks servers have to serve millions of people, and that couple of seconds adds up for them. Facebooks servers are really working hard to serve all of those websites. Is there a way to make Facebook faster and have its servers do less work at the same time? Suppose you have a niece who keeps asking you about planets. How far is Mars from Earth? How far is the Moon? How far is Jupiter? Each time, you have to do a Google search and give her an answer. It takes 84 Chapter 5 I Hash tables a couple of minutes. Now, suppose she always asked, How far is the Moon? Pretty soon, you d memorize that the Moon is 238,900 miles away. Y ou wouldnt have to look it up on Google you d just remember and answer. This is how caching works: websites remember the data instead of recalculating it. If youre logged in to Facebook, all the content you see is tailored just for you. Each time you go to facebook.com, its servers have to think about what content youre interested in. But if youre not logged in to Facebook, you see the login page. Everyone sees the same login page. Facebook is asked the same thing over and over: Give me the home page when Im logged out. So it stops making the server do work to figure out what the home page looks like. Instead, it memorizes what the home page looks like and sends it to you. This is called caching . It has two advantages: Y ou get the web page a lot faster, just like when you memorized the distance from Earth to the Moon. The next time your niece asks you, you wont have to Google it. Y ou can answer instantly. Facebook has to do less work. Caching is a common way to make things faster. All big websites use caching. And that data is cached in a hash! 85 Use cases Facebook isnt just caching the home page. Its also caching the About page, the Contact page, the Terms and Conditions page, and a lot more. So it needs a mapping from page URL to page data. When you visit a page on Facebook, it first checks whether the page is stored in the hash. Here it is in code: cache def get_page(url): if cache.get(url): return cacheurl Returns cached data else: data get_data_from_server(url) cacheurl data Saves this data in your cache first return data Here, you make the server do work only if the URL isnt in the cache. Before you return the data, though, you save it in the cache. The next time someone requests this URL, you can send the data from the cache instead of making the server do the work. 86 Chapter 5 I Hash tables Recap To recap, hashes are good for Modeling relationships from one thing to another thing Filtering out duplicates Cachingmemorizing data instead of making your server do work Collisions Like I said earlier, most languages have hash tables. Y ou dont need to know how to write your own. So, I wont talk about the internals of hash tables too much. But you still care about performance! To understand the performance of hash tables, you first need to understand what collisions are. The next two sections cover collisions and performance. First, Ive been telling you a white lie. I told you that a hash function always maps different keys to different slots in the array. In reality, its almost impossible to write a hash function that does this. Lets take a simple example. Suppose your array contains 26 slots. And your hash function is really simple: it assigns a spot in the array alphabetically. 87 Collisions Maybe you can already see the problem. Y ou want to put the price of apples in your hash. Y ou get assigned the first slot. Then you want to put the price of bananas in the hash. Y ou get assigned the second slot. Everything is going so well! But now you want to put the price of avocados in your hash. Y ou get assigned the first slot again. Oh no! Apples have that slot already! What to do? This is called a collision : two keys have been assigned the same slot. This is a problem. If you store the price of avocados at that slot, youll overwrite the price of apples. Then the next time someone asks for the price of apples, they will get the price of avocados instead! Collisions are bad, and you need to work around them. There are many different ways to deal with collisions. The simplest one is this: if multiple keys map to the same slot, start a linked list at that slot. 88 Chapter 5 I Hash tables In this example, both apple and avocado map to the same slot. So you start a linked list at that slot. If you need to know the price of bananas, its still quick. If you need to know the price of apples, its a little slower. Y ou have to search through this linked list to find apple . If the linked list is small, no big dealyou have to search through three or four elements. But suppose you work at a grocery store where you only sell produce that starts with the letter A. Hey, wait a minute! The entire hash table is totally empty except for one slot. And that slot has a giant linked list! Every single element in this hash table is in the linked list. Thats as bad as putting everything in a linked list to begin with. Its going to slow down your hash table. There are",
      "source": "Grokking Algorithms - Chapter 9: Array",
      "timestamp": "2025-11-14T00:38:40.764194",
      "type": "book_content",
      "book_title": "Grokking Algorithms",
      "chapter_title": "Chapter 9: Array",
      "chapter_number": 9
    },
    {
      "text": "two lessons here: Your hash function is really important. Y our hash function mapped all the keys to a single slot. Ideally, your hash function would map keys evenly all over the hash. If those linked lists get long, it slows down your hash table a lot. But they wont get long if you use a good hash function ! Hash functions are important. A good hash function will give you very few collisions. So how do you pick a good hash function? Thats coming up in the next section! Performance You started this chapter at the grocery store. Y ou wanted to build something that would give you the prices for produce instantly . Well, hash tables are really fast. In the average case, hash tables take O(1) for everything. O(1) is called constant time . Y ou havent seen constant time before. It doesnt mean 89 Performance instant. It means the time taken will stay the same, regardless of how big the hash table is. For example, you know that simple search takes linear time. Binary search is fasterit takes log time: Looking something up in a hash table takes constant time. See how its a flat line? That means it doesnt matter whether your hash table has 1 element or 1 billion elementsgetting something out of a hash table will take the same amount of time. Actually, youve seen constant time before. Getting an item out of an array takes constant time. It doesnt matter how big your array is; it takes the same amount of time to get an element. In the average case, hash tables are really fast. 90 Chapter 5 I Hash tables In the worst case, a hash table takes O( n)linear timefor everything, which is really slow. Lets compare hash tables to arrays and lists. Look at the average case for hash tables. Hash tables are as fast as arrays at searching (getting a value at an index). And theyre as fast as linked lists at inserts and deletes. Its the best of both worlds! But in the worst case, hash tables are slow at all of those. So its important that you dont hit worst-case performance with hash tables. And to do that, you need to avoid collisions. To avoid collisions, you need A low load factor A good hash function Load factor The load factor of a hash table is easy to calculate. Hash tables use an array for storage, so you count the number of occupied slots in an array. For example, this hash table has a load factor of 25, or 0.4. Note Before you start this next section, know that this isnt required reading. Im going to talk about how to implement a hash table, but youll never have to do that yourself. Whatever programming language you use will have an implementation of hash tables built in. You can use the built-in hash table and assume it will have good performance. The next section gives you a peek under the hood. 91 Performance Whats the load factor of this hash table? If you said 13, youre right. Load factor measures how many empty slots remain in your hash table. Suppose you need to store the price of 100 produce items in your hash table, and your hash table has 100 slots. In the best case, each item will get its own slot. This hash table has a load factor of 1. What if your hash table has only 50 slots? Then it has a load factor of 2. Theres no way each item will get its own slot, because there arent enough slots! Having a load factor greater than 1 means you have more items than slots in your array. Once the load factor starts to grow, you need to add more slots to your hash table. This is called resizing . For example, suppose you have this hash table that is getting pretty full. Y ou need to resize this hash table. First you create a new array thats bigger. The rule of thumb is to make an array that is twice the size. 92 Chapter 5 I Hash tables Now you need to re-insert all of those items into this new hash table using the hash function: This new table has a load factor of 38. Much better! With a lower load factor, youll have fewer collisions, and your table will perform better. A good rule of thumb is, resize when your load factor is greater than 0.7. Y ou might be thinking, This resizing business takes a lot of time! And youre right. Resizing is expensive, and you dont want to resize too often. But averaged out, hash tables take O(1) even with resizing. A good hash function A good hash function distributes values in the array evenly. A bad hash function groups values together and produces a lot of collisions. What is a good hash function? Thats something youll never have to worry aboutold men (and women) with big beards sit in dark rooms and worry about that. If youre really curious, look up the SHA function (theres a short description of it in the last chapter). Y ou could use that as your hash function. 93 Recap EXERCISES Its important for hash functions to have a good distribution. They should map items as broadly as possible. The worst case is a hash function that maps all items to the same slot in the hash table. Suppose you have these four hash functions that work with strings: a. Return 1 for all input. b. Use the length of the string as the index. c. Use the first character of the string as the index. So, all strings starting with a are hashed together, and so on. d. Map every letter to a prime number: a 2, b 3, c 5, d 7, e 11, and so on. For a string, the hash function is the sum of all the characters modulo the size of the hash. For example, if your hash size is 10, and the string is bag , the index is 3 2 17 10 22 10 2. For each of these examples, which hash functions would provide a good distribution? Assume a hash table size of 10 slots. 5.5 A phonebook where the keys are names and values are phone numbers. The names are as follows: Esther, Ben, Bob, and Dan. 5.6 A mapping from battery size to power. The sizes are A, AA, AAA, and AAAA. 5.7 A mapping from book titles to authors. The titles are Maus , Fun Home , and Watchmen . Recap Y oull almost never have to implement a hash table yourself. The programming language you use should provide an implementation for you. Y ou can use Pythons hash tables and assume that youll get the average case performance: constant time. Hash tables are a powerful data structure because theyre so fast and they let you model data in a different way. Y ou might soon find that youre using them all the time: 94 Chapter 5 I Hash tables Y ou can make a hash table by combining a hash function with an array. Collisions are bad. Y ou need a hash function that minimizes collisions. Hash tables have really fast search, insert, and delete. Hash tables are good for modeling relationships from one item to another item. Once your load factor is greater than .07, its time to resize your hash table. Hash tables are used for caching data (for example, with a web server). Hash tables are great for catching duplicates. 95In this chapter You learn how to model a network using a new, abstract data structure: graphs. You learn breadth-first search, an algorithm you can run on graphs to answer questions like, Whats the shortest path to go to X? You learn about directed versus undirected graphs. You learn topological sort, a different kind of sorting algorithm that exposes dependencies between nodes.6breadth-first search This chapter introduces graphs. First, Ill talk about what graphs are (they dont involve an X or Y axis). Then Ill show you your first graph algorithm. Its called breadth-first search (BFS). Breadth-first search allows you to find the shortest distance between two things. But shortest distance can mean a lot of things! Y ou can use breadth-first search to Write a checkers AI that calculates the fewest moves to victory 96 Chapter 6 I Breadth-first search Write a spell checker (fewest edits from your misspelling to a real wordfor example, READED - READER is one edit) Find the doctor closest to you in your network Graph algorithms are some of the most useful algorithms I know. Make sure you read the next few chapters carefullythese are algorithms youll be able to apply again and again. Introduction to graphs Suppose youre in San Francisco, and you want to go from Twin Peaks to the Golden Gate Bridge. Y ou want to get there by bus, with the minimum number of transfers. Here are your options. 97 Introduction to graphs Whats your algorithm to find the path with the fewest steps? Well, can you get there in one step? Here are all the places you can get to in one step. The bridge isnt highlighted; you cant get there in one step. Can you get there in two steps? Again, the bridge isnt there, so you cant get to the bridge in two steps. What about three steps? 98 Chapter 6 I Breadth-first search Aha! Now the Golden Gate Bridge shows up. So it takes three steps to get from Twin Peaks to the bridge using this route. There are other routes that will get you to the bridge too, but theyre longer (four steps). The algorithm found that the shortest route to the bridge is three steps long. This type of problem is called a shortest-path problem . Y oure always trying to find the shortest something. It could be the shortest route to your friends house. It could be the smallest number of moves to checkmate in a game of chess. The algorithm to solve a shortest-path problem is called breadth-first search . To figure out how to get from Twin Peaks to the Golden Gate Bridge, there are two steps: 1. Model the problem as a graph. 2. Solve the problem using breadth-first search. Next Ill cover what graphs are. Then Ill go into breadth-first search in more detail. What is a graph? A graph models a set of connections. For example, suppose you and your friends are playing poker, and you want to model who owes whom money. Heres how you could say, Alex owes Rama money. 99 Breadth-first search The full graph could look something like this. Alex owes Rama money, Tom owes Adit money, and so on. Each graph is made up of nodes and edges . Thats all there is to it! Graphs are made up of nodes and edges. A node can be directly connected to many other nodes. Those nodes are called its neighbors . In this graph, Rama is Alexs neighbor. Adit isnt Alexs neighbor, because they arent directly connected. But Adit is Ramas and Toms neighbor. Graphs are a way to model how different things are connected to one another. Now lets see breadth-first search in action. Breadth-first search We looked at a search algorithm in chapter 1: binary search. Breadth- first search is a different kind of search algorithm: one that runs on graphs. It can help answer two types of questions: Question type 1: Is there a path from node A to node B? Question type 2: What is the shortest path from node A to node B? Graph of people who owe other people poker money 100 Chapter 6 I Breadth-first search Y ou already saw breadth-first search once, when you calculated the shortest route from Twin Peaks to the Golden Gate Bridge. That was a question of type 2: What is the shortest",
      "source": "Grokking Algorithms - Chapter 10",
      "timestamp": "2025-11-14T00:38:40.764194",
      "type": "book_content",
      "book_title": "Grokking Algorithms",
      "chapter_title": "Chapter 10",
      "chapter_number": 10
    },
    {
      "text": "path? Now lets look at the algorithm in more detail. Y oull ask a question of type 1: Is there a path? Suppose youre the proud owner of a mango farm. Y oure looking for a mango seller who can sell your mangoes. Are you connected to a mango seller on Facebook? Well, you can search through your friends. This search is pretty straightforward. First, make a list of friends to search. 101 Breadth-first search Now, go to each person in the list and check whether that person sells mangoes. Suppose none of your friends are mango sellers. Now you have to search through your friends friends. Each time you search for someone from the list, add all of their friends to the list. 102 Chapter 6 I Breadth-first search This way, you not only search your friends, but you search their friends, too. Remember, the goal is to find one mango seller in your network. So if Alice isnt a mango seller, you add her friends to the list, too. That means youll eventually search her friendsand then their friends, and so on. With this algorithm, youll search your entire network until you come across a mango seller. This algorithm is breadth-first search. Finding the shortest path As a recap, these are the two questions that breadth-first search can answer for you: Question type 1: Is there a path from node A to node B? (Is there a mango seller in your network?) Question type 2: What is the shortest path from node A to node B? (Who is the closest mango seller?) Y ou saw how to answer question 1; now lets try to answer question 2. Can you find the closest mango seller? For example, your friends are first-degree connections, and their friends are second-degree connections. 103 Breadth-first search Y ou d prefer a first-degree connection to a second-degree connection, and a second-degree connection to a third-degree connection, and so on. So you shouldnt search any second-degree connections before you make sure you dont have a first-degree connection who is a mango seller. Well, breadth-first search already does this! The way breadth-first search works, the search radiates out from the starting point. So youll check first-degree connections before second-degree connections. Pop quiz: who will be checked first, Claire or Anuj? Answer: Claire is a first- degree connection, and Anuj is a second-degree connection. So Claire will be checked before Anuj. Another way to see this is, first-degree connections are added to the search list before second-degree connections. Y ou just go down the list and check people to see whether each one is a mango seller. The first-degree connections will be searched before the second- degree connections, so youll find the mango seller closest to you. Breadth-first search not only finds a path from A to B, it also finds the shortest path. Notice that this only works if you search people in the same order in which theyre added. That is, if Claire was added to the list before Anuj, Claire needs to be searched before Anuj. What happens if you search Anuj before Claire, and theyre both mango sellers? Well, Anuj is a second-degree contact, and Claire is a first-degree contact. Y ou end up with a mango seller who isnt the closest to you in your network. So you need to search people in the order that theyre added. Theres a data structure for this: its called a queue . Queues A queue works exactly like it does in real life. Suppose you and your friend are queueing up at the bus stop. If youre before him in the queue, you get on the bus first. A queue works the same way. Queues are similar to stacks. Y ou cant access random elements in the queue. Instead, there are two only operations, enqueue and dequeue . 104 Chapter 6 I Breadth-first search If you enqueue two items to the list, the first item you added will be dequeued before the second item. Y ou can use this for your search list! People who are added to the list first will be dequeued and searched first. The queue is called a FIFO data structure: First In, First Out. In contrast, a stack is a LIFO data structure: Last In, First Out. Now that you know how a queue works, lets implement breadth-first search! EXERCISES Run the breadth-first search algorithm on each of these graphs to find the solution. 6.1 Find the length of the shortest path from start to finish. 6.2 Find the length of the shortest path from cab to bat . 105 Implementing the graph Implementing the graph First, you need to implement the graph in code. A graph consists of several nodes. And each node is connected to neighboring nodes. How do you express a relationship like you - bob? Luckily, you know a data structure that lets you express relationships: a hash table ! Remember, a hash table allows you to map a key to a value. In this case, you want to map a node to all of its neighbors. Heres how you d write it in Python: graph graphyou alice, bob, claire Notice that you is mapped to an array. So graphyou will give you an array of all the neighbors of you . A graph is just a bunch of nodes and edges, so this is all you need to have a graph in Python. What about a bigger graph, like this one? 106 Chapter 6 I Breadth-first search Here it is as Python code: graph graphyou alice, bob, claire graphbob anuj, peggy graphalice peggy graphclaire thom, jonny graphanuj graphpeggy graphthom graphjonny Pop quiz: does it matter what order you add the keyvalue pairs in? Does it matter if you write graphclaire thom, jonny graphanuj instead of graphanuj graphclaire thom, jonny Think back to the previous chapter. Answer: It doesnt matter. Hash tables have no ordering, so it doesnt matter what order you add keyvalue pairs in. Anuj, Peggy, Thom, and Jonny dont have any neighbors. They have arrows pointing to them, but no arrows from them to someone else. This is called a directed graph the relationship is only one way. So Anuj is Bobs neighbor, but Bob isnt Anujs neighbor. An undirected graph doesnt have any arrows, and both nodes are each others neighbors. For example, both of these graphs are equal. 107 Implementing the algorithm Implementing the algorithm To recap, heres how the implementation will work. Make a queue to start. In Python, you use the double-ended queue (deque ) function for this: from collections import deque search_queue deque() search_queue graphyou Remember, graph you will give you a list of all your neighbors, like alice, bob, claire . Those all get added to the search queue. Creates a new queue Adds all of your neighbors to the search queue Note When updating queues, I use the terms enqueue and dequeue . Youll also encoun - ter the terms push and pop. Push is almost always the same thing as enqueue , and pop is almost always the same thing as dequeue . 108 Chapter 6 I Breadth-first search Lets see the rest: while search_queue: person search_queue.popleft() if person_is_seller(person): print person is a mango seller! return True else: search_queue graphperson return False One final thing: you still need a person_is_seller function to tell you when someone is a mango seller. Heres one: def person_is_seller(name): return name-1 m This function checks whether the persons name ends with the letter m. If it does, theyre a mango seller. Kind of a silly way to do it, but itll do for this example. Now lets see the breadth-first search in action. While the queue isnt empty grabs the first person off the queue Checks whether the person is a mango seller Yes, theyre a mango seller. No, they arent. Add all of this persons friends to the search queue. If you reached here, no one in the queue was a mango seller. 109 Implementing the algorithm And so on. The algorithm will keep going until either A mango seller is found, or The queue becomes empty, in which case there is no mango seller. Alice and Bob share a friend: Peggy. So Peggy will be added to the queue twice: once when you add Alices friends, and again when you add Bobs friends. Y oull end up with two Peggys in the search queue. But you only need to check Peggy once to see whether shes a mango seller. If you check her twice, youre doing unnecessary, extra work. So once you search a person, you should mark that person as searched and not search them again. If you dont do this, you could also end up in an infinite loop. Suppose the mango seller graph looked like this. To start, the search queue contains all of your neighbors. Now you check Peggy. She isnt a mango seller, so you add all of her neighbors to the search queue. 110 Chapter 6 I Breadth-first search Next, you check yourself. Y oure not a mango seller, so you add all of your neighbors to the search queue. And so on. This will be an infinite loop, because the search queue will keep going from you to Peggy. Before checking a person, its important to make sure they havent been checked already. To do that, youll keep a list of people youve already checked. Heres the final code for breadth-first search, taking that into account: def search(name): search_queue deque() search_queue graphname searched while search_queue: person search_queue.popleft() if not person in searched: if person_is_seller(person): print person is a mango seller! return True else: search_queue graphperson searched.append(person) return False search(you) This array is how you keep track of which people youve searched before. Only search this person if you havent already searched them. Marks this person as searched 111 Implementing the algorithm Try running this code yourself. Maybe try changing the person_is_ seller function to something more meaningful, and see if it prints what you expect. Running time If you search your entire network for a mango seller, that means youll follow each edge (remember, an edge is the arrow or connection from one person to another). So the running time is at least O(number of edges). Y ou also keep a queue of every person to search. Adding one person to the queue takes constant time: O(1). Doing this for every person will take O(number of people) total. Breadth-first search takes O(number of people number of edges), and its more commonly written as O(VE) (V for number of vertices, E for number of edges). EXERCISE Heres a small graph of my morning routine. It tells you that I cant eat breakfast until Ive brushed my teeth. So eat breakfast depends on brush teeth . On the other hand, showering doesnt depend on brushing my teeth, because I can shower before I brush my teeth. From this graph, you can make a list of the order in which I need to do my morning routine: 1. Wake up. 2. Shower. 3. Brush teeth. 4. Eat breakfast. 112 Chapter 6 I Breadth-first search Note that shower can be moved around, so this list is also valid: 1. Wake up. 2. Brush teeth. 3. Shower. 4. Eat breakfast. 6.3 For these three lists, mark whether each one is valid or invalid. 6.4 Heres a larger graph. Make a valid list for this graph. Y ou could say that this list is sorted, in a way. If task A depends on task B, task A shows up later in the list. This is called a topological sort , and its a way to make an ordered list out of a graph. Suppose youre planning a wedding and have a large graph full of tasks to doand youre not sure where to start. Y ou could topologically sort the graph and get a list of tasks to do, in order. 113 Implementing the algorithm Suppose you have",
      "source": "Grokking Algorithms - Chapter 11: Algorithm",
      "timestamp": "2025-11-14T00:38:40.764194",
      "type": "book_content",
      "book_title": "Grokking Algorithms",
      "chapter_title": "Chapter 11: Algorithm",
      "chapter_number": 11
    },
    {
      "text": "a family tree. This is a graph, because you have nodes (the people) and edges. The edges point to the nodes parents. But all the edges go downit wouldnt make sense for a family tree to have an edge pointing back up! That would be meaninglessyour dad cant be your grandfathers dad! This is called a tree. A tree is a special type of graph, where no edges ever point back. 6.5 Which of the following graphs are also trees? 114 Chapter 6 I Breadth-first search Recap Breadth-first search tells you if theres a path from A to B. If theres a path, breadth-first search will find the shortest path. If you have a problem like find the shortest X, try modeling your problem as a graph, and use breadth-first search to solve. A directed graph has arrows, and the relationship follows the direction of the arrow (rama - adit means rama owes adit money). Undirected graphs dont have arrows, and the relationship goes both ways (ross - rachel means ross dated rachel and rachel dated ross). Queues are FIFO (First In, First Out). Stacks are LIFO (Last In, First Out). Y ou need to check people in the order they were added to the search list, so the search list needs to be a queue. Otherwise, you wont get the shortest path. Once you check someone, make sure you dont check them again. Otherwise, you might end up in an infinite loop. 115In this chapter We continue the discussion of graphs, and you learn about weighted graphs: a way to assign more or less weight to some edges. You learn Dijkstras algorithm, which lets you answer Whats the shortest path to X? for weighted graphs. You learn about cycles in graphs, where Dijkstras algorithm doesnt work.7Dijkstras algorithm 116 Chapter 7 I Dijkstras algorithm In the last chapter, you figured out a way to get from point A to point B. Its not necessarily the fastest path. Its the shortest path, because it has the least number of segments (three segments). But suppose you add travel times to those segments. Now you see that theres a faster path. Y ou used breadth-first search in the last chapter. Breadth-first search will find you the path with the fewest segments (the first graph shown here). What if you want the fastest path instead (the second graph)? Y ou can do that fastest with a different algorithm called Dijkstras algorithm. Working with Dijkstras algorithm Lets see how it works with this graph. Each segment has a travel time in minutes. Y oull use Dijkstras algorithm to go from start to finish in the shortest possible time. 117 Working with Dijkstras algorithm If you ran breadth-first search on this graph, you d get this shortest path. But that path takes 7 minutes. Lets see if you can find a path that takes less time! There are four steps to Dijkstras algorithm: 1. Find the cheapest node. This is the node you can get to in the least amount of time. 2. Update the costs of the neighbors of this node. Ill explain what I mean by this shortly. 3. Repeat until youve done this for every node in the graph. 4. Calculate the final path. Step 1: Find the cheapest node. Y oure standing at the start, wondering if you should go to node A or node B. How long does it take to get to each node? It takes 6 minutes to get to node A and 2 minutes to get to node B. The rest of the nodes, you dont know yet. Because you dont know how long it takes to get to the finish yet, you put down infinity (youll see why soon). Node B is the closest node its 2 minutes away. 118 Chapter 7 I Dijkstras algorithm Step 2: Calculate how long it takes to get to all of node Bs neighbors by following an edge from B. Hey, you just found a shorter path to node A! It used to take 6 minutes to get to node A. But if you go through node B, theres a path that only takes 5 minutes! When you find a shorter path for a neighbor of B, update its cost. In this case, you found A shorter path to A (down from 6 minutes to 5 minutes) A shorter path to the finish (down from infinity to 7 minutes) Step 3: Repeat! Step 1 again: Find the node that takes the least amount of time to get to. Y oure done with node B, so node A has the next smallest time estimate. 119 Working with Dijkstras algorithm Step 2 again: Update the costs for node A s neighbors. Woo, it takes 6 minutes to get to the finish now! Y ouve run Dijkstras algorithm for every node (you dont need to run it for the finish node). At this point, you know It takes 2 minutes to get to node B. It takes 5 minutes to get to node A. It takes 6 minutes to get to the finish. Ill save the last step, calculating the final path, for the next section. For now, Ill just show you what the final path is. Breadth-first search wouldnt have found this as the shortest path, because it has three segments. And theres a way to get from the start to the finish in two segments. 120 Chapter 7 I Dijkstras algorithm In the last chapter, you used breadth-first search to find the shortest path between two points. Back then, shortest path meant the path with the fewest segments. But in Dijkstras algorithm, you assign a number or weight to each segment. Then Dijkstras algorithm finds the path with the smallest total weight. To recap, Dijkstras algorithm has four steps: 1. Find the cheapest node. This is the node you can get to in the least amount of time. 2. Check whether theres a cheaper path to the neighbors of this node. If so, update their costs. 3. Repeat until youve done this for every node in the graph. 4. Calculate the final path. (Coming up in the next section!) Terminology I want to show you some more examples of Dijkstras algorithm in action. But first let me clarify some terminology. When you work with Dijkstras algorithm, each edge in the graph has a number associated with it. These are called weights. A graph with weights is called a weighted graph . A graph without weights is called an unweighted graph . 121 Terminology To calculate the shortest path in an unweighted graph, use breadth-first search . To calculate the shortest path in a weighted graph, use Dijkstras algorithm . Graphs can also have cycles . A cycle looks like this. It means you can start at a node, travel around, and end up at the same node. Suppose youre trying to find the shortest path in this graph that has a cycle. Would it make sense to follow the cycle? Well, you can use the path that avoids the cycle. Or you can follow the cycle. 122 Chapter 7 I Dijkstras algorithm Y ou end up at node A either way, but the cycle adds more weight. Y ou could even follow the cycle twice if you wanted. But every time you follow the cycle, youre just adding 8 to the total weight. So following the cycle will never give you the shortest path. Finally, remember our conversation about directed versus undirected graphs from chapter 6? An undirected graph means that both nodes point to each other. Thats a cycle! With an undirected graph, each edge adds another cycle. Dijkstras algorithm only works with directed acyclic graphs , called DAGs for short. Trading for a piano Enough terminology, lets look at another example! This is Rama. Rama is trying to trade a music book for a piano. 123 Trading for a piano Ill give you this poster for your book, says Alex. Its a poster of my favorite band, Destroyer. Or Ill give you this rare LP of Rick Astley for your book and 5 more. Ooh, Ive heard that LP has a really great song, says Amy. Ill trade you my guitar or drum set for the poster or the LP . Ive been meaning to get into guitar! exclaims Beethoven. Hey, Ill trade you my piano for either of Amys things. Perfect! With a little bit of money, Rama can trade his way from a piano book to a real piano. Now he just needs to figure out how to spend the least amount of money to make those trades. Lets graph out what hes been offered. In this graph, the nodes are all the items Rama can trade for. The weights on the edges are the amount of money he would have to pay to make the trade. So he can trade the poster for the guitar for 30, or trade the LP for the guitar for 15. How is Rama going to figure out the path from the book to the piano where he spends the least dough? Dijkstras algorithm to the rescue! Remember, Dijkstras algorithm has four steps. In this example, youll do all four steps, so youll calculate the final path at the end, too. Before you start, you need some setup. Make a table of the cost for each node. The cost of a node is how expensive it is to get to. 124 Chapter 7 I Dijkstras algorithm Y oull keep updating this table as the algorithm goes on. To calculate the final path, you also need a parent column on this table. Ill show you how this column works soon. Lets start the algorithm. Step 1: Find the cheapest node. In this case, the poster is the cheapest trade, at 0. Is there a cheaper way to trade for the poster? This is a really important point, so think about it. Can you see a series of trades that will get Rama the poster for less than 0? Read on when youre ready. Answer: No. Because the poster is the cheapest node Rama can get to, theres no way to make it any cheaper. Heres a different way to look at it. Suppose youre traveling from home to work. If you take the path toward the school, that takes 2 minutes. If you take the path toward the park, that takes 6 minutes. Is there any way you can take the path toward the park, and end up at the school, in less than 2 minutes? Its impossible, because it takes longer than 2 minutes just to get to the park. On the other hand, can you find a faster path to the park? Yup. 125 Trading for a piano This is the key idea behind Dijkstras algorithm: Look at the cheapest node on your graph. There is no cheaper way to get to this node! Back to the music example. The poster is the cheapest trade. Step 2: Figure out how long it takes to get to its neighbors (the cost). Y ou have prices for the bass guitar and the drum set in the table. Their value was set when you went through the poster, so the poster gets set as their parent. That means, to get to the bass guitar, you follow the edge from the poster, and the same for the drums. Step 1 again: The LP is the next cheapest node at 5. Step 2 again: Update the values of all of its neighbors. Hey, you updated the price of both the drums and the guitar! That means its cheaper to get to the drums and guitar by following the edge from the LP . So you set the LP as the new parent for both instruments. 126 Chapter 7 I Dijkstras algorithm The bass guitar is the next cheapest item. Update its neighbors. Ok, you finally have a price for the piano, by trading the guitar for",
      "source": "Grokking Algorithms - Chapter 12: Graph",
      "timestamp": "2025-11-14T00:38:40.764194",
      "type": "book_content",
      "book_title": "Grokking Algorithms",
      "chapter_title": "Chapter 12: Graph",
      "chapter_number": 12
    },
    {
      "text": "the piano. So you set the guitar as the parent. Finally, the last node, the drum set. Rama can get the piano even cheaper by trading the drum set for the piano instead. So the cheapest set of trades will cost Rama 35 . Now, as I promised, you need to figure out the path. So far, you know that the shortest path costs 35, but how do you figure out the path? To start with, look at the parent for piano . The piano has drums as its parent. That means Rama trades the drums for the piano. So you follow this edge. 127 Trading for a piano Lets see how you d follow the edges. Piano has drums as its parent. And drums has the LP as its parent. So Rama will trade the LP for the drums. And of course, hell trade the book for the LP . By following the parents backward, you now have the complete path. Heres the series of trades Rama needs to make. 128 Chapter 7 I Dijkstras algorithm So far, Ive been using the term shortest path pretty literally: calculating the shortest path between two locations or between two people. I hope this example showed you that the shortest path doesnt have to be about physical distance. It can be about minimizing something. In this case, Rama wanted to minimize the amount of money he spent. Thanks, Dijkstra! Negative-weight edges In the trading example, Alex offered to trade the book for two items. Suppose Sarah offers to trade the LP for the poster, and shell give Rama an additional 7. It doesnt cost Rama anything to make this trade; instead, he gets 7 back. How would you show this on the graph? The edge from the LP to the poster has a negative weight! Rama gets 7 back if he makes that trade. Now Rama has two ways to get to the poster. 129 Negative-weight edges So it makes sense to do the second tradeRama gets 2 back that way! Now, if you remember, Rama can trade the poster for the drums. There are two paths he could take. The second path costs him 2 less, so he should take that path, right? Well, guess what? If you run Dijkstras algorithm on this graph, Rama will take the wrong path. Hell take the longer path. You cant use Dijkstras algorithm if you have negative-weight edges. Negative-weight edges break the algorithm. Lets see what happens when you run Dijkstras algorithm on this. First, make the table of costs. Next, find the lowest-cost node, and update the costs for its neighbors. In this case, the poster is the lowest-cost node. So, according to Dijkstras algorithm, there is no cheaper way to get to the poster than paying 0 (you know thats wrong!). Anyway, lets update the costs for its neighbors. Ok, the drums have a cost of 35 now. 130 Chapter 7 I Dijkstras algorithm Lets get the next-cheapest node that hasnt already been processed. Update the costs for its neighbors. Y ou already processed the poster node, but youre updating the cost for it. This is a big red flag. Once you process a node, it means theres no cheaper way to get to that node. But you just found a cheaper way to the poster! Drums doesnt have any neighbors, so thats the end of the algorithm. Here are the final costs. It costs 35 to get to the drums. Y ou know that theres a path that costs only 33, but Dijkstras algorithm didnt find it. Dijkstras algorithm assumed that because you were processing the poster node, there was no faster way to get to that node. That assumption only works if you have no negative-weight edges. So you cant use negative-weight edges with Dijkstras algorithm. If you want to find the shortest path in a graph that has negative-weight edges, theres an algorithm for that! Its called the Bellman-Ford algorithm . Bellman-Ford is out of the scope of this book, but you can find some great explanations online. 131 Implementation Implementation Lets see how to implement Dijkstras algorithm in code. Heres the graph Ill use for the example. To code this example, youll need three hash tables. Y oull update the costs and parents hash tables as the algorithm progresses. First, you need to implement the graph. Y oull use a hash table like you did in chapter 6: graph In the last chapter, you stored all the neighbors of a node in the hash table, like this: graphyou alice, bob, claire But this time, you need to store the neighbors and the cost for getting to that neighbor. For example, Start has two neighbors, A and B. 132 Chapter 7 I Dijkstras algorithm How do you represent the weights of those edges? Why not just use another hash table? graphstart graphstarta 6 graphstartb 2 So graphstart is a hash table. Y ou can get all the neighbors for Start like this: print graphstart.keys() a, b Theres an edge from Start to A and an edge from Start to B. What if you want to find the weights of those edges? print graphstarta 2 print graphstartb 6 Lets add the rest of the nodes and their neighbors to the graph: grapha graphafin 1 graphb graphba 3 graphbfin 5 graphfin The finish node doesnt have any neighbors. 133 Implementation The full graph hash table looks like this. Next you need a hash table to store the costs for each node. The cost of a node is how long it takes to get to that node from the start. Y ou know it takes 2 minutes from Start to node B. Y ou know it takes 6 minutes to get to node A (although you may find a path that takes less time). Y ou dont know how long it takes to get to the finish. If you dont know the cost yet, you put down infinity. Can you represent infinity in Python? Turns out, you can: infinity float(inf) Heres the code to make the costs table: infinity float(inf) costs costsa 6 costsb 2 costsfin infinity Y ou also need another hash table for the parents: 134 Chapter 7 I Dijkstras algorithm Heres the code to make the hash table for the parents: parents parentsa start parentsb start parentsfin None Finally, you need an array to keep track of all the nodes youve already processed, because you dont need to process a node more than once: processed Thats all the setup. Now lets look at the algorithm. Ill show you the code first and then walk through it. Heres the code: node find_lowest_cost_node(costs) while node is not None: cost costsnode neighbors graphnode for n in neighbors.keys(): new_cost cost neighborsn if costsn new_cost: costsn new_cost parentsn node processed.append(node) node find_lowest_cost_node(costs) Thats Dijkstras algorithm in Python! Ill show you the code for the function later. First, lets see this find_lowest_cost_node algorithm code in action. Find the lowest-cost node that you havent processed yet. If youve processed all the nodes, this while loop is done. Go through all the neighbors of this node. If its cheaper to get to this neighbor by going through this node update the cost for this node. This node becomes the new parent for this neighbor. Mark the node as processed. Find the next node to process, and loop. 135 Implementation Find the node with the lowest cost. Get the cost and neighbors of that node. Loop through the neighbors. Each node has a cost. The cost is how long it takes to get to that node from the start. Here, youre calculating how long it would take to get to node A if you went Start node B node A, instead of Start node A. Lets compare those costs. 136 Chapter 7 I Dijkstras algorithm Y ou found a shorter path to node A! Update the cost. The new path goes through node B, so set B as the new parent. Ok, youre back at the top of the loop. The next neighbor for is the Finish node. How long does it take to get to the finish if you go through node B? It takes 7 minutes. The previous cost was infinity minutes, and 7 minutes is less than that. 137 Implementation Set the new cost and the new parent for the Finish node. Ok, you updated the costs for all the neighbors of node B. Mark it as processed. Find the next node to process. Get the cost and neighbors for node A. 138 Chapter 7 I Dijkstras algorithm Node A only has one neighbor: the Finish node. Currently it takes 7 minutes to get to the Finish node. How long would it take to get there if you went through node A? Its faster to get to Finish from node A! Lets update the cost and parent. 139 Implementation If its the lowest cost so far and hasnt been processed yet def find_lowest_cost_node(costs): lowest_cost float(inf) lowest_cost_node None for node in costs: Go through each node. cost costsnode if cost lowest_cost and node not in processed: lowest_cost cost set it as the new lowest-cost node. lowest_cost_node node return lowest_cost_nodeOnce youve processed all the nodes, the algorithm is over. I hope the walkthrough helped you understand the algorithm a little better. Finding the lowest-cost node is pretty easy with the find_lowest_ cost_node function. Here it is in code: EXERCISE 7.1 In each of these graphs, what is the weight of the shortest path from start to finish? 140 Chapter 7 I Dijkstras algorithm Recap Breadth-first search is used to calculate the shortest path for an unweighted graph. Dijkstras algorithm is used to calculate the shortest path for a weighted graph. Dijkstras algorithm works when all the weights are positive. If you have negative weights, use the Bellman-Ford algorithm. 141greedy algorithms In this chapter You learn how to tackle the impossible: problems that have no fast algorithmic solution (NP-complete problems). You learn how to identify such problems when you see them, so you dont waste time trying to find a fast algorithm for them. You learn about approximation algorithms, which you can use to find an approximate solution to an NP-complete problem quickly. You learn about the greedy strategy, a very simple problem-solving strategy. 8 142 Chapter 8 I Greedy algorithms The classroom scheduling problem Suppose you have a classroom and want to hold as many classes here as possible. Y ou get a list of classes. Y ou cant hold all of these classes in there, because some of them overlap. Y ou want to hold as many classes as possible in this classroom. How do you pick what set of classes to hold, so that you get the biggest set of classes possible? Sounds like a hard problem, right? Actually, the algorithm is so easy, it might surprise you. Heres how it works: 1. Pick the class that ends the soonest. This is the first class youll hold in this classroom. 2. Now, you have to pick a class that starts after the first class. Again, pick the class that ends the soonest. This is the second class youll hold. 143 The classroom scheduling problem Keep doing this, and youll end up with the answer! Lets try it out. Art ends the soonest, at 10:00 a.m., so thats one of the classes you pick. Now you need the next class that starts after 10:00 a.m. and ends the soonest. English is out because it conflicts with Art, but Math works. Finally, CS conflicts with Math, but Music works. So these are the three classes youll hold in this classroom. 144 Chapter 8 I Greedy algorithms A lot of people tell me that this algorithm seems easy. Its too obvious, so it must be wrong. But thats the beauty of greedy algorithms: theyre easy! A greedy algorithm is simple: at each step, pick the optimal move. In this case, each time you pick a class, you pick",
      "source": "Grokking Algorithms - Chapter 13",
      "timestamp": "2025-11-14T00:38:40.764194",
      "type": "book_content",
      "book_title": "Grokking Algorithms",
      "chapter_title": "Chapter 13",
      "chapter_number": 13
    },
    {
      "text": "the class that ends the soonest. In technical terms: at each step you pick the locally optimal solution , and in the end youre left with the globally optimal solution. Believe it or not, this simple algorithm finds the optimal solution to this scheduling problem! Obviously, greedy algorithms dont always work. But theyre simple to write! Lets look at another example. The knapsack problem Suppose youre a greedy thief. Y oure in a store with a knapsack, and there are all these items you can steal. But you can only take what you can fit in your knapsack. The knapsack can hold 35 pounds. Y oure trying to maximize the value of the items you put in your knapsack. What algorithm do you use? Again, the greedy strategy is pretty simple: 1. Pick the most expensive thing that will fit in your knapsack. 2. Pick the next most expensive thing that will fit in your knapsack. And so on. Except this time, it doesnt work! For example, suppose there are three items you can steal. 145 The knapsack problem Y our knapsack can hold 35 pounds of items. The stereo system is the most expensive, so you steal that. Now you dont have space for anything else. Y ou got 3,000 worth of goods. But wait! If you d picked the laptop and the guitar instead, you could have had 3,500 worth of loot! Clearly, the greedy strategy doesnt give you the optimal solution here. But it gets you pretty close. In the next chapter, Ill explain how to calculate the correct solution. But if youre a thief in a shopping center, you dont care about perfect. Pretty good is good enough. Heres the takeaway from this second example: sometimes, perfect is the enemy of good. Sometimes all you need is an algorithm that solves the problem pretty well. And thats where greedy algorithms shine, because theyre simple to write and usually get pretty close. EXERCISES 8.1 You work for a furniture company, and you have to ship furniture all over the country. Y ou need to pack your truck with boxes. All the boxes are of different sizes, and youre trying to maximize the space you use in each truck. How would you pick boxes to maximize space? Come up with a greedy strategy. Will that give you the optimal solution? 8.2 Y oure going to Europe, and you have seven days to see everything you can. Y ou assign a point value to each item (how much you want 146 Chapter 8 I Greedy algorithms to see it) and estimate how long it takes. How can you maximize the point total (seeing all the things you really want to see) during your stay? Come up with a greedy strategy. Will that give you the optimal solution? Lets look at one last example. This is an example where greedy algorithms are absolutely necessary. The set-covering problem Suppose youre starting a radio show. Y ou want to reach listeners in all 50 states. Y ou have to decide what stations to play on to reach all those listeners. It costs money to be on each station, so youre trying to minimize the number of stations you play on. Y ou have a list of stations. Each station covers a region, and theres overlap. How do you figure out the smallest set of stations you can play on to cover all 50 states? Sounds easy, doesnt it? Turns out its extremely hard. Heres how to do it: 1. List every possible subset of stations. This is called the power set . There are 2n possible subsets. 147 The set-covering problem 2. From these, pick the set with the smallest number of stations that covers all 50 states. The problem is, it takes a long time to calculate every possible subset of stations. It takes O(2 n) time, because there are 2 n stations. Its possible to do if you have a small set of 5 to 10 stations. But with all the examples here, think about what will happen if you have a lot of items. It takes much longer if you have more stations. Suppose you can calculate 10 subsets per second. Theres no algorithm that solves it fast enough! What can you do? Approximation algorithms Greedy algorithms to the rescue! Heres a greedy algorithm that comes pretty close: 1. Pick the station that covers the most states that havent been covered yet. Its OK if the station covers some states that have been covered already. 2. Repeat until all the states are covered. This is called an approximation algorithm. When calculating the exact solution will take too much time, an approximation algorithm will work. Approximation algorithms are judged by How fast they are How close they are to the optimal solution Greedy algorithms are a good choice because not only are they simple to come up with, but that simplicity means they usually run fast, too. In this case, the greedy algorithm runs in O( n2) time, where n is the number of radio stations. 148 Chapter 8 I Greedy algorithms Lets see how this problem looks in code. Code for setup For this example, Im going to use a subset of the states and the stations to keep things simple. First, make a list of the states you want to cover: states_needed set(mt, wa, or, id, nv, ut, ca, az) You pass an array in, and it gets converted to a set. I used a set for this. A set is like a list, except that each item can show up only once in a set. Sets cant have duplicates. For example, suppose you had this list: arr 1, 2, 2, 3, 3, 3 And you converted it to a set: set(arr) set(1, 2, 3) 1, 2, and 3 all show up just once in a set. Y ou also need the list of stations that youre choosing from. I chose to use a hash for this: stations stationskone set(id, nv, ut) stationsktwo set(wa, id, mt) stationskthree set(or, nv, ca) stationskfour set(nv, ut) stationskfive set(ca, az) The keys are station names, and the values are the states they cover. So in this example, the kone station covers Idaho, Nevada, and Utah. All the values are sets, too. Making everything a set will make your life easier, as youll see soon. Finally, you need something to hold the final set of stations youll use: final_stations set() 149 The set-covering problem Calculating the answer Now you need to calculate what stations youll use. Take a look at the image at right, and see if you can predict what stations you should use. There can be more than one correct solution. Y ou need to go through every station and pick the one that covers the most uncovered states. Ill call this best_station : best_station None states_covered set() for station, states_for_station in stations.items(): states_covered is a set of all the states this station covers that havent been covered yet. The for loop allows you to loop over every station to see which one is the best station. Lets look at the body of the for loop: covered states_needed states_for_station if len(covered) len(states_covered): best_station station states_covered covered Theres a funny-looking line here: covered states_needed states_for_station Whats going on? Sets Suppose you have a set of fruits. Y ou also have a set of vegetables. When you have two sets, you can do some fun things with them. New syntax! This is called a set intersection. 150 Chapter 8 I Greedy algorithms Here are some things you can do with sets. A set union means combine both sets. A set intersection means find the items that show up in both sets (in this case, just the tomato). A set difference means subtract the items in one set from the items in the other set. For example: fruits set(avocado, tomato, banana) vegetables set(beets, carrots, tomato) fruits vegetables This is a set union. set(avocado, beets, carrots, tomato, banana) fruits vegetables This is a set intersection. set(tomato) fruits vegetables This is a set difference. set(avocado, banana) vegetables fruits What do you think this will do? 151 The set-covering problem To recap: Sets are like lists, except sets cant have duplicates. Y ou can do some interesting operations on sets, like union, intersection, and difference. Back to the code Lets get back to the original example. This is a set intersection: covered states_needed states_for_station covered is a set of states that were in both states_needed and states_for_station . So covered is the set of uncovered states that this station covers! Next you check whether this station covers more states than the current best_station : if len(covered) len(states_covered): best_station station states_covered covered If so, this station is the new best_station . Finally, after the for loop is over, you add best_station to the final list of stations: final_stations.add(best_station) Y ou also need to update states_needed . Because this station covers some states, those states arent needed anymore: states_needed - states_covered And you loop until states_needed is empty. Heres the full code for the loop: while states_needed: best_station None states_covered set() for station, states in stations.items(): covered states_needed states if len(covered) len(states_covered): best_station station states_covered covered states_needed - states_covered final_stations.add(best_station) 152 Chapter 8 I Greedy algorithms Finally, you can print final_stations , and you should see this: print final_stations set(ktwo, kthree, kone, kfive) Is that what you expected? Instead of stations 1, 2, 3, and 5, you could have chosen stations 2, 3, 4, and 5. Lets compare the run time of the greedy algorithm to the exact algorithm. EXERCISES For each of these algorithms, say whether its a greedy algorithm or not. 8.3 Quicksort 8.4 Breadth-first search 8.5 Dijkstras algorithm NP-complete problems To solve the set-covering problem, you had to calculate every possible set. 153 NP-complete problems Maybe you were reminded of the traveling salesperson problem from chapter 1. In this problem, a salesperson has to visit five different cities. And hes trying to figure out the shortest route that will take him to all five cities. To find the shortest route, you first have to calculate every possible route. How many routes do you have to calculate for five cities? Traveling salesperson, step by step Lets start small. Suppose you only have two cities. There are two routes to choose from. 154 Chapter 8 I Greedy algorithms Y ou may be wondering, In the traveling salesperson problem, is there a specific city you need to start from? For example, lets say Im the traveling salesperson. I live in San Francisco, and I need to go to four other cities. San Francisco would be my start city. But sometimes the start city isnt set. Suppose youre FedEx, trying to deliver a package to the Bay Area. The package is being flown in from Chicago to one of 50 FedEx locations in the Bay Area. Then that package will go on a truck that will travel to different locations delivering packages. Which location should it get flown to? Here the start location is unknown. Its up to you to compute the optimal path and start location for the traveling salesperson. The running time for both versions is the same. But its an easier example if theres no defined start city, so Ill go with that version. Two cities two possible routes. 3 cities Now suppose you add one more city. How many possible routes are there? If you start at Berkeley, you have two more cities to visit. Same route or different? You may think this should be the same route. After all, isnt SF Marin the same distance as Marin SF? Not necessarily. Some cities (like San Francisco) have a lot of one-way streets, so you cant go back the way you came. You might also have to go 1 or 2 miles out of the way to find an on- ramp to a highway. So these two routes arent necessarily the same. 155 NP-complete problems There are",
      "source": "Grokking Algorithms - Chapter 14",
      "timestamp": "2025-11-14T00:38:40.764194",
      "type": "book_content",
      "book_title": "Grokking Algorithms",
      "chapter_title": "Chapter 14",
      "chapter_number": 14
    },
    {
      "text": "six total routes, two for each city you can start at. So three cities six possible routes. 4 cities Lets add another city, Fremont. Now suppose you start at Fremont. 156 Chapter 8 I Greedy algorithms There are six possible routes starting from Fremont. And hey! They look a lot like the six routes you calculated earlier, when you had only three cities. Except now all the routes have an additional city, Fremont! Theres a pattern here. Suppose you have four cities, and you pick a start city, Fremont. There are three cities left. And you know that if there are three cities, there are six different routes for getting between those cities. If you start at Fremont, there are six possible routes. Y ou could also start at one of the other cities. Four possible start cities, with six possible routes for each start city 4 6 24 possible routes. Do you see a pattern? Every time you add a new city, youre increasing the number of routes you have to calculate. How many possible routes are there for six cities? If you guessed 720, youre right. 5,040 for 7 cities, 40,320 for 8 cities. This is called the factorial function (remember reading about this in chapter 3?). So 5! 120. Suppose you have 10 cities. How many possible routes are there? 10! 3,628,800. Y ou have to calculate over 3 million possible routes for 10 cities. As you can see, the number of possible 157 NP-complete problems routes becomes big very fast! This is why its impossible to compute the correct solution for the traveling-salesperson problem if you have a large number of cities. The traveling-salesperson problem and the set-covering problem both have something in common: you calculate every possible solution and pick the smallestshortest one. Both of these problems are NP-complete . Heres the short explanation of NP-completeness: some problems are famously hard to solve. The traveling salesperson and the set-covering problem are two examples. A lot of smart people think that its not possible to write an algorithm that will solve these problems quickly.Approximating Whats a good approximation algorithm for the traveling salesperson? Something simple that finds a short path. See if you can come up with an answer before reading on. Heres how I would do it: arbitrarily pick a start city. Then, each time the salesperson has to pick the next city to visit, they pick the closest unvisited city. Suppose they start in Marin. Total distance: 71 miles. Maybe its not the shortest path, but its still pretty short. 158 Chapter 8 I Greedy algorithms How do you tell if a problem is NP-complete? Jonah is picking players for his fantasy football team. He has a list of abilities he wants: good quarterback, good running back, good in rain, good under pressure, and so on. He has a list of players, where each player fulfills some abilities. Jonah needs a team that fulfills all his abilities, and the team size is limited. Wait a second, Jonah realizes. This is a set-covering problem! Jonah can use the same approximation algorithm to create his team: 1. Find the player who fulfills the most abilities that havent been fulfilled yet. 2. Repeat until the team fulfills all abilities (or you run out of space on the team). NP-complete problems show up everywhere! Its nice to know if the problem youre trying to solve is NP-complete. At that point, you can stop trying to solve it perfectly, and solve it using an approximation algorithm instead. But its hard to tell if a problem youre working on is NP-complete. Usually theres a very small difference between a problem thats easy to solve and an NP-complete problem. For example, in the previous chapters, I talked a lot about shortest paths. Y ou know how to calculate the shortest way to get from point A to point B. 159 NP-complete problems But if you want to find the shortest path that connects several points, thats the traveling-salesperson problem, which is NP-complete. The short answer: theres no easy way to tell if the problem youre working on is NP-complete. Here are some giveaways: Y our algorithm runs quickly with a handful of items but really slows down with more items. All combinations of X usually point to an NP-complete problem. Do you have to calculate every possible version of X because you cant break it down into smaller sub-problems? Might be NP-complete. If your problem involves a sequence (such as a sequence of cities, like traveling salesperson), and its hard to solve, it might be NP-complete. If your problem involves a set (like a set of radio stations) and its hard to solve, it might be NP-complete. Can you restate your problem as the set-covering problem or the traveling-salesperson problem? Then your problem is definitely NP-complete. EXERCISES 8.6 A postman needs to deliver to 20 homes. He needs to find the shortest route that goes to all 20 homes. Is this an NP-complete problem? 8.7 Finding the largest clique in a set of people (a clique is a set of people who all know each other). Is this an NP-complete problem? 8.8 Y oure making a map of the USA, and you need to color adjacent states with different colors. Y ou have to find the minimum number of colors you need so that no two adjacent states are the same color. Is this an NP-complete problem? 160 Chapter 8 I Greedy algorithms Recap Greedy algorithms optimize locally, hoping to end up with a global optimum. NP-complete problems have no known fast solution. If you have an NP-complete problem, your best bet is to use an approximation algorithm. Greedy algorithms are easy to write and fast to run, so they make good approximation algorithms. 161In this chapter You learn dynamic programming, a technique to solve a hard problem by breaking it up into subproblems and solving those subproblems first. Using examples, you learn to how to come up with a dynamic programming solution to a new problem.dynamic programming 9 The knapsack problem Lets revisit the knapsack problem from chapter 8. Y oure a thief with a knapsack that can carry 4 lb of goods. 162 Chapter 9 I Dynamic programming Y ou have three items that you can put into the knapsack. What items should you steal so that you steal the maximum moneys worth of goods? The simple solution The simplest algorithm is this: you try every possible set of goods and find the set that gives you the most value. This works, but its really slow. For 3 items, you have to calculate 8 possible sets. For 4 items, you have to calculate 16 sets. With every item you add, the number of sets you have to calculate doubles! This algorithm takes O(2 n) time, which is very, very slow. 163 The knapsack problem Thats impractical for any reasonable number of goods. In chapter 8, you saw how to calculate an approximate solution. That solution will be close to the optimal solution, but it may not be the optimal solution. So how do you calculate the optimal solution? Dynamic programming Answer: With dynamic programming! Lets see how the dynamic- programming algorithm works here. Dynamic programming starts by solving subproblems and builds up to solving the big problem. For the knapsack problem, youll start by solving the problem for smaller knapsacks (or sub-knapsacks) and then work up to solving the original problem. Dynamic programming is a hard concept, so dont worry if you dont get it right away. Were going to look at a lot of examples. Ill start by showing you the algorithm in action first. After youve seen it in action once, youll have a lot of questions! Ill do my best to address every question. 164 Chapter 9 I Dynamic programming Every dynamic-programming algorithm starts with a grid. Heres a grid for the knapsack problem. The rows of the grid are the items, and the columns are knapsack weights from 1 lb to 4 lb. Y ou need all of those columns because they will help you calculate the values of the sub-knapsacks. The grid starts out empty. Y oure going to fill in each cell of the grid. Once the grid is filled in, youll have your answer to this problem! Please follow along. Make your own grid, and well fill it out together. The guitar row Ill show you the exact formula for calculating this grid later. Lets do a walkthrough first. Start with the first row. This is the guitar row, which means youre trying to fit the guitar into the knapsack. At each cell, theres a simple decision: do you steal the guitar or not? Remember, youre trying to find the set of items to steal that will give you the most value. The first cell has a knapsack of capacity 1 lb. The guitar is also 1 lb, which means it fits into the knapsack! So the value of this cell is 1,500, and it contains a guitar. 165 The knapsack problem Lets start filling in the grid. Like this, each cell in the grid will contain a list of all the items that fit into the knapsack at that point. Lets look at the next cell. Here you have a knapsack of capacity 2 lb. Well, the guitar will definitely fit in there! The same for the rest of the cells in this row. Remember, this is the first row, so you have only the guitar to choose from. Y oure pretending that the other two items arent available to steal right now. At this point, youre probably confused. Why are you doing this for knapsacks with a capacity of 1 lb, 2 lb, and so on, when the problem talks about a 4 lb knapsack? Remember how I told you that dynamic programming starts with a small problem and builds up to the big problem? Y oure solving subproblems here that will help you to solve the big problem. Read on, and things will become clearer. 166 Chapter 9 I Dynamic programming At this point, your grid should look like this. Remember, youre trying to maximize the value of the knapsack. This row represents the current best guess for this max. So right now, according to this row, if you had a knapsack of capacity 4 lb, the max value you could put in there would be 1,500. Y ou know thats not the final solution. As we go through the algorithm, youll refine your estimate. The stereo row Lets do the next row. This one is for the stereo. Now that youre on the second row, you can steal the stereo or the guitar. At every row, you can steal the item at that row or the items in the rows above it. So you cant choose to steal the laptop right now, but you can steal the stereo andor the guitar. Lets start with the first cell, a knapsack of capacity 1 lb. The current max value you can fit into a knapsack of 1 lb is 1,500. 167 The knapsack problem Should you steal the stereo or not? Y ou have a knapsack of capacity 1 lb. Will the stereo fit in there? Nope, its too heavy! Because you cant fit the stereo, 1,500 remains the max guess for a 1 lb knapsack. Same thing for the next two cells. These knapsacks have a capacity of 2 lb and 3 lb. The old max value for both was 1,500. The stereo still doesnt fit, so your guesses remain unchanged. What if you have a knapsack of capacity 4 lb? Aha: the stereo finally fits! The old max value was 1,500, but if you put the stereo in there instead, the value is 3,000! Lets take the stereo. 168 Chapter 9 I Dynamic programming Y ou just updated your estimate! If you have a 4 lb knapsack, you can fit at least 3,000 worth of goods in it.",
      "source": "Grokking Algorithms - Chapter 15",
      "timestamp": "2025-11-14T00:38:40.764194",
      "type": "book_content",
      "book_title": "Grokking Algorithms",
      "chapter_title": "Chapter 15",
      "chapter_number": 15
    },
    {
      "text": "Y ou can see from the grid that youre incrementally updating your estimate. The laptop row Lets do the same thing with the laptop! The laptop weighs 3 lb, so it wont fit into a 1 lb or a 2 lb knapsack. The estimate for the first two cells stays at 1,500. At 3 lb, the old estimate was 1,500. But you can choose the laptop instead, and thats worth 2,000. So the new max estimate is 2,000! At 4 lb, things get really interesting. This is an important part. The current estimate is 3,000. Y ou can put the laptop in the knapsack, but its only worth 2,000. 169 The knapsack problem Hmm, thats not as good as the old estimate. But wait! The laptop weighs only 3 lb, so you have 1 lb free! Y ou could put something in this 1 lb. Whats the maximum value you can fit into 1 lb of space? Well, youve been calculating it all along. According to the last best estimate, you can fit the guitar into that 1 lb space, and thats worth 1,500. So the real comparison is as follows. Y ou might have been wondering why you were calculating max values for smaller knapsacks. I hope now it makes sense! When you have space left over, you can use the answers to those subproblems to figure out what will fit in that space. Its better to take the laptop the guitar for 3,500. 170 Chapter 9 I Dynamic programming The final grid looks like this. Theres the answer: the maximum value that will fit in the knapsack is 3,500, made up of a guitar and a laptop! Maybe you think that I used a different formula to calculate the value of that last cell. Thats because I skipped some unnecessary complexity when filling in the values of the earlier cells. Each cells value gets calculated with the same formula. Here it is. Y ou can use this formula with every cell in this grid, and you should end up with the same grid I did. Remember how I talked about solving subproblems? Y ou combined the solutions to two subproblems to solve the bigger problem. 171 Knapsack problem FAQ Knapsack problem FAQ Maybe this still feels like magic. This section answers some common questions. What happens if you add an item? Suppose you realize theres a fourth item you can steal that you didnt notice before! Y ou can also steal an iPhone. Do you have to recalculate everything to account for this new item? Nope. Remember, dynamic programming keeps progressively building on your estimate. So far, these are the max values. That means for a 4 lb knapsack, you can steal 3,500 worth of goods. Y ou thought that was the final max value. But lets add a row for the iPhone. 172 Chapter 9 I Dynamic programming Turns out you have a new max value! Try to fill in this new row before reading on. Lets start with the first cell. The iPhone fits into the 1 lb knapsack. The old max was 1,500, but the iPhone is worth 2,000. Lets take the iPhone instead. In the next cell, you can fit the iPhone and the guitar. For cell 3, you cant do better than take the iPhone and the guitar again, so leave it as is. For the last cell, things get interesting. The current max is 3,500. Y ou can steal the iPhone instead, and you have 3 lb of space left over. 173 Knapsack problem FAQ Those 3 lb are worth 2,000! 2,000 from the iPhone 2,000 from the old subproblem: thats 4,000. A new max! Heres the new final grid. Question: Would the value of a column ever go down ? Is this possible? Think of an answer before reading on. Answer: No. At every iteration, youre storing the current max estimate. The estimate can never get worse than it was before! EXERCISE 9.1 Suppose you can steal another item: an MP3 player. It weighs 1 lb and is worth 1,000. Should you steal it? 174 Chapter 9 I Dynamic programming What happens if you change the order of the rows? Does the answer change? Suppose you fill the rows in this order: stereo, laptop, guitar. What does the grid look like? Fill out the grid for yourself before moving on. Heres what the grid looks like. The answer doesnt change. The order of the rows doesnt matter. Can you fill in the grid column-wise instead of row-wise? Try it for yourself! For this problem, it doesnt make a difference. It could make a difference for other problems. What happens if you add a smaller item? Suppose you can steal a necklace. It weighs 0.5 lb, and its worth 1,000. So far, your grid assumes that all weights are integers. Now you decide to steal the necklace. Y ou have 3.5 lb left over. Whats the max value you can fit in 3.5 lb? Y ou dont know! Y ou only calculated values for 1 lb, 2 lb, 3 lb, and 4 lb knapsacks. Y ou need to know the value of a 3.5 lb knapsack. Because of the necklace, you have to account for finer granularity, so the grid has to change. 175 Knapsack problem FAQ Can you steal fractions of an item? Suppose youre a thief in a grocery store. Y ou can steal bags of lentils and rice. If a whole bag doesnt fit, you can open it and take as much as you can carry. So now its not all or nothingyou can take a fraction of an item. How do you handle this using dynamic programming? Answer: Y ou cant. With the dynamic-programming solution, you either take the item or not. Theres no way for it to figure out that you should take half an item. But this case is also easily solved using a greedy algorithm! First, take as much as you can of the most valuable item. When that runs out, take as much as you can of the next most valuable item, and so on. For example, suppose you have these items to choose from. Quinoa is more expensive per pound than anything else. So, take all the quinoa you can carry! If that fills your knapsack, thats the best you can do. If the quinoa runs out and you still have space in your knapsack, take the next most valuable item, and so on. Optimizing your travel itinerary Suppose youre going to London for a nice vacation. Y ou have two days there and a lot of things you want to do. Y ou cant do everything, so you make a list. 176 Chapter 9 I Dynamic programming For each thing you want to see, you write down how long it will take and rate how much you want to see it. Can you figure out what you should see, based on this list? Its the knapsack problem again! Instead of a knapsack, you have a limited amount of time. And instead of stereos and laptops, you have a list of places you want to go. Draw the dynamic-programming grid for this list before moving on. Heres what the grid looks like. Did you get it right? Fill in the grid. What places should you end up seeing? Heres the answer. 177 Knapsack problem FAQ Handling items that depend on each other Suppose you want to go to Paris, so you add a couple of items on the list. These places take a lot of time, because first you have to travel from London to Paris. That takes half a day. If you want to do all three items, it will take four and a half days. Wait, thats not right. Y ou dont have to travel to Paris for each item. Once youre in Paris, each item should only take a day. So it should be one day per item half a day of travel 3.5 days, not 4.5 days. If you put the Eiffel Tower in your knapsack, then the Louvre becomes cheaperit will only cost you a day instead of 1.5 days. How do you model this in dynamic programming? Y ou cant. Dynamic programming is powerful because it can solve subproblems and use those answers to solve the big problem. Dynamic programming only works when each subproblem is discretewhen it doesnt depend on other subproblems. That means theres no way to account for Paris using the dynamic-programming algorithm. Is it possible that the solution will require more than two sub-knapsacks? Its possible that the best solution involves stealing more than two items. The way the algorithm is set up, youre combining two knapsacks at mostyoull never have more than two sub-knapsacks. But its possible for those sub-knapsacks to have their own sub-knapsacks. 178 Chapter 9 I Dynamic programming Is it possible that the best solution doesnt fill the knapsack completely? Y es. Suppose you could also steal a diamond. This is a big diamond: it weighs 3.5 pounds. Its worth a million dollars, way more than anything else. Y ou should definitely steal it! But theres half a pound of space left, and nothing will fit in that space. EXERCISE 9.2 Suppose youre going camping. Y ou have a knapsack that will hold 6 lb, and you can take the following items. Each has a value, and the higher the value, the more important the item is: Water, 3 lb, 10 Book, 1 lb, 3 Food, 2 lb, 9 Jacket, 2 lb, 5 Camera, 1 lb, 6 Whats the optimal set of items to take on your camping trip? Longest common substring Youv e seen one dynamic programming problem so far. What are the takeaways? Dynamic programming is useful when youre trying to optimize something given a constraint . In the knapsack problem, you had to maximize the value of the goods you stole, constrained by the size of the knapsack. Y ou can use dynamic programming when the problem can be broken into discrete subproblems, and they dont depend on each other. 179 Longest common substring It can be hard to come up with a dynamic-programming solution. Thats what well focus on in this section. Some general tips follow: Every dynamic-programming solution involves a grid. The values in the cells are usually what youre trying to optimize. For the knapsack problem, the values were the value of the goods. Each cell is a subproblem, so think about how you can divide your problem into subproblems. That will help you figure out what the axes are. Lets look at another example. Suppose you run dictionary.com. Someone types in a word, and you give them the definition. But if someone misspells a word, you want to be able to guess what word they meant. Alex is searching for fish, but he accidentally put in hish. Thats not a word in your dictionary, but you have a list of words that are similar. (This is a toy example, so youll limit your list to two words. In reality, this list would probably be thousands of words.) Alex typed hish . Which word did Alex mean to type: fish or vista ? Making the grid What does the grid for this problem look like? Y ou need to answer these questions: What are the values of the cells? How do you divide this problem into subproblems? What are the axes of the grid? In dynamic programming, youre trying to maximize something. In this case, youre trying to find the longest substring that two words have in common. What substring do hish and fish have in common? How about hish and vista ? Thats what you want to calculate. 180 Chapter 9 I Dynamic programming Remember, the values for the cells are usually what youre trying to optimize. In this case, the values will probably be a number: the length of the longest substring that the two strings have in common. How do",
      "source": "Grokking Algorithms - Chapter 16",
      "timestamp": "2025-11-14T00:38:40.764194",
      "type": "book_content",
      "book_title": "Grokking Algorithms",
      "chapter_title": "Chapter 16",
      "chapter_number": 16
    },
    {
      "text": "you divide this problem into subproblems? Y ou could compare substrings. Instead of comparing hish and fish, you could compare his and fis first. Each cell will contain the length of the longest substring that two substrings have in common. This also gives you a clue that the axes will probably be the two words. So the grid probably looks like this. If this seems like black magic to you, dont worry. This is hard stuff thats why Im teaching it so late in the book! Later, Ill give you an exercise so you can practice dynamic programming yourself. Filling in the grid Now you have a good idea of what the grid should look like. Whats the formula for filling in each cell of the grid? Y ou can cheat a little, because you already know what the solution should be hish and fish have a substring of length 3 in common: ish. But that still doesnt tell you the formula to use. Computer scientists sometimes joke about using the Feynman algorithm. The Feynman algorithm is named after the famous physicist Richard Feynman, and it works like this: 1. Write down the problem. 2. Think real hard. 3. Write down the solution. 181 Longest common substring Computer scientists are a fun bunch! The truth is, theres no easy way to calculate the formula here. Y ou have to experiment and try to find something that works. Sometimes algorithms arent an exact recipe. Theyre a framework that you build your idea on top of. Try to come up with a solution to this problem yourself. Ill give you a hintpart of the grid looks like this. What are the other values? Remember that each cell is the value of a subproblem. Why does cell (3, 3) have a value of 2? Why does cell (3, 4) have a value of 0? Read on after youve tried to come up with a formula yourself. Even if you dont get it right, my explanation will make a lot more sense. 182 Chapter 9 I Dynamic programming The solution Heres the final grid. Heres my formula for filling in each cell. Heres how the formula looks in pseudocode: if word_ai word_bj: The letters match. cellij celli-1j-1 1 else: The letters dont match. cellij 0 183 Longest common substring Heres the grid for hish vs. vista. One thing to note: for this problem, the final solution may not be in the last cell! For the knapsack problem, this last cell always had the final solution. But for the longest common substring, the solution is the largest number in the gridand it may not be the last cell. Lets go back to the original question: which string has more in common with hish? hish and fish have a substring of three letters in common. hish and vista have a substring of two letters in common. Alex probably meant to type fish. Longest common subsequence Suppose Alex accidentally searched for fosh. Which word did he mean: fish or fort? Lets compare them using the longest-common-substring formula. 184 Chapter 9 I Dynamic programming Theyre both the same: two letters! But fosh is closer to fish. Y oure comparing the longest common substring , but you really need to compare the longest common subsequence : the number of letters in a sequence that the two words have in common. How do you calculate the longest common subsequence? Heres the partial grid for fish and fosh . Can you figure out the formula for this grid? The longest common subsequence is very similar to the longest common substring, and the formulas are pretty similar, too. Try to solve it yourselfI give the answer next. Longest common subsequencesolution Heres the final grid. 185 Longest common substring Heres my formula for filling in each cell. And here it is in pseudocode: if word_ai word_bj: The letters match. cellij celli-1j-1 1 else: The letters dont match. cellij max(celli-1j, cellij-1) Whewyou did it! This is definitely one of the toughest chapters in the book. So is dynamic programming ever really used? Yes: Biologists use the longest common subsequence to find similarities in DNA strands. They can use this to tell how similar two animals or two diseases are. The longest common subsequence is being used to find a cure for multiple sclerosis. Have you ever used diff (like git diff )? Diff tells you the differences between two files, and it uses dynamic programming to do so. We talked about string similarity. Levenshtein distance measures how similar two strings are, and it uses dynamic programming. Levenshtein distance is used for everything from spell-check to figuring out whether a user is uploading copyrighted data. 186 Chapter 9 I Dynamic programming Have you ever used an app that does word wrap, like Microsoft Word? How does it figure out where to wrap so that the line length stays consistent? Dynamic programming! EXERCISE 9.3 Draw and fill in the grid to calculate the longest common substring between blue and clues . Recap Dynamic programming is useful when youre trying to optimize something given a constraint. Y ou can use dynamic programming when the problem can be broken into discrete subproblems. Every dynamic-programming solution involves a grid. The values in the cells are usually what youre trying to optimize. Each cell is a subproblem, so think about how you can divide your problem into subproblems. Theres no single formula for calculating a dynamic-programming solution. 187In this chapter You learn to build a classification system using the k-nearest neighbors algorithm. You learn about feature extraction. You learn about regression: predicting a number, like the value of a stock tomorrow, or how much a user will enjoy a movie. You learn about the use cases and limitations of k-nearest neighbors.k-nearest neighbors 10 Classifying oranges vs. grapefruit Look at this fruit. Is it an orange or a grapefruit? Well, I know that grapefruits are generally bigger and redder. 188 Chapter 10 I k-nearest neighbors My thought process is something like this: I have a graph in my mind. Generally speaking, the bigger, redder fruit are grapefruits. This fruit is big and red, so its probably a grapefruit. But what if you get a fruit like this? How would you classify this fruit? One way is to look at the neighbors of this spot. Take a look at the three closest neighbors of this spot. 189 Building a recommendations system More neighbors are oranges than grapefruit. So this fruit is probably an orange. Congratulations: Y ou just used the k-nearest neighbors (KNN) algorithm for classification ! The whole algorithm is pretty simple. The KNN algorithm is simple but useful! If youre trying to classify something, you might want to try KNN first. Lets look at a more real-world example. Building a recommendations system Suppose youre Netflix, and you want to build a movie recommendations system for your users. On a high level, this is similar to the grapefruit problem! 190 Chapter 10 I k-nearest neighbors Y ou can plot every user on a graph. These users are plotted by similarity, so users with similar taste are plotted closer together. Suppose you want to recommend movies for Priyanka. Find the five users closest to her. Justin, JC, Joey, Lance, and Chris all have similar taste in movies. So whatever movies they like, Priyanka will probably like too! Once you have this graph, building a recommendations system is easy. If Justin likes a movie, recommend it to Priyanka. 191 Building a recommendations system But theres still a big piece missing. Y ou graphed the users by similarity. How do you figure out how similar two users are? Feature extraction In the grapefruit example, you compared fruit based on how big they are and how red they are. Size and color are the features youre comparing. Now suppose you have three fruit. Y ou can extract the features. Then you can graph the three fruit. From the graph, you can tell visually that fruits A and B are similar. Lets measure how close they are. To find the distance between two points, you use the Pythagorean formula. 192 Chapter 10 I k-nearest neighbors Heres the distance between A and B, for example. The distance between A and B is 1. Y ou can find the rest of the distances, too. The distance formula confirms what you saw visually: fruits A and B are similar. Suppose youre comparing Netflix users, instead. Y ou need some way to graph the users. So, you need to convert each user to a set of coordinates, just as you did for fruit. 193 Building a recommendations system Once you can graph users, you can measure the distance between them. Heres how you can convert users into a set of numbers. When users sign up for Netflix, have them rate some categories of movies based on how much they like those categories. For each user, you now have a set of ratings! Priyanka and Justin like Romance and hate Horror. Morpheus likes Action but hates Romance (he hates when a good action movie gets ruined by a cheesy romantic scene). Remember how in oranges versus grapefruit, each fruit was represented by a set of two numbers? Here, each user is represented by a set of five numbers. A mathematician would say, instead of calculating the distance in two dimensions, youre now calculating the distance in five dimensions. But the distance formula remains the same. 194 Chapter 10 I K-nearest neighbors It just involves a set of five numbers instead of a set of two numbers. The distance formula is flexible: you could have a set of a million numbers and still use the same old distance formula to find the distance. Maybe youre wondering, What does distance mean when you have five numbers? The distance tells you how similar those sets of numbers are. Heres the distance between Priyanka and Justin. Priyanka and Justin are pretty similar. Whats the difference between Priyanka and Morpheus? Calculate the distance before moving on. Did you get it right? Priyanka and Morpheus are 24 apart. The distance tells you that Priyankas tastes are more like Justins than Morpheuss. Great! Now recommending movies to Priyanka is easy: if Justin likes a movie, recommend it to Priyanka, and vice versa. Y ou just built a movie recommendations system! If youre a Netflix user, Netflix will keep telling you, Please rate more movies. The more movies you rate, the better your recommendations will be. Now you know why. The more movies you rate, the more accurately Netflix can see what other users youre similar to. 195 Building a recommendations system EXERCISES 10.1 In the Netflix example, you calculated the distance between two different users using the distance formula. But not all users rate movies the same way. Suppose you have two users, Y ogi and Pinky, who have the same taste in movies. But Y ogi rates any movie he likes as a 5, whereas Pinky is choosier and reserves the 5s for only the best. Theyre well matched, but according to the distance algorithm, they arent neighbors. How would you take their different rating strategies into account? 10.2 Suppose Netflix nominates a group of influencers. For example, Quentin Tarantino and Wes Anderson are influencers on Netflix, so their ratings count for more than a normal users. How would you change the recommendations system so its biased toward the ratings of influencers? Regression Suppose you want to do more than just recommend a movie: you want to guess how Priyanka will rate this movie. Take the five people closest to her. By the way, I keep talking about the closest five people. Theres nothing special about the number 5: you could do the closest 2, or 10, or 10,000. Thats why the algorithm is called k-nearest neighbors and not five- nearest neighbors! Suppose youre trying to guess a rating for Pitch Perfect . Well, how did Justin, JC, Joey, Lance, and Chris rate it? 196 Chapter 10",
      "source": "Grokking Algorithms - Chapter 17",
      "timestamp": "2025-11-14T00:38:40.764194",
      "type": "book_content",
      "book_title": "Grokking Algorithms",
      "chapter_title": "Chapter 17",
      "chapter_number": 17
    },
    {
      "text": "I k-nearest neighbors Y ou could take the average of their ratings and get 4.2 stars. Thats called regression . These are the two basic things youll do with KNNclassification and regression: Classification categorization into a group Regression predicting a response (like a number) Regression is very useful. Suppose you run a small bakery in Berkeley, and you make fresh bread every day. Y oure trying to predict how many loaves to make for today. Y ou have a set of features: Weather on a scale of 1 to 5 (1 bad, 5 great). Weekend or holiday? (1 if its a weekend or a holiday, 0 otherwise.) Is there a game on? (1 if yes, 0 if no.) And you know how many loaves of bread youve sold in the past for different sets of features. 197 Building a recommendations system Today is a weekend day with good weather. Based on the data you just saw, how many loaves will you sell? Lets use KNN, where K 4. First, figure out the four nearest neighbors for this point. Here are the distances. A, B, D, and E are the closest. Take an average of the loaves sold on those days, and you get 218.75. Thats how many loaves you should make for today! Cosine similarity So far, youve been using the distance formula to compare the distance between two users. Is this the best formula to use? A common one used in practice is cosine similarity . Suppose two users are similar, but one of them is more conservative in their ratings. They both loved Manmohan Desais Amar Akbar Anthony . Paul rated it 5 stars, but Rowan rated it 4 stars. If you keep using the distance formula, these two users might not be each others neighbors, even though they have similar taste. Cosine similarity doesnt measure the distance between two vectors. Instead, it compares the angles of the two vectors. Its better at dealing with cases like this. Cosine similarity is out of the scope of this book, but look it up if you use KNN! 198 Chapter 10 I k-nearest neighbors Picking good features To figure out recommendations, you had users rate categories of movies. What if you had them rate pictures of cats instead? Then you d find users who rated those pictures similarly. This would probably be a worse recommendations engine, because the features dont have a lot to do with taste in movies! Or suppose you ask users to rate movies so you can give them recommendationsbut you only ask them to rate Toy Story , Toy Story 2, and Toy Story 3 . This wont tell you a lot about the users movie tastes! When youre working with KNN, its really important to pick the right features to compare against. Picking the right features means Features that directly correlate to the movies youre trying to recommend Features that dont have a bias (for example, if you ask the users to only rate comedy movies, that doesnt tell you whether they like action movies) Do you think ratings are a good way to recommend movies? Maybe I rated The Wire more highly than House Hunters , but I actually spend more time watching House Hunters . How would you improve this Netflix recommendations system? Going back to the bakery: can you think of two good and two bad features you could have picked for the bakery? Maybe you need to make more loaves after you advertise in the paper. Or maybe you need to make more loaves on Mondays. Theres no one right answer when it comes to picking good features. Y ou have to think about all the different things you need to consider. EXERCISE 10.3 Netflix has millions of users. The earlier example looked at the five closest neighbors for building the recommendations system. Is this too low? Too high? 199 Introduction to machine learning Introduction to machine learning KNN is a really useful algorithm, and its your introduction to the magical world of machine learning! Machine learning is all about making your computer more intelligent. Y ou already saw one example of machine learning: building a recommendations system. Lets look at some other examples. OCR OCR stands for optical character recognition . It means you can take a photo of a page of text, and your computer will automatically read the text for you. Google uses OCR to digitize books. How does OCR work? For example, consider this number. How would you automatically figure out what number this is? Y ou can use KNN for this: 1. Go through a lot of images of numbers, and extract features of those numbers. 2. When you get a new image, extract the features of that image, and see what its nearest neighbors are! Its the same problem as oranges versus grapefruit. Generally speaking, OCR algorithms measure lines, points, and curves. Then, when you get a new character, you can extract the same features from it. 200 Chapter 10 I k-nearest neighbors Feature extraction is a lot more complicated in OCR than the fruit example. But its important to understand that even complex technologies build on simple ideas, like KNN. Y ou could use the same ideas for speech recognition or face recognition. When you upload a photo to Facebook, sometimes its smart enough to tag people in the photo automatically. Thats machine learning in action! The first step of OCR, where you go through images of numbers and extract features, is called training . Most machine-learning algorithms have a training step: before your computer can do the task, it must be trained. The next example involves spam filters, and it has a training step. Building a spam filter Spam filters use another simple algorithm called the Naive Bayes classifier . First, you train your Naive Bayes classifier on some data. Suppose you get an email with the subject collect your million dollars now! Is it spam? Y ou can break this sentence into words. Then, for each word, see what the probability is for that word to show up in a spam email. For example, in this very simple model, the word million only appears in spam emails. Naive Bayes figures out the probability that something is likely to be spam. It has applications similar to KNN. 201 Introduction to machine learning For example, you could use Naive Bayes to categorize fruit: you have a fruit thats big and red. Whats the probability that its a grapefruit? Its another simple algorithm thats fairly effective. We love those algorithms! Predicting the stock market Heres something thats hard to do with machine learning: really predicting whether the stock market will go up or down. How do you pick good features in a stock market? Suppose you say that if the stock went up yesterday, it will go up today. Is that a good feature? Or suppose you say that the stock will always go down in May. Will that work? Theres no guaranteed way to use past numbers to predict future performance. Predicting the future is hard, and its almost impossible when there are so many variables involved. Recap I hope this gives you an idea of all the different things you can do with KNN and with machine learning! Machine learning is an interesting field that you can go pretty deep into if you decide to: KNN is used for classification and regression and involves looking at the k-nearest neighbors. Classification categorization into a group. Regression predicting a response (like a number). 202 Chapter 10 I k-nearest neighbors Feature extraction means converting an item (like a fruit or a user) into a list of numbers that can be compared. Picking good features is an important part of a successful KNN algorithm. 203In this chapter You get a brief overview of 10 algorithms that werent covered in this book, and why theyre useful. You get pointers on what to read next, depending on what your interests are.where to go next 11 Trees Lets go back to the binary search example. When a user logs in to Facebook, Facebook has to look through a big array to see if the username exists. We said the fastest way to search through this array is to run binary search. But theres a problem: every time a new user signs up, you insert their username into the array. Then you have to re-sort the array, because binary search only works with sorted arrays. Wouldnt it be nice if you could insert 204 Chapter 11 I Where to go next the username into the right slot in the array right away, so you dont have to sort the array afterward? Thats the idea behind the binary search tree data structure. A binary search tree looks like this. For every node, the nodes to its left are smaller in value, and the nodes to the right are larger in value. Suppose youre searching for Maggie. Y ou start at the root node. 205 Trees Maggie comes after David , so go toward the right. Maggie comes before Manning , so go to the left. Y ou found Maggie! Its almost like running a binary search! Searching for an element in a binary search tree takes O(log n) time on average and O( n) time in the worst case . Searching a sorted array takes O(log n) time in the worst case , so you might think a sorted array is better. But a binary search tree is a lot faster for insertions and deletions on average. Binary search trees have some downsides too: for one thing, you dont get random access. Y ou cant say, Give me the fifth element of this tree. Those performance times are also on average and rely on the tree being balanced. Suppose you have an imbalanced tree like the one shown next. 206 Chapter 11 I Where to go next See how its leaning to the right? This tree doesnt have very good performance, because it isnt balanced. There are special binary search trees that balance themselves. One example is the red-black tree. So when are binary search trees used? B-trees, a special type of binary tree, are commonly used to store data in databases. If youre interested in databases or more-advanced data structures, check these out: B-trees Red-black trees Heaps Splay trees Inverted indexes Heres a very simplified version of how a search engine works. Suppose you have three web pages with this simple content. 207 The Fourier transform Lets build a hash table from this content. The keys of the hash table are the words, and the values tell you what pages each word appears on. Now suppose a user searches for hi. Lets see what pages hi shows up on. Aha: It appears on pages A and B. Lets show the user those pages as the result. Or suppose the user searches for there . Well, you know that it shows up on pages A and C. Pretty easy, huh? This is a useful data structure: a hash that maps words to places where they appear. This data structure is called an inverted index , and its commonly used to build search engines. If youre interested in search, this is a good place to start. The Fourier transform The Fourier transform is one of those rare algorithms: brilliant, elegant, and with a million use cases. The best analogy for the Fourier transform comes from Better Explained (a great website that explains math simply): given a smoothie, the Fourier transform will tell you the ingredients in the smoothie.1 Or, to put it another way, given a song, the transform can separate it into individual frequencies. It turns out that this simple idea has a lot of use cases. For example, if you can separate a song into frequencies, you can boost the ones you care about. Y ou could boost the bass and hide the treble. The Fourier transform is great for processing",
      "source": "Grokking Algorithms - Chapter 18",
      "timestamp": "2025-11-14T00:38:40.764194",
      "type": "book_content",
      "book_title": "Grokking Algorithms",
      "chapter_title": "Chapter 18",
      "chapter_number": 18
    },
    {
      "text": "signals. Y ou can also use it to compress music. First you break an audio file down into its ingredient notes. The Fourier transform tells you exactly how much each note contributes to the overall song. So you can just get rid of the notes that arent important. Thats how the MP3 format works! Music isnt the only type of digital signal. The JPG format is another compressed format, and it works the same way. People use the Fourier transform to try to predict upcoming earthquakes and analyze DNA. 1 Kalid, An Interactive Guide to the Fourier Transform, Better Explained, http:mng.bx874X. 208 Chapter 11 I Where to go next Y ou can use it to build an app like Shazam, which guesses what song is playing. The Fourier transform has a lot of uses. Chances are high that youll run into it! Parallel algorithms The next three topics are about scalability and working with a lot of data. Back in the day, computers kept getting faster and faster. If you wanted to make your algorithm faster, you could wait a few months, and the computers themselves would become faster. But were near the end of that period. Instead, laptops and computers ship with multiple cores. To make your algorithms faster, you need to change them to run in parallel across all the cores at once! Heres a simple example. The best you can do with a sorting algorithm is roughly O( n log n). Its well known that you cant sort an array in O( n) time unless you use a parallel algorithm ! Theres a parallel version of quicksort that will sort an array in O( n) time. Parallel algorithms are hard to design. And its also hard to make sure they work correctly and to figure out what type of speed boost youll see. One thing is for surethe time gains arent linear. So if you have two cores in your laptop instead of one, that almost never means your algorithm will magically run twice as fast. There are a couple of reasons for this: Overhead of managing the parallelism Suppose you have to sort an array of 1,000 items. How do you divide this task among the two cores? Do you give each core 500 items to sort and then merge the two sorted arrays into one big sorted array? Merging the two arrays takes time. Load balancing Suppose you have 10 tasks to do, so you give each core 5 tasks. But core A gets all the easy tasks, so its done in 10 seconds, whereas core B gets all the hard tasks, so it takes a minute. That means core A was sitting idle for 50 seconds while core B was doing all the work! How do you distribute the work evenly so both cores are working equally hard? If youre interested in the theoretical side of performance and scalability, parallel algorithms might be for you! 209 MapReduce MapReduce Theres a special type of parallel algorithm that is becoming increasingly popular: the distributed algorithm . Its fine to run a parallel algorithm on your laptop if you need two to four cores, but what if you need hundreds of cores? Then you can write your algorithm to run across multiple machines. The MapReduce algorithm is a popular distributed algorithm. Y ou can use it through the popular open source tool Apache Hadoop. Why are distributed algorithms useful? Suppose you have a table with billions or trillions of rows, and you want to run a complicated SQL query on it. Y ou cant run it on MySQL, because it struggles after a few billion rows. Use MapReduce through Hadoop! Or suppose you have to process a long list of jobs. Each job takes 10 seconds to process, and you need to process 1 million jobs like this. If you do this on one machine, it will take you months! If you could run it across 100 machines, you might be done in a few days. Distributed algorithms are great when you have a lot of work to do and want to speed up the time required to do it. MapReduce in particular is built up from two simple ideas: the map function and the reduce function. The map function The map function is simple: it takes an array and applies the same function to each item in the array. For example, here were doubling every item in the array: arr1 1, 2, 3, 4, 5 arr2 map(lambda x: 2 x, arr1) 2, 4, 6, 8, 10 210 Chapter 11 I Where to go next arr2 now contains 2, 4, 6, 8, 10 every element in arr1 was doubled! Doubling an element is pretty fast. But suppose you apply a function that takes more time to process. Look at this pseudocode: arr1 A list of URLs arr2 map(download_page, arr1) Here you have a list of URLs, and you want to download each page and store the contents in arr2 . This could take a couple of seconds for each URL. If you had 1,000 URLs, this might take a couple of hours! Wouldnt it be great if you had 100 machines, and map could automatically spread out the work across all of them? Then you would be downloading 100 pages at a time, and the work would go a lot faster! This is the idea behind the map in MapReduce. The reduce function The reduce function confuses people sometimes. The idea is that you reduce a whole list of items down to one item. With map, you go from one array to another. With reduce , you transform an array to a single item. Heres an example: arr1 1, 2, 3, 4, 5 reduce(lambda x,y: xy, arr1) 15 211 Bloom filters and HyperLogLog In this case, you sum up all the elements in the array: 1 2 3 4 5 15 ! I wont explain reduce in more detail here, because there are plenty of tutorials online. MapReduce uses these two simple concepts to run queries about data across multiple machines. When you have a large dataset (billions of rows), MapReduce can give you an answer in minutes where a traditional database might take hours. Bloom filters and HyperLogLog Suppose youre running Reddit. When someone posts a link, you want to see if its been posted before. Stories that havent been posted before are considered more valuable. So you need to figure out whether this link has been posted before. Or suppose youre Google, and youre crawling web pages. Y ou only want to crawl a web page if you havent crawled it already. So you need to figure out whether this page has been crawled before. Or suppose youre running bit.ly, which is a URL shortener. Y ou dont want to redirect users to malicious websites. Y ou have a set of URLs that are considered malicious. Now you need to figure out whether youre redirecting the user to a URL in that set. All of these examples have the same problem. Y ou have a very large set. 212 Chapter 11 I Where to go next Now you have a new item, and you want to see whether it belongs in that set. Y ou could do this quickly with a hash. For example, suppose Google has a big hash in which the keys are all the pages it has crawled. Y ou want to see whether youve already crawled adit.io. Look it up in the hash. adit.io is a key in the hash, so youve already crawled it. The average lookup time for hash tables is O(1). adit.io is in the hash, so youve already crawled it. Y ou found that out in constant time. Pretty good! Except that this hash needs to be huge . Google indexes trillions of web pages. If this hash has all the URLs that Google has indexed, it will take up a lot of space. Reddit and bit.ly have the same space problem. When you have so much data, you need to get creative! Bloom filters Bloom filters offer a solution. Bloom filters are probabilistic data structures . They give you an answer that could be wrong but is probably correct. Instead of a hash, you can ask your bloom filter if youve crawled this URL before. A hash table would give you an accurate answer. A bloom filter will give you an answer thats probably correct: False positives are possible. Google might say, Y ouve already crawled this site, even though you havent. False negatives arent possible. If the bloom filter says, Y ou havent crawled this site, then you definitely havent crawled this site. Bloom filters are great because they take up very little space. A hash table would have to store every URL crawled by Google, but a bloom filter doesnt have to do that. Theyre great when you dont need an exact answer, as in all of these examples. Its okay for bit.ly to say, We think this site might be malicious, so be extra careful. 213 The SHA algorithms HyperLogLog Along the same lines is another algorithm called HyperLogLog. Suppose Google wants to count the number of unique searches performed by its users. Or suppose Amazon wants to count the number of unique items that users looked at today. Answering these questions takes a lot of space! With Google, you d have to keep a log of all the unique searches. When a user searches for something, you have to see whether its already in the log. If not, you have to add it to the log. Even for a single day, this log would be massive! HyperLogLog approximates the number of unique elements in a set. Just like bloom filters, it wont give you an exact answer, but it comes very close and uses only a fraction of the memory a task like this would otherwise take. If you have a lot of data and are satisfied with approximate answers, check out probabilistic algorithms! The SHA algorithms Do you remember hashing from chapter 5? Just to recap, suppose you have a key, and you want to put the associated value in an array. Y ou use a hash function to tell you what slot to put the value in. And you put the value in that slot. 214 Chapter 11 I Where to go next This allows you to do constant-time lookups. When you want to know the value for a key, you can use the hash function again, and it will tell you in O(1) time what slot to check. In this case, you want the hash function to give you a good distribution. So a hash function takes a string and gives you back the slot number for that string. Comparing files Another hash function is a secure hash algorithm (SHA) function. Given a string, SHA gives you a hash for that string. The terminology can be a little confusing here. SHA is a hash function . It generates a hash , which is just a short string. The hash function for hash tables went from string to array index, whereas SHA goes from string to string. SHA generates a different hash for every string. Note SHA hashes are long. Theyve been truncated here. Y ou can use SHA to tell whether two files are the same. This is useful when you have very large files. Suppose you have a 4 GB file. Y ou want to check whether your friend has the same large file. Y ou dont have to try to email them your large file. Instead, you can both calculate the SHA hash and compare it. 215 The SHA algorithms Checking passwords SHA is also useful when you want to compare strings without revealing what the original string was. For example, suppose Gmail gets hacked, and the attacker steals all the passwords! Is your password out in the open? No, it isnt. Google doesnt store the original",
      "source": "Grokking Algorithms - Chapter 19",
      "timestamp": "2025-11-14T00:38:40.764194",
      "type": "book_content",
      "book_title": "Grokking Algorithms",
      "chapter_title": "Chapter 19",
      "chapter_number": 19
    },
    {
      "text": "password, only the SHA hash of the password! When you type in your password, Google hashes it and checks it against the hash in its database. So its only comparing hashesit doesnt have to store your password! SHA is used very commonly to hash passwords like this. Its a one-way hash. Y ou can get the hash of a string. 216 Chapter 11 I Where to go next But you cant get the original string from the hash. That means if an attacker gets the SHA hashes from Gmail, they cant convert those hashes back to the original passwords! Y ou can convert a password to a hash, but not vice versa. SHA is actually a family of algorithms: SHA-0, SHA-1, SHA-2, and SHA-3. As of this writing, SHA-0 and SHA-1 have some weaknesses. If youre using an SHA algorithm for password hashing, use SHA-2 or SHA-3. The gold standard for password-hashing functions is currently bcrypt (though nothing is foolproof). Locality-sensitive hashing SHA has another important feature: its locality insensitive. Suppose you have a string, and you generate a hash for it. If you change just one character of the string and regenerate the hash, its totally different! This is good because an attacker cant compare hashes to see whether theyre close to cracking a password. Sometimes, you want the opposite: you want a locality-sensitive hash function. Thats where Simhash comes in. If you make a small change to a string, Simhash generates a hash thats only a little different. This allows you to compare hashes and see how similar two strings are, which is pretty useful! Google uses Simhash to detect duplicates while crawling the web. A teacher could use Simhash to see whether a student was copying an essay from the web. 217 Diffie-Hellman key exchange Scribd allows users to upload documents or books to share with others. But Scribd doesnt want users uploading copyrighted content! The site could use Simhash to check whether an upload is similar to a Harry Potter book and, if so, reject it automatically. Simhash is useful when you want to check for similar items. Diffie-Hellman key exchange The Diffie-Hellman algorithm deserves a mention here, because it solves an age-old problem in an elegant way. How do you encrypt a message so it can only be read by the person you sent the message to? The easiest way is to come up with a cipher, like a 1, b 2, and so on. Then if I send you the message 4,15,7 , you can translate it to d,o,g . But for this to work, we both have to agree on the cipher. We cant agree over email, because someone might hack into your email, figure out the cipher, and decode our messages. Heck, even if we meet in person, someone might guess the cipherits not complicated. So we should change it every day. But then we have to meet in person to change it every day! Even if we did manage to change it every day, a simple cipher like this is easy to crack with a brute-force attack. Suppose I see the message 9,6,13,13,16 24,16,19,13,5 . Ill guess that this uses a 1, b 2, and so on. Thats gibberish. Lets try a 2, b 3, and so on. 218 Chapter 11 I Where to go next That worked! A simple cipher like this is easy to break. The Germans used a much more complicated cipher in WWII, but it was still cracked. Diffie-Hellman solves both problems: Both parties dont need to know the cipher. So we dont have to meet and agree to what the cipher should be. The encrypted messages are extremely hard to decode. Diffie-Hellman has two keys: a public key and a private key. The public key is exactly that: public. Y ou can post it on your website, email it to friends, or do anything you want with it. Y ou dont have to hide it. When someone wants to send you a message, they encrypt it using the public key. An encrypted message can only be decrypted using the private key. As long as youre the only person with the private key, only you will be able to decrypt this message! The Diffie-Hellman algorithm is still used in practice, along with its successor, RSA. If youre interested in cryptography, Diffie-Hellman is a good place to start: its elegant and not too hard to follow. Linear programming I saved the best for last. Linear programming is one of the coolest things I know. Linear programming is used to maximize something given some constraints. For example, suppose your company makes two products, shirts and totes. Shirts need 1 meter of fabric and 5 buttons. Totes need 2 meters of fabric and 2 buttons. Y ou have 11 meters of fabric and 20 buttons. Y ou make 2 per shirt and 3 per tote. How many shirts and totes should you make to maximize your profit? Here youre trying to maximize profit, and youre constrained by the amount of materials you have. Another example: youre a politician, and you want to maximize the number of votes you get. Y our research has shown that it takes an average of an hour of work (marketing, research, and so on) for each vote from a San Franciscan or 1.5 hoursvote from a Chicagoan. Y ou need at least 500 San Franciscans and at least 300 Chicagoans. Y ou have 219 Epilogue 50 days. It also costs you 2San Franciscan versus 1Chicagoan. Y our total budget is 1,500. Whats the maximum number of total votes you can get (San Francisco Chicago)? Here youre trying to maximize votes, and youre constrained by time and money. Y ou might be thinking, Y ouve talked about a lot of optimization topics in this book. How are they related to linear programming? All the graph algorithms can be done through linear programming instead. Linear programming is a much more general framework, and graph problems are a subset of that. I hope your mind is blown! Linear programming uses the Simplex algorithm. Its a complex algorithm, which is why I didnt include it in this book. If youre interested in optimization, look up linear programming! Epilogue I hope this quick tour of 10 algorithms showed you how much more is left to discover. I think the best way to learn is to find something youre interested in and dive in. This book gave you a solid foundation to do just that. 221 answers to exercises CHAPTER 1 1.1 Suppose you have a sorted list of 128 names, and youre searching through it using binary search. Whats the maximum number of steps it would take? Answer: 7. 1.2 Suppose you double the size of the list. Whats the maximum number of steps now? Answer: 8. 1.3 Y ou have a name, and you want to find the persons phone number in the phone book. Answer: O(log n). 1.4 Y ou have a phone number, and you want to find the persons name in the phone book. (Hint: Y oull have to search through the whole book!) Answer: O(n). 1.5 Y ou want to read the numbers of every person in the phone book. Answer: O(n). 1.6 Y ou want to read the numbers of just the As. Answer: O(n). Y ou may think, Im only doing this for 1 out of 26 characters, so the run time should be O( n26). A simple rule to remember is, ignore numbers that are added, subtracted, multiplied, or divided. None of these are correct Big O run times: 222 answers to exercises O(n 26), O( n - 26), O( n 26), O( n 26). Theyre all the same as O(n)! Why? If youre curious, flip to Big O notation revisited, in chapter 4, and read up on constants in Big O notation (a constant is just a number; 26 was the constant in this question). CHAPTER 2 2.1 Suppose youre building an app to keep track of your finances. Every day, you write down everything you spent money on. At the end of the month, you review your expenses and sum up how much you spent. So, you have lots of inserts and a few reads. Should you use an array or a list? Answer: In this case, youre adding expenses to the list every day and reading all the expenses once a month. Arrays have fast reads and slow inserts. Linked lists have slow reads and fast inserts. Because youll be inserting more often than reading, it makes sense to use a linked list. Also, linked lists have slow reads only if youre accessing random elements in the list. Because youre reading every element in the list, linked lists will do well on reads too. So a linked list is a good solution to this problem. 2.2 Suppose youre building an app for restaurants to take customer orders. Y our app needs to store a list of orders. Servers keep adding orders to this list, and chefs take orders off the list and make them. Its an order queue: servers add orders to the back of the queue, and the chef takes the first order off the queue and cooks it. 223 Would you use an array or a linked list to implement this queue? (Hint: linked lists are good for insertsdeletes, and arrays are good for random access. Which one are you going to be doing here?) Answer: A linked list. Lots of inserts are happening (servers adding orders), which linked lists excel at. Y ou dont need search or random access (what arrays excel at), because the chefs always take the first order off the queue. 2.3 Lets run a thought experiment. Suppose Facebook keeps a list of usernames. When someone tries to log in to Facebook, a search is done for their username. If their name is in the list of usernames, they can log in. People log in to Facebook pretty often, so there are a lot of searches through this list of usernames. Suppose Facebook uses binary search to search the list. Binary search needs random accessyou need to be able to get to the middle of the list of usernames instantly. Knowing this, would you implement the list as an array or a linked list? Answer: A sorted array. Arrays give you random accessyou can get an element from the middle of the array instantly. Y ou cant do that with linked lists. T o get to the middle element in a linked list, youd have to start at the first element and follow all the links down to the middle element. 2.4 People sign up for Facebook pretty often, too. Suppose you decided to use an array to store the list of users. What are the downsides of an array for inserts? In particular, suppose youre using binary search to search for logins. What happens when you add new users to an array? Answer: Inserting into arrays is slow. Also, if youre using binary search to search for usernames, the array needs to be sorted. Suppose someone named Adit B signs up for Facebook. Their name will be inserted at the end of the array. So you need to sort the array every time a name is inserted!answers to exercises 224 2.5 In reality, Facebook uses neither an array nor a linked list to store user information. Lets consider a hybrid data structure: an array of linked lists. Y ou have an array with 26 slots. Each slot points to a linked list. For example, the first slot in the array points to a linked list containing all the usernames starting with a. The second slot points to a linked list containing all the usernames starting with b, and so on. Suppose Adit B signs up for Facebook, and you want to add them to the list. Y ou go to slot 1 in the array, go to the linked list for slot",
      "source": "Grokking Algorithms - Chapter 20",
      "timestamp": "2025-11-14T00:38:40.764194",
      "type": "book_content",
      "book_title": "Grokking Algorithms",
      "chapter_title": "Chapter 20",
      "chapter_number": 20
    },
    {
      "text": "1, and add Adit B at the end. Now, suppose you want to search for Zakhir H. Y ou go to slot 26, which points to a linked list of all the Z names. Then you search through that list to find Zakhir H. Compare this hybrid data structure to arrays and linked lists. Is it slower or faster than each for searching and inserting? Y ou dont have to give Big O run times, just whether the new data structure would be faster or slower. Answer: Searchingslower than arrays, faster than linked lists. Insertingfaster than arrays, same amount of time as linked lists. So its slower for searching than an array, but faster or the same as linked lists for everything. Well talk about another hybrid data structure called a hash table later in the book. This should give you an idea of how you can build up more complex data structures from simple ones. So what does Facebook really use? It probably uses a dozen different databases, with different data structures behind them: hash tables, B-trees, and others. Arrays and linked lists are the building blocks for these more complex data structures.answers to exercises 225 CHAPTER 3 3.1 Suppose I show you a call stack like this. What information can you give me, just based on this call stack? Answer: Here are some things you could tell me: The greet function is called first, with name maggie. Then the greet function calls the greet2 function, with name maggie . At this point, the greet function is in an incomplete, suspended state. The current function call is the greet2 function. After this function call completes, the greet function will resume. 3.2 Suppose you accidentally write a recursive function that runs forever. As you saw, your computer allocates memory on the stack for each function call. What happens to the stack when your recursive function runs forever? Answer: The stack grows forever. Each program has a limited amount of space on the call stack. When your program runs out of space (which it eventually will), it will exit with a stack- overflow error.answers to exercises 226 CHAPTER 4 4.1 Write out the code for the earlier sum function. Answer: def sum(list): if list : return 0 return list0 sum(list1:) 4.2 Write a recursive function to count the number of items in a list. Answer: def count(list): if list : return 0 return 1 count(list1:) 4.3 Find the maximum numbe r in a list. Answer: def max(list): if len(list) 2: return list0 if list0 list1 else list1 sub_max max(list1:) return list0 if list0 sub_max else sub_max 4.4 Remember binary search from chapter 1? Its a divide-and- conquer algorithm, too. Can you come up with the base case and recursive case for binary search? Answer: The base case for binary search is an array with one item. If the item youre looking for matches the item in the array, you found it! Otherwise, it isnt in the array. In the recursive case for binary search, you split the array in half, throw away one half, and call binary search on the other half. How long would each of these operations take in Big O notation? 4.5 Printing the value of each element in an array. Answer: O(n) 4.6 Doubling the value of each element in an array. Answer: O(n) 4.7 Doubling the value of just the first element in an array. Answer: O(1)answers to exercises 227 4.8 Creating a multiplication table with all the elements in the array. So if your array is 2, 3, 7, 8, 10, you first multiply every element by 2, then multiply every element by 3, then by 7, and so on. Answer: O(n2) CHAPTER 5 Which of these hash functions are consistent? 5.1 f(x) 1 Returns 1 for all input Answer: Consistent 5.2 f(x) rand() Returns a random number every time Answer: Not consistent 5.3 f(x) next_empty_slot() Returns the index of the next empty slot in the hash table Answer: Not consistent 5.4 f(x) len(x) Uses the length of the string as the index Answer: Consistent Suppose you have these four hash functions that work with strings: A. Return 1 for all input. B. Use the length of the string as the index. C. Use the first character of the string as the index. So, all strings starting with a are hashed together, and so on. D. Map every letter to a prime number: a 2, b 3, c 5, d 7, e 11, and so on. For a string, the hash function is the sum of all the characters modulo the size of the hash. For example, if your hash size is 10, and the string is bag , the index is 3 2 17 10 22 10 2. For each of the following examples, which hash functions would provide a good distribution? Assume a hash table size of 10 slots. 5.5 A phonebook where the keys are names and values are phone numbers. The names are as follows: Esther, Ben, Bob, and Dan. Answer: Hash functions C and D would give a good distribution.answers to exercises 228 5.6 A mapping from battery size to power. The sizes are A, AA, AAA, and AAAA. Answer: Hash functions B and D would give a good distribution. 5.7 A mapping from book titles to authors. The titles are Maus , Fun Home , and Watchmen . Answer: Hash functions B, C, and D would give a good distribution. CHAPTER 6 Run the breadth-first search algorithm on each of these graphs to find the solution. 6.1 Find the length of the sho rtest path from start to finish. Answer: The shortest path has a length of 2. 6.2 Find the length of the sho rtest path from cab to bat . Answer: The shortest path has a length of 2.answers to exercises 229 6.3 Heres a small graph of my morning routine. For these three lists, mark whether each one is valid or invalid. Answers: AInvalid; BValid; CInvalid. 6.4 Heres a larger graph. Make a valid list for this graph. Answer: 1Wake up; 2Exercise; 3Shower; 4Brush teeth; 5Get dressed; 6Pack lunch; 7Eat breakfast.answers to exercises 230 6.5 Which of the following graphs are also trees? Answers: ATree; BNot a tree; CTree. The last example is just a sideways tree. Trees are a subset of graphs. So a tree is always a graph, but a graph may or may not be a tree. CHAPTER 7 7.1 In each of these graphs, what is the weight of the shortest path from start to finish? Answers: A: A8; B60; CTrick question. No shortest path is possible (negative-weight cycle).answers to exercises 231 CHAPTER 8 8.1 Y ou work for a furniture company, and you have to ship furniture all over the country. Y ou need to pack your truck with boxes. All the boxes are of different sizes, and youre trying to maximize the space you use in each truck. How would you pick boxes to maximize space? Come up with a greedy strategy. Will that give you the optimal solution? Answer: A greedy strategy would be to pick the largest box that will fit in the remaining space, and repeat until you cant pack any more boxes. No, this wont give you the optimal solution. 8.2 Y oure going to Europe, and you have seven days to see everything you can. Y ou assign a point value to each item (how much you want to see it) and estimate how long it takes. How can you maximize the point total (seeing all the things you really want to see) during your stay? Come up with a greedy strategy. Will that give you the optimal solution? Answer: Keep picking the activity with the highest point value that you can still do in the time you have left. Stop when you cant do anything else. No, this wont give you the optimal solution. For each of these algorithms, say whether its a greedy algorithm or not. 8.3 Quicksort Answer: No. 8.4 Breadth-first search Answer: Y es. 8.5 Dijkstras algorithm Answer: Y es. 8.6 A postman needs to deliver to 20 homes. He needs to find the shortest route that goes to all 20 homes. Is this an NP-complete problem? Answer: Y es. 8.7 Finding the largest clique in a se t of people (a clique is a set of people who all know each other). Is this an NP-complete problem? Answer: Y es.answers to exercises 232 8.8 Y oure making a map of the USA, and you need to color adjacent states with different colors. Y ou have to find the minimum number of colors you need so that no two adjacent states are the same color. Is this an NP-complete problem? Answer: Y es. CHAPTER 9 9.1 Suppose you can steal another item: an MP3 player. It weighs 1 lb and is worth 1,000. Should you steal it? Answer: Y es. Then you could steal the MP3 player, the iPhone, and the guitar, worth a total of 4,500. 9.2 Suppose youre going camping. Y ou have a knapsack that holds 6 lb, and you can take the following items. They each have a value, and the higher the value, the more important the item is: Water, 3 lb, 10 Book, 1 lb, 3 Food, 2 lb, 9 Jacket, 2 lb, 5 Camera, 1 lb, 6 Whats the optimal set of items to take on your camping trip? Answer: Y ou should take water, food, and a camera. 9.3 Draw and fill in the grid to calculate the longest common substring between blue and clues . Answer: answers to exercises 233 CHAPTER 10 10.1 In the Netflix example, you calculated distance between two different users using the distance formula. But not all users rate movies the same way. Suppose you have two users, Y ogi and Pinky, who have the same taste in movies. But Y ogi rates any movie he likes as a 5, whereas Pinky is choosier and reserves the 5s for only the best. Theyre well matched, but according to the distance algorithm, they arent neighbors. How would you take their different rating strategies into account? Answer: Y ou could use something called normalization . Y ou look at the average rating for each person and use it to scale their ratings. For example, you might notice that Pinkys average rating is 3, whereas Y ogis average rating is 3.5. So you bump up Pinkys ratings a little, until her average rating is 3.5 as well. Then you can compare their ratings on the same scale. 10.2 Suppose Netflix nominates a group of influencers. For example, Quentin Tarantino and Wes Anderson are influencers on Netflix, so their ratings count for more than a normal users. How would you change the recommendations system so its biased toward the ratings of influencers? Answer: Y ou could give more weight to the ratings of the influencers when using KNN. Suppose you have three neighbors: Joe, Dave, and Wes Anderson (an influencer). They rated Caddyshack a 3, a 4, and a 5, respectively. Instead of just taking the average of their ratings (3 4 5 3 4 stars), you could give Wes Andersons rating more weight: 3 4 5 5 5 5 4.4 stars. 10.3 Netflix has millions of users. The earlier example looked at the five closest neighbors for building the recommendations system. Is this too low? T oo high? Answer: Its too low. If you look at fewer neighbors, theres a bigger chance that the results will be skewed. A good rule of thumb is, if you have N users, you should look at sqrt( N) neighbors.answers to exercises 235A adit.io 212 algorithms approximation algorithms 147150 calculating answer 149 code for setup 147148 sets 149150 Bellman-Ford 130 Big O notation and 1019 common run times 1516 drawing squares example 1314 exercises 17 growth of run times at differ - ent rates 1113 overview 10 traveling salesperson prob - lem 1719 worst-case run",
      "source": "Grokking Algorithms - Chapter 21",
      "timestamp": "2025-11-14T00:38:40.764194",
      "type": "book_content",
      "book_title": "Grokking Algorithms",
      "chapter_title": "Chapter 21",
      "chapter_number": 21
    },
    {
      "text": "time 15 binary search 310 better way to search 57 exercises 69 overview 34 running time 10 breadth-first search 107113 exercise 111113 running time 111 Dijkstras algorithm 115139 exercise 139 implementation 131139negative-weight edges 128130 overview 115119 terminology related to 120122 trading for piano example 122128 distributed, usefulness of 209 Euclids 54 Feynman 180 greedy algorithms 141159 classroom scheduling prob - lem 142144 exercises 145146 knapsack problem 144145 NP-complete problems 152158 overview 141 set-covering problem 146151 HyperLogLog algorithm 213 k-nearest neighbors algorithm building recommendations system 189194 classifying oranges vs. grape - fruit 187189 exercises 195199 machine learning 199201 MapReduce algorithm 209211 map function 209210 reduce function 210211 parallel 208 SHA algorithms 213216checking passwords 215216 comparing files 214 overview 213 approximation algorithms 147150 calculating answer 149 code for setup 147148 sets 149150 arrays deletions and 30 exercises 3031 insertions and 2829 overview 28 terminology used with 2728 uses of 2627 B base case 4041, 41, 53 Bellman-Ford algorithm 130 best_station 151 Better Explained website 207 Big O notation 1019 common run times 1516 drawing squares example 1314 exercises 17 growth of run times at different rates 1113 overview 10 quicksort and 6671 average case vs. worst case 6871 exercises 72Index 236 index merge sort vs. quicksort 6768 overview 66 traveling salesperson problem 1719 worst-case run time 15 binary search 310 better way to search 57 exercises 69 overview 34 running time 10 binary search trees 204205 bloom filters 211212 breadth-first search 95113 graphs and 99104 exercises 104 finding shortest path 102103 overview 107110 queues 103104 implementing 105106 implementing algorithm 107113 exercise 111113 overview 107110 running time 111 overview 9598 built-in hash table 90 bye function 44 C cache, using hash tables as 8385 Caldwell, Leigh 40 call stack overview 4245 with recursion 4550 cheapest node 117, 125 classification 189 classroom scheduling problem 142144 common substring 184 constants 35 constant time 8889 covered set 151 Ctrl-C shortcut 41 cycles, graph 121D DAGs (directed acyclic graphs) 122 DC (divide and conquer) 5260 def countdown(i) function 41 deletions 30 deque function 107 dict function 78 Diffie-Hellman key exchange 217 Dijkstras algorithm 115139 exercise 139 implementation 131139 negative-weight edges 128130 overview 115119 terminology related to 120122 trading for piano example 122128 directed graph 106 distance formula 194 distributed algorithms 209 DNS resolution 81 double-ended queue 107 duplicate entries, preventing 8183 dynamic programming 161185 exercises 173178, 186 knapsack problem 161171 changing order of rows 174 FAQ 171173 filling in grid column-wise 174 guitar row 164167 if solution doesnt fill knapsack completely 178 if solution requires more than two sub-knapsacks 177 laptop row 168170 optimizing travel itinerary 175177 overview 161 simple solution 162163 stealing fractions of an item 175 stereo row 166168 longest common substring 178185filling in grid 180182 longest common subsequence 183186 making grid 179180 overview 179180 solution 182183 E edges 99, 113 empty array 57, 58 encrypted messages 218 enqueue operation 104 Euclids algorithm 54 F Facebook, user login and signups example 31 fact function 45, 47 factorial function 45 factorial time 19 false negatives 212 false positives 212 Feynman algorithm 180 FIFO (First In, First Out) data structure 104 find_lowest_cost_node function 134, 139 first-degree connection 103 for loop 149 for node 136 Fourier transform 207208 G git diff 185 graphs breadth-first search and 99104 exercises 104 finding shortest path 102104 overview 99101 queues 103104 overview 9698 graphstart hash table 132 greedy algorithms 141159 237 index classroom scheduling problem 142144 exercises 145146 knapsack problem 144145 NP-complete problems 152158 set-covering problem 146151 approximation algorithms 147150 back to code 151152 exercise 152 overview 146 greet2 function 44 greet function 4345 H hash tables 7388 collisions 8688 hash functions 7678 performance 8891 exercises 93 good hash function 9091 load factor 9091 use cases 7986 preventing duplicate entries 8183 using hash tables as cache 8385 using hash tables for lookups 7981 Haskell 59 HyperLogLog algorithm 213 I inductive proofs 65 infinity, representing in Python 133 insertions 2829 inverted indexes 206207 IP address, mapping web address to 81 J JPG format 207K Khan Academy 7, 54 knapsack problem changing order of rows 174 FAQ 171173 filling in grid column-wise 174 guitar row 164167 if solution doesnt fill knapsack completely 178 if solution requires more than two sub-knapsacks 177 laptop row 168170 optimizing travel itinerary 175177 overview 144145, 161 simple solution 162163 stealing fractions of an item 175 stereo row 166168 k-nearest neighbors algorithm building recommendations system 189194 classifying oranges vs. grapefruit 187189 exercises 195198 machine learning 199201 L Levenshtein distance 185 LIFO (Last In, Last Out) data structure 104 linear programming 218219 linear time 10, 15, 89 linked lists 2526 deletions and 30 exercises 28, 30 31 insertions and 2829 overview 2526 terminology used with 2728 load balancing 208 locality-sensitive hashing 216 logarithmic time. See log time logarithms 7 log time 7, 10, 15 lookups, using hash tables for 7981M machine learning 199201 MapReduce algorithm map function 209210 reduce function 210211 memory 2223 merge sort vs. quicksort 6768 MP3 format 207 N Naive Bayes classifier 200 name variable 43 neighbors 99 n! (n factorial) operations 19 nodes 99, 105 n operations 12 NP-complete problems 152158 O OCR (optical character recognition) 199201 P parallel algorithms 208 partitioning 61 person_is_seller function 108, 111 pivot element 60 pop (remove and read) action 42 Print function 43 print_items function 67 private key, Diffie-Hellman 218 probabilistic data structure 212 pseudocode 38, 40, 182 public key, Diffie-Hellman 218 push (insert) action 42 Pythagorean formula 191 Q queues 3031 quicksort, Big O notation and 6671 238 average case vs. worst case 6871 exercises 72 merge sort vs. quicksort 6768 R random access 30 recommendations system, building 189194 recursion 3749 base case and recursive case 4041 call stack with 4550 overview 3739 regression 196 resizing 91 run time common run times 1516 growth of at different rates 1113 overview 10 S searches binary search 310 as better way to search 57 exercises 69 overview 34running time 10 breadth-first search graphs and 99104 implementing 105106 implementing algorithm 107113 selection sort 3233 sequential access 30 set-covering problem 146151 approximation algorithms calculating answer 149 code for setup 147148 sets 149150 exercise 152 overview 146 set difference 150 set intersection 150 sets 148 set union 150 SHA algorithms 213216 checking passwords 215216 comparing files 214 overview 213 SHA (Secure Hash Algorithm) function 92, 214 shortest path 98, 128 signals, processing 207 Simhash 216, 217 simple search 5, 11, 200 SQL query 209stacks 4249 call stack 4345 call stack with recursion 4550 exercise 45, 4950 overview 42 states_covered set 149 states_for_station 151 states_needed 151 stock market, predicting 201 strings, mapping to numbers 76 sum function 57, 59 T third-degree connection 103 topological sort 112 training 200 trees 203206 U undirected graph 122 unique searches 213 unweighted graph 120 W weighted graph 120index",
      "source": "Grokking Algorithms - Chapter 22: Search",
      "timestamp": "2025-11-14T00:38:40.764194",
      "type": "book_content",
      "book_title": "Grokking Algorithms",
      "chapter_title": "Chapter 22: Search",
      "chapter_number": 22
    }
  ],
  "news": [
    {
      "title": "Starmer's chief of staff McSweeney not leaving role over briefing war, BBC told",
      "summary": "The PM's top aide was not involved \"directly or indirectly\" in briefings against cabinet ministers, sources tell the BBC.",
      "link": "https://www.bbc.com/news/articles/cn8vn4vv87xo?at_medium=RSS&at_campaign=rss",
      "published": "Thu, 13 Nov 2025 17:20:59 GMT",
      "source": "https://feeds.bbci.co.uk/news/rss.xml",
      "timestamp": "2025-11-14T00:19:24.370326",
      "type": "real_time_news"
    },
    {
      "title": "Missing information and racism concerns: Five key failings in Sara Sharif review",
      "summary": "Review finds \"different actions could and should have been taken\" leading up to the 10-year-old's death.",
      "link": "https://www.bbc.com/news/articles/c1e31vdjjl5o?at_medium=RSS&at_campaign=rss",
      "published": "Thu, 13 Nov 2025 16:03:44 GMT",
      "source": "https://feeds.bbci.co.uk/news/rss.xml",
      "timestamp": "2025-11-14T00:19:24.370326",
      "type": "real_time_news"
    },
    {
      "title": "BBC faces fresh claim of misleading Trump edit",
      "summary": "The clip aired on Newsnight in 2022, two years before the Panorama that led to the director-general's resignation.",
      "link": "https://www.bbc.com/news/articles/cr5e9erpnzlo?at_medium=RSS&at_campaign=rss",
      "published": "Thu, 13 Nov 2025 18:27:45 GMT",
      "source": "https://feeds.bbci.co.uk/news/rss.xml",
      "timestamp": "2025-11-14T00:19:24.370326",
      "type": "real_time_news"
    },
    {
      "title": "Police and crime commissioners to be scrapped in England and Wales",
      "summary": "The government says it will save £100m over this Parliament and less than 20% of voters can name their PCC.",
      "link": "https://www.bbc.com/news/articles/c93d4dd3l3lo?at_medium=RSS&at_campaign=rss",
      "published": "Thu, 13 Nov 2025 18:31:04 GMT",
      "source": "https://feeds.bbci.co.uk/news/rss.xml",
      "timestamp": "2025-11-14T00:19:24.370326",
      "type": "real_time_news"
    },
    {
      "title": "Amber warnings issued ahead of heavy rain from Storm Claudia",
      "summary": "Storm Claudia is set to bring heavy and persistent rain to parts of the UK with amber warnings issued with risk of flooding and disruption.",
      "link": "https://www.bbc.com/weather/articles/cj0e3y6yy99o?at_medium=RSS&at_campaign=rss",
      "published": "Thu, 13 Nov 2025 16:51:01 GMT",
      "source": "https://feeds.bbci.co.uk/news/rss.xml",
      "timestamp": "2025-11-14T00:19:24.370326",
      "type": "real_time_news"
    },
    {
      "title": "Faisal Islam: Slow growth raises stakes even higher for the Budget",
      "summary": "The Budget somehow has to provide certainty, boost consumer and business confidence, and fill a large fiscal gap.",
      "link": "https://www.bbc.com/news/articles/c93x5xw22n6o?at_medium=RSS&at_campaign=rss",
      "published": "Thu, 13 Nov 2025 12:47:59 GMT",
      "source": "https://feeds.bbci.co.uk/news/rss.xml",
      "timestamp": "2025-11-14T00:19:24.370326",
      "type": "real_time_news"
    },
    {
      "title": "Titanic passenger's watch expected to fetch £1m",
      "summary": "The watch belonged to Bavarian-born American businessman Isidor Straus, who died in the disaster.",
      "link": "https://www.bbc.com/news/articles/cr5e9n3q8qdo?at_medium=RSS&at_campaign=rss",
      "published": "Thu, 13 Nov 2025 16:03:28 GMT",
      "source": "https://feeds.bbci.co.uk/news/rss.xml",
      "timestamp": "2025-11-14T00:19:24.370326",
      "type": "real_time_news"
    },
    {
      "title": "Guests ejected mid-stay from bankrupt hotel chain Sonder",
      "summary": "Sonder guests have complained that they had to leave their accommodation as the firm files for a sudden bankruptcy.",
      "link": "https://www.bbc.com/news/articles/c364yg7g351o?at_medium=RSS&at_campaign=rss",
      "published": "Thu, 13 Nov 2025 17:20:05 GMT",
      "source": "https://feeds.bbci.co.uk/news/rss.xml",
      "timestamp": "2025-11-14T00:19:24.370326",
      "type": "real_time_news"
    },
    {
      "title": "Royal escort motorcyclist cleared over pedestrian's death",
      "summary": "Met Police officer PC Christopher Harrison was accused of causing death by careless driving.",
      "link": "https://www.bbc.com/news/articles/cy0yj4kp0eyo?at_medium=RSS&at_campaign=rss",
      "published": "Thu, 13 Nov 2025 16:16:32 GMT",
      "source": "https://feeds.bbci.co.uk/news/rss.xml",
      "timestamp": "2025-11-14T00:19:24.370326",
      "type": "real_time_news"
    },
    {
      "title": "Russia's attacks have ramped up - Ukraine is fighting to hold on through another winter",
      "summary": "Years of conflict have taken their toll and the war of attrition is continuing on the homefront - but Ukrainians are fighting back hard by trying to keep morale high",
      "link": "https://www.bbc.com/news/articles/cly98qp99l8o?at_medium=RSS&at_campaign=rss",
      "published": "Thu, 13 Nov 2025 06:00:11 GMT",
      "source": "https://feeds.bbci.co.uk/news/rss.xml",
      "timestamp": "2025-11-14T00:19:24.370326",
      "type": "real_time_news"
    },
    {
      "title": "Starmer's chief of staff McSweeney not leaving role over briefing war, BBC told",
      "summary": "The PM's top aide was not involved \"directly or indirectly\" in briefings against cabinet ministers, sources tell the BBC.",
      "link": "https://www.bbc.com/news/articles/cn8vn4vv87xo?at_medium=RSS&at_campaign=rss",
      "published": "Thu, 13 Nov 2025 17:20:59 GMT",
      "source": "https://feeds.bbci.co.uk/news/rss.xml",
      "timestamp": "2025-11-14T00:28:55.791202",
      "type": "real_time_news"
    },
    {
      "title": "Missing information and racism concerns: Five key failings in Sara Sharif review",
      "summary": "Review finds \"different actions could and should have been taken\" leading up to the 10-year-old's death.",
      "link": "https://www.bbc.com/news/articles/c1e31vdjjl5o?at_medium=RSS&at_campaign=rss",
      "published": "Thu, 13 Nov 2025 16:03:44 GMT",
      "source": "https://feeds.bbci.co.uk/news/rss.xml",
      "timestamp": "2025-11-14T00:28:55.791202",
      "type": "real_time_news"
    },
    {
      "title": "BBC faces fresh claim of misleading Trump edit",
      "summary": "The clip aired on Newsnight in 2022, two years before the Panorama that led to the director-general's resignation.",
      "link": "https://www.bbc.com/news/articles/cr5e9erpnzlo?at_medium=RSS&at_campaign=rss",
      "published": "Thu, 13 Nov 2025 18:27:45 GMT",
      "source": "https://feeds.bbci.co.uk/news/rss.xml",
      "timestamp": "2025-11-14T00:28:55.791202",
      "type": "real_time_news"
    },
    {
      "title": "Police and crime commissioners to be scrapped in England and Wales",
      "summary": "The government says it will save £100m over this Parliament and less than 20% of voters can name their PCC.",
      "link": "https://www.bbc.com/news/articles/c93d4dd3l3lo?at_medium=RSS&at_campaign=rss",
      "published": "Thu, 13 Nov 2025 18:31:04 GMT",
      "source": "https://feeds.bbci.co.uk/news/rss.xml",
      "timestamp": "2025-11-14T00:28:55.791202",
      "type": "real_time_news"
    },
    {
      "title": "Amber warnings issued ahead of heavy rain from Storm Claudia",
      "summary": "Storm Claudia is set to bring heavy and persistent rain to parts of the UK with amber warnings issued with risk of flooding and disruption.",
      "link": "https://www.bbc.com/weather/articles/cj0e3y6yy99o?at_medium=RSS&at_campaign=rss",
      "published": "Thu, 13 Nov 2025 16:51:01 GMT",
      "source": "https://feeds.bbci.co.uk/news/rss.xml",
      "timestamp": "2025-11-14T00:28:55.791202",
      "type": "real_time_news"
    },
    {
      "title": "Faisal Islam: Slow growth raises stakes even higher for the Budget",
      "summary": "The Budget somehow has to provide certainty, boost consumer and business confidence, and fill a large fiscal gap.",
      "link": "https://www.bbc.com/news/articles/c93x5xw22n6o?at_medium=RSS&at_campaign=rss",
      "published": "Thu, 13 Nov 2025 12:47:59 GMT",
      "source": "https://feeds.bbci.co.uk/news/rss.xml",
      "timestamp": "2025-11-14T00:28:55.791202",
      "type": "real_time_news"
    },
    {
      "title": "Titanic passenger's watch expected to fetch £1m",
      "summary": "The watch belonged to Bavarian-born American businessman Isidor Straus, who died in the disaster.",
      "link": "https://www.bbc.com/news/articles/cr5e9n3q8qdo?at_medium=RSS&at_campaign=rss",
      "published": "Thu, 13 Nov 2025 16:03:28 GMT",
      "source": "https://feeds.bbci.co.uk/news/rss.xml",
      "timestamp": "2025-11-14T00:28:55.791202",
      "type": "real_time_news"
    },
    {
      "title": "Guests ejected mid-stay from bankrupt hotel chain Sonder",
      "summary": "Sonder guests have complained that they had to leave their accommodation as the firm files for a sudden bankruptcy.",
      "link": "https://www.bbc.com/news/articles/c364yg7g351o?at_medium=RSS&at_campaign=rss",
      "published": "Thu, 13 Nov 2025 17:20:05 GMT",
      "source": "https://feeds.bbci.co.uk/news/rss.xml",
      "timestamp": "2025-11-14T00:28:55.791202",
      "type": "real_time_news"
    },
    {
      "title": "Royal escort motorcyclist cleared over pedestrian's death",
      "summary": "Met Police officer PC Christopher Harrison was accused of causing death by careless driving.",
      "link": "https://www.bbc.com/news/articles/cy0yj4kp0eyo?at_medium=RSS&at_campaign=rss",
      "published": "Thu, 13 Nov 2025 16:16:32 GMT",
      "source": "https://feeds.bbci.co.uk/news/rss.xml",
      "timestamp": "2025-11-14T00:28:55.791202",
      "type": "real_time_news"
    },
    {
      "title": "Russia's attacks have ramped up - Ukraine is fighting to hold on through another winter",
      "summary": "Years of conflict have taken their toll and the war of attrition is continuing on the homefront - but Ukrainians are fighting back hard by trying to keep morale high",
      "link": "https://www.bbc.com/news/articles/cly98qp99l8o?at_medium=RSS&at_campaign=rss",
      "published": "Thu, 13 Nov 2025 06:00:11 GMT",
      "source": "https://feeds.bbci.co.uk/news/rss.xml",
      "timestamp": "2025-11-14T00:28:55.791202",
      "type": "real_time_news"
    }
  ],
  "wikipedia": [
    {
      "title": "Artificial intelligence",
      "summary": "Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.\nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., language models and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being calle",
      "content": "Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.\nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., language models and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields. Some companies, such as OpenAI, Google DeepMind and Meta, aim to create artificial general intelligence (AGI)—AI that can complete virtually any cognitive task at least as well as a human.\nArtificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when graphics processing units started being used to accelerate neural networks and deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture. In the 2020s, an ongoing period of rapid progress in advanced generative AI became known as the AI boom. Generative AI's ability to create and modify content has led to several unintended consequences and harms, which has raised ethical concerns about AI's long-term effects and potential existential risks, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\n\n\n== Goals ==\nThe general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.\n\n\n=== Reasoning and problem-solving ===\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions. By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.\nMany of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": They become exponentially slower as the problems grow. Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments. Accurate and efficient reasoning is an unsolved problem.\n\n\n=== Knowledge representation ===\n\nKnowledge representation and knowledge engineering allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval, scene interpretation, clinical decision support, knowledge discovery (mining \"interesting\" and actionable inferences from large databases), and other areas.\nA knowledge base is a body of knowledge represented in a form that can be used by a program. An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge. Knowledge bases need to represent things such as objects, properties, categories, and relations between objects; situations, events, states, and time; causes and effects; knowledge about knowledge (what we know about what other people know); default reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing); and many other aspects and domains of knowledge.\nAmong the most difficult problems in knowledge representation are the breadth of com",
      "url": "https://en.wikipedia.org/wiki/Artificial_intelligence",
      "topic": "Artificial Intelligence",
      "timestamp": "2025-11-14T00:19:28.297446",
      "type": "wikipedia_content"
    },
    {
      "title": "Artificial general intelligence",
      "summary": "Artificial general intelligence (AGI)—sometimes called human‑level intelligence AI—is a type of artificial intelligence that would match or surpass human capabilities across virtually all cognitive tasks.\nSome researchers argue that state‑of‑the‑art large language models (LLMs) already exhibit signs of AGI‑level capability, while others maintain that genuine AGI has not yet been achieved. Beyond AGI, artificial superintelligence (ASI) would outperform the best human abilities across every domain by a wide margin.\nUnlike artificial narrow intelligence (ANI), whose competence is confined to well‑defined tasks, an AGI system can generalise knowledge, transfer skills between domains, and solve novel problems without task‑specific reprogramming. The concept does not, in principle, require the system to be an autonomous agent; a static model—such as a highly capable large language model—or an embodied robot could both satisfy the definition so long as human‑level breadth and proficiency are ",
      "content": "Artificial general intelligence (AGI)—sometimes called human‑level intelligence AI—is a type of artificial intelligence that would match or surpass human capabilities across virtually all cognitive tasks.\nSome researchers argue that state‑of‑the‑art large language models (LLMs) already exhibit signs of AGI‑level capability, while others maintain that genuine AGI has not yet been achieved. Beyond AGI, artificial superintelligence (ASI) would outperform the best human abilities across every domain by a wide margin.\nUnlike artificial narrow intelligence (ANI), whose competence is confined to well‑defined tasks, an AGI system can generalise knowledge, transfer skills between domains, and solve novel problems without task‑specific reprogramming. The concept does not, in principle, require the system to be an autonomous agent; a static model—such as a highly capable large language model—or an embodied robot could both satisfy the definition so long as human‑level breadth and proficiency are achieved.\nCreating AGI is a primary goal of AI research and of companies such as OpenAI, Google, xAI, and Meta. A 2020 survey identified 72 active AGI research and development projects across 37 countries.\nThe timeline for achieving human‑level AI remains deeply contested. Recent surveys of AI researchers give median forecasts ranging from the late 2020s to mid‑century, while still recording significant numbers who expect arrival much sooner—or never at all. There is debate on the exact definition of AGI and regarding whether modern LLMs such as GPT-4 are early forms of emerging AGI. AGI is a common topic in science fiction and futures studies.\nContention exists over whether AGI represents an existential risk. Many AI experts have stated that mitigating the risk of human extinction posed by AGI should be a global priority. Others find the development of AGI to be in too remote a stage to present such a risk.\n\n\n== Terminology ==\nAGI is also known as strong AI, full AI, human-level AI, human-level intelligent AI, or general intelligent action.\nSome academic sources reserve the term \"strong AI\" for computer programs that will experience sentience or consciousness. In contrast, weak AI (or narrow AI) can solve one specific problem but lacks general cognitive abilities. Some academic sources use \"weak AI\" to refer more broadly to any programs that neither experience consciousness nor have a mind in the same sense as humans.\nRelated concepts include artificial superintelligence and transformative AI. An artificial superintelligence (ASI) is a hypothetical type of AGI that is much more generally intelligent than humans, while the notion of transformative AI relates to AI having a large impact on society, for example, similar to the agricultural or industrial revolution.\nA framework for classifying AGI by performance and autonomy was proposed in 2023 by Google DeepMind researchers. They define five performance levels of AGI: emerging, competent, expert, virtuoso, and superhuman. For example, a competent AGI is defined as an AI that outperforms 50% of skilled adults in a wide range of non-physical tasks, and a superhuman AGI (i.e. an artificial superintelligence) is similarly defined but with a threshold of 100%. They consider large language models like ChatGPT or LLaMA 2 to be instances of emerging AGI (comparable to unskilled humans). Regarding the autonomy of AGI and associated risks, they define five levels: tool (fully in human control), consultant, collaborator, expert, and agent (fully autonomous).\n\n\n== Characteristics ==\n\nVarious popular definitions of intelligence have been proposed. One of the leading proposals is the Turing test. However, there are other well-known definitions, and some researchers disagree with the more popular approaches.\n\n\n=== Intelligence traits ===\nResearchers generally hold that a system is required to do all of the following to be regarded as an AGI:\n\nreason, use strategy, solve puzzles, and make judgments under uncertainty,\nrepresent knowledge, including common sense knowledge,\nplan,\nlearn,\ncommunicate in natural language,\nif necessary, integrate these skills in completion of any given goal.\nMany interdisciplinary approaches (e.g. cognitive science, computational intelligence, and decision making) consider additional traits such as imagination (the ability to form novel mental images and concepts) and autonomy.\nComputer-based systems that exhibit many of these capabilities exist (e.g. see computational creativity, automated reasoning, decision support system, robot, evolutionary computation, intelligent agent). There is debate about whether modern AI systems possess them to an adequate degree.\n\n\n=== Physical traits ===\nOther capabilities are considered desirable in intelligent systems, as they may affect intelligence or aid in its expression. These include:\n\nthe ability to sense (e.g. see, hear, etc.), and\nthe ability to act (e.g. move and manipulate objects, change location to explore, etc.)\nThis in",
      "url": "https://en.wikipedia.org/wiki/Artificial_general_intelligence",
      "topic": "Artificial Intelligence",
      "timestamp": "2025-11-14T00:19:30.966455",
      "type": "wikipedia_content"
    },
    {
      "title": "Attention (machine learning)",
      "summary": "In machine learning, attention is a method that determines the importance of each component in a sequence relative to the other components in that sequence. In natural language processing, importance is represented by \"soft\" weights assigned to each word in a sentence. More generally, attention encodes vectors called token embeddings across a fixed-width sequence that can range from tens to millions of tokens in size.\nUnlike \"hard\" weights, which are computed during the backwards training pass, \"soft\" weights exist only in the forward pass and therefore change with every step of the input. Earlier designs implemented the attention mechanism in a serial recurrent neural network (RNN) language translation system, but a more recent design, namely the transformer, removed the slower sequential RNN and relied more heavily on the faster parallel attention scheme.\nInspired by ideas about attention in humans, the attention mechanism was developed to address the weaknesses of using information ",
      "content": "In machine learning, attention is a method that determines the importance of each component in a sequence relative to the other components in that sequence. In natural language processing, importance is represented by \"soft\" weights assigned to each word in a sentence. More generally, attention encodes vectors called token embeddings across a fixed-width sequence that can range from tens to millions of tokens in size.\nUnlike \"hard\" weights, which are computed during the backwards training pass, \"soft\" weights exist only in the forward pass and therefore change with every step of the input. Earlier designs implemented the attention mechanism in a serial recurrent neural network (RNN) language translation system, but a more recent design, namely the transformer, removed the slower sequential RNN and relied more heavily on the faster parallel attention scheme.\nInspired by ideas about attention in humans, the attention mechanism was developed to address the weaknesses of using information from the hidden layers of recurrent neural networks. Recurrent neural networks favor more recent information contained in words at the end of a sentence, while information earlier in the sentence tends to be attenuated. Attention allows a token equal access to any part of a sentence directly, rather than only through the previous state.\n\n\n== History ==\n\nAdditional surveys of the attention mechanism in deep learning are provided by Niu et al. and Soydaner.\nThe major breakthrough came with self-attention, where each element in the input sequence attends to all others, enabling the model to capture global dependencies. This idea was central to the Transformer architecture, which replaced recurrence with attention mechanisms. As a result, Transformers became the foundation for models like BERT, T5 and generative pre-trained transformers (GPT). \n\n\n== Overview ==\n\nThe modern era of machine attention was revitalized by grafting an attention mechanism (Fig 1.  orange) to an Encoder-Decoder.\n\nFigure 2 shows the internal step-by-step operation of the attention block (A) in Fig 1.\n\n\n=== Interpreting attention weights ===\nIn translating between languages, alignment is the process of matching words from the source sentence to words of the translated sentence. Networks that perform verbatim translation without regard to word order would show the highest scores along the (dominant) diagonal of the matrix. The off-diagonal dominance shows that the attention mechanism is more nuanced. \nConsider an example of translating I love you to French. On the first pass through the decoder, 94% of the attention weight is on the first English word I, so the network offers the word je. On the second pass of the decoder, 88% of the attention weight is on the third English word you, so it offers t'. On the last pass, 95% of the attention weight is on the second English word love, so it offers aime.\nIn the I love you example, the second word love is aligned with the third word aime. Stacking soft row vectors together for je, t', and aime yields an alignment matrix:\n\nSometimes, alignment can be multiple-to-multiple. For example, the English phrase look it up corresponds to cherchez-le. Thus, \"soft\" attention weights work better than \"hard\" attention weights (setting one attention weight to 1, and the others to 0), as we would like the model to make a context vector consisting of a weighted sum of the hidden vectors, rather than \"the best one\", as there may not be a best hidden vector.\n\n\n== Variants ==\n\nMany variants of attention implement soft weights, such as\n\nfast weight programmers, or fast weight controllers (1992). A \"slow\" neural network outputs the \"fast\" weights of another neural network through outer products. The slow network learns by gradient descent. It was later renamed as \"linearized self-attention\".\nBahdanau-style attention, also referred to as additive attention,\nLuong-style attention, which is known as multiplicative attention,\nEarly attention mechanisms similar to modern self-attention were proposed using recurrent neural networks. However, the highly parallelizable self-attention was introduced in 2017 and successfully used in the Transformer model,\npositional attention and factorized positional attention.\nFor convolutional neural networks, attention mechanisms can be distinguished by the dimension on which they operate, namely: spatial attention, channel attention, or combinations.\nThese variants recombine the encoder-side inputs to redistribute those effects to each target output. Often, a correlation-style matrix of dot products provides the re-weighting coefficients.  In the figures below, W is the matrix of context attention weights, similar to the formula in Overview section above.\n\n\n== Optimizations ==\n\n\n=== Flash attention ===\nThe size of the attention matrix is proportional to the square of the number of input tokens. Therefore, when the input is long, calculating the attention matrix requires a lot of GPU memory. Flash attention i",
      "url": "https://en.wikipedia.org/wiki/Attention_(machine_learning)",
      "topic": "Machine Learning",
      "timestamp": "2025-11-14T00:19:36.802162",
      "type": "wikipedia_content"
    },
    {
      "title": "Neural network (machine learning)",
      "summary": "In machine learning, a neural network or neural net (NN), also called artificial neural network (ANN), is a computational model inspired by the structure and functions of biological neural networks.\nA neural network consists of connected units or nodes called artificial neurons, which loosely model the neurons in the brain. Artificial neuron models that mimic biological neurons more closely have also been recently investigated and shown to significantly improve performance. These are connected by edges, which model the synapses in the brain. Each artificial neuron receives signals from connected neurons, then processes them and sends a signal to other connected neurons. The \"signal\" is a real number, and the output of each neuron is computed by some non-linear function of the totality of its inputs, called the activation function. The strength of the signal at each connection is determined by a weight, which adjusts during the learning process.\nTypically, neurons are aggregated into la",
      "content": "In machine learning, a neural network or neural net (NN), also called artificial neural network (ANN), is a computational model inspired by the structure and functions of biological neural networks.\nA neural network consists of connected units or nodes called artificial neurons, which loosely model the neurons in the brain. Artificial neuron models that mimic biological neurons more closely have also been recently investigated and shown to significantly improve performance. These are connected by edges, which model the synapses in the brain. Each artificial neuron receives signals from connected neurons, then processes them and sends a signal to other connected neurons. The \"signal\" is a real number, and the output of each neuron is computed by some non-linear function of the totality of its inputs, called the activation function. The strength of the signal at each connection is determined by a weight, which adjusts during the learning process.\nTypically, neurons are aggregated into layers. Different layers may perform different transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly passing through multiple intermediate layers (hidden layers). A network is typically called a deep neural network if it has at least two hidden layers.\nArtificial neural networks are used for various tasks, including predictive modeling, adaptive control, and solving problems in artificial intelligence. They can learn from experience, and can derive conclusions from a complex and seemingly unrelated set of information.\n\n\n== Training ==\nNeural networks are typically trained through empirical risk minimization. This method is based on the idea of optimizing the network's parameters to minimize the difference, or empirical risk, between the predicted output and the actual target values in a given dataset. Gradient-based methods such as backpropagation are usually used to estimate the parameters of the network. During the training phase, ANNs learn from labeled training data by iteratively updating their parameters to minimize a defined loss function. This method allows the network to generalize to unseen data.\n\n\n== History ==\n\n\n=== Early work ===\nToday's deep neural networks are based on early work in statistics over 200 years ago. The simplest kind of feedforward neural network (FNN) is a linear network, which consists of a single layer of output nodes with linear activation functions; the inputs are fed directly to the outputs via a series of weights. The sum of the products of the weights and the inputs is calculated at each node. The mean squared errors between these calculated outputs and the given target values are minimized by creating an adjustment to the weights. This technique has been known for over two centuries as the method of least squares or linear regression. It was used as a means of finding a good rough linear fit to a set of points by Legendre (1805) and Gauss (1795) for the prediction of planetary movement.\nHistorically, digital computers such as the von Neumann model operate via the execution of explicit instructions with access to memory by a number of processors. Some neural networks, on the other hand, originated from efforts to model information processing in biological systems through the framework of connectionism. Unlike the von Neumann model, connectionist computing does not separate memory and processing.\nWarren McCulloch and Walter Pitts (1943) considered a non-learning computational model for neural networks. This model paved the way for research to split into two approaches. One approach focused on biological processes while the other focused on the application of neural networks to artificial intelligence.\nIn the late 1940s, D. O. Hebb proposed a learning hypothesis based on the mechanism of neural plasticity that became known as Hebbian learning. It was used in many early neural networks, such as Rosenblatt's perceptron and the Hopfield network. Farley and Clark (1954) used computational machines to simulate a Hebbian network. Other neural network computational machines were created by Rochester, Holland, Habit and Duda (1956). \nIn 1958, psychologist Frank Rosenblatt described the perceptron, one of the first implemented artificial neural networks, funded by the United States Office of Naval Research.\nR. D. Joseph (1960) mentions an even earlier perceptron-like device by Farley and Clark: \"Farley and Clark of MIT Lincoln Laboratory actually preceded Rosenblatt in the development of a perceptron-like device.\" However, \"they dropped the subject.\"\nThe perceptron raised public excitement for research in Artificial Neural Networks, causing the US government to drastically increase funding. This contributed to \"the Golden Age of AI\" fueled by the optimistic claims made by computer scientists regarding the ability of perceptrons to emulate human intelligence.\nThe first perceptrons did not have adaptive hidden units. However, ",
      "url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
      "topic": "Machine Learning",
      "timestamp": "2025-11-14T00:19:39.339449",
      "type": "wikipedia_content"
    },
    {
      "title": "Python (programming language)",
      "summary": "Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation. Python is dynamically type-checked and garbage-collected. It supports multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming.\nGuido van Rossum began working on Python in the late 1980s as a successor to the ABC programming language. Python 3.0, released in 2008, was a major revision and not completely backward-compatible with earlier versions. Beginning with Python 3.5, capabilities and keywords for typing were added to the language, allowing optional static typing. Currently only versions in the 3.x series are supported. \nPython has gained widespread use in the machine learning community. It is widely taught as an introductory programming language. Since 2003, Python has consistently ranked in the top ten of the most popular programming languages in the TIOBE Programm",
      "content": "Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation. Python is dynamically type-checked and garbage-collected. It supports multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming.\nGuido van Rossum began working on Python in the late 1980s as a successor to the ABC programming language. Python 3.0, released in 2008, was a major revision and not completely backward-compatible with earlier versions. Beginning with Python 3.5, capabilities and keywords for typing were added to the language, allowing optional static typing. Currently only versions in the 3.x series are supported. \nPython has gained widespread use in the machine learning community. It is widely taught as an introductory programming language. Since 2003, Python has consistently ranked in the top ten of the most popular programming languages in the TIOBE Programming Community Index, which ranks based on searches in 24 platforms.\n\n\n== History ==\n\nPython was conceived in the late 1980s by Guido van Rossum at Centrum Wiskunde & Informatica (CWI) in the Netherlands. It was designed as a successor to the ABC programming language, which was inspired by SETL, capable of exception handling and interfacing with the Amoeba operating system. Python implementation began in December 1989. Van Rossum first released it in 1991 as Python 0.9.0. Van Rossum assumed sole responsibility for the project, as the lead developer, until 12 July 2018, when he announced his \"permanent vacation\" from responsibilities as Python's \"benevolent dictator for life\" (BDFL); this title was bestowed on him by the Python community to reflect his long-term commitment as the project's chief decision-maker. (He has since come out of retirement and is self-titled \"BDFL-emeritus\".) In January 2019, active Python core developers elected a five-member Steering Council to lead the project.\nThe name Python derives from the British comedy series Monty Python's Flying Circus. (See § Naming.)\nPython 2.0 was released on 16 October 2000, featuring many new features such as list comprehensions, cycle-detecting garbage collection, reference counting, and Unicode support. Python 2.7's end-of-life was initially set for 2015, and then postponed to 2020 out of concern that a large body of existing code could not easily be forward-ported to Python 3. It no longer receives security patches or updates. While Python 2.7 and older versions are officially unsupported, a different unofficial Python implementation, PyPy, continues to support Python 2, i.e., \"2.7.18+\" (plus 3.11), with the plus signifying (at least some) \"backported security updates\".\nPython 3.0 was released on 3 December 2008, and was a major revision and not completely backward-compatible with earlier versions, with some new semantics and changed syntax. Python 2.7.18, released in 2020, was the last release of Python 2. Several releases in the Python 3.x series have added new syntax to the language, and made a few (considered very minor) backward-incompatible changes.\nAs of November 2025, Python 3.14.0 is the latest stable release, and Python 3.13.9 was released a week later, all older 3.x versions had a security update down to Python 3.9.24 then again with 3.9.25, the final version in 3.9 series. Python 3.10 is, since November 2025, the oldest supported branch. Python 3.15 has an alpha released, and Android has a official downloadable executable available for Python 3.14. Releases receive two years of full support followed by three years of security support.\n\n\n== Design philosophy and features ==\nPython is a multi-paradigm programming language. Object-oriented programming and structured programming are fully supported, and many of their features support functional programming and aspect-oriented programming – including metaprogramming and metaobjects. Many other paradigms are supported via extensions, including design by contract and logic programming. Python is often referred to as a 'glue language' because it is purposely designed to be able to integrate components written in other languages.\nPython uses dynamic typing and a combination of reference counting and a cycle-detecting garbage collector for memory management. It uses dynamic name resolution (late binding), which binds method and variable names during program execution.\nPython's design offers some support for functional programming in the \"Lisp tradition\". It has filter, map, and reduce functions; list comprehensions, dictionaries, sets, and generator expressions. The standard library has two modules (itertools and functools) that implement functional tools borrowed from Haskell and Standard ML.\nPython's core philosophy is summarized in the Zen of Python (PEP 20) written by Tim Peters, which includes aphorisms such as these:\n\nExplicit is better than implicit.\nSimple is better than complex.\nReadability counts.\nSpecial c",
      "url": "https://en.wikipedia.org/wiki/Python_(programming_language)",
      "topic": "Python Programming",
      "timestamp": "2025-11-14T00:19:42.512713",
      "type": "wikipedia_content"
    },
    {
      "title": "Outline of the Python programming language",
      "summary": "The following outline is provided as an overview of and topical guide to Python:\nPython is a general-purpose, interpreted, object-oriented, multi-paradigm, and dynamically typed programming language known for its readable syntax and broad standard library. Python was created by Guido van Rossum and first released in 1991. It emphasizes code readability and developer productivity.",
      "content": "The following outline is provided as an overview of and topical guide to Python:\nPython is a general-purpose, interpreted, object-oriented, multi-paradigm, and dynamically typed programming language known for its readable syntax and broad standard library. Python was created by Guido van Rossum and first released in 1991. It emphasizes code readability and developer productivity.\n\n\n== What type of language is Python? ==\nProgramming language — artificial language designed to communicate instructions to a machine.\nObject-oriented programming — built primarily around objects and classes.\nFunctional programming — supports functions as first-class objects.\nScripting language — often used for automation and small programs.\nGeneral-purpose programming language — designed for a wide variety of application domains.\nDynamically typed — type checking occurs at runtime.\nInterpreted language — code is executed by an interpreter.\nMulti-paradigm — supports procedural, object-oriented, and functional programming.\n\n\n== History of Python ==\n\nABC (programming language) – precourser to Python\nPython started by Guido van Rossum in 1989, first released in 1991.\nPython 2 — major version released in 2000, officially retired in 2020.\nPython 3 — released in 2008\n\n\n== General Python concepts ==\n\n\n== Issues and limitations ==\nPerformance — slower than compiled languages like C or Java, can be mitigated by C extensions or JIT compilers (PyPy).\nGlobal interpreter lock — limits parallel CPU-bound threads in CPython\nMemory consumption — high memory use compared to some lower-level languages\nVersion compatibility — Python 2 vs Python 3 differences caused migration issues\n\n\n== Python implementations ==\n\nCPython — reference implementation in C\nIronPython — Python for .NET\nJython — Python for the JVM\nMicroPython — Python for microcontrollers and embedded systems\nNuitka — compiler that packages user code with CPython into a static binary\nPyPy — JIT-compiled Python interpreter for speed\nPythonAnywhere — freemium hosted Python installation that runs in the browser\nStackless Python — Python with lightweight concurrency features\n\n\n== Python toolchain ==\n\nList of Python software\nComparison of Python IDEs\nComparison of server-side web frameworks for Python\nList of Python frameworks\nList of Python libraries\nList of unit testing frameworks for Python\nPython Package Index\n\n\n== Notable projects using Python ==\nYouTube (backend)\nInstagram (backend)\nDropbox\nReddit\nOpenStack\nBlender (scripting and plugins)\nSageMath\nNumPy\nPandas\nTensorFlow\n\n\n== Python development communities ==\nActiveState — commercial Python distributions and support\nAnaconda, Inc. — Python data science ecosystem\nGitHub\nPython Software Foundation\nPython Package Index (PyPI) — third-party software repository for Python\n\n\n== Example source code ==\nArticles with example Python code\n\n\n== Python publications ==\n\n\n=== Books about Python ===\nAutomate the Boring Stuff with Python – Creative Commons Python book\nAlex Martelli — Python in a Nutshell and Python Cookbook\nMark Pilgrim – Dive into Python\nNaomi Ceder — The Quick Python Book\nWes McKinney — Python for Data Analysis\nZed Shaw – Learn Python the Hard Way\n\n\n=== Textbooks ===\nCore Python Programming\n\n\n== Python programmers ==\n\n\n== Python conferences ==\nEuroPython – annual Python conference in Europe\nPyCon – the largest annual convention for the Python community\nPyData – conference series focused on data analysis, machine learning, and scientific computing with Python\nSciPy Conferences – focused on the use of Python in scientific computing and research\nDjangoCon – a conference dedicated to the Django web framework\nPyOhio – a free regional Python conference held in Ohio\n\n\n== Python learning resources ==\n\nCodecademy – interactive Python programming lessons\nGeeksforGeeks – tutorials, coding examples, and interactive programming for Python concepts and data structures.\nKaggle – free Python courses focused on data science and machine learning.\nPython.org Tutorial – the official Python tutorial from the Python Software Foundation.\nReal Python – articles, tutorials, and courses for Python developers.\nW3Schools – beginner-friendly Python tutorials.\nWikibooks Python Programming – free open-content textbook on Python.\n\n\n=== Competitive programming ===\nCodeforces – an online platform for programming contests that supports Python submissions\nCodewars – gamified coding challenges supporting Python\nHackerRank – competitive programming and interview preparation site with Python challenges\nKaggle – while focused on data science competitions, it also includes Python-based problem solving.\nLeetCode – online judge and problem-solving platform where Python is widely used\n\n\n== See also ==\nOutline of computer programming\nOutline of software\nOutline of software engineering\nList of programmers\nOutlines of other programming languages\nOutline of the C programming language\nOutline of the C sharp programming language\nOutline of the C++ programming language\nOutline of the Ja",
      "url": "https://en.wikipedia.org/wiki/Outline_of_the_Python_programming_language",
      "topic": "Python Programming",
      "timestamp": "2025-11-14T00:19:44.805038",
      "type": "wikipedia_content"
    },
    {
      "title": "History of Python",
      "summary": "The programming language Python was conceived in the late 1980s, and its implementation was started in December 1989 by Guido van Rossum at CWI in the Netherlands as a successor to ABC capable of exception handling and interfacing with the Amoeba operating system. Van Rossum was Python's principal author and had a central role in deciding the direction of Python (as reflected in the title given to him by the Python community, Benevolent Dictator for Life (BDFL)) until stepping down as leader on July 12, 2018. Python was named after the BBC TV show Monty Python's Flying Circus.\nPython 2.0 was released on October 16, 2000, with many major new features, such as list comprehensions, cycle-detecting garbage collector, reference counting, memory management and support for Unicode, along with a change to the development process itself, with a shift to a more transparent and community-backed process.\nPython 3.0, a major, backwards-incompatible release, was released on December 3, 2008 after a ",
      "content": "The programming language Python was conceived in the late 1980s, and its implementation was started in December 1989 by Guido van Rossum at CWI in the Netherlands as a successor to ABC capable of exception handling and interfacing with the Amoeba operating system. Van Rossum was Python's principal author and had a central role in deciding the direction of Python (as reflected in the title given to him by the Python community, Benevolent Dictator for Life (BDFL)) until stepping down as leader on July 12, 2018. Python was named after the BBC TV show Monty Python's Flying Circus.\nPython 2.0 was released on October 16, 2000, with many major new features, such as list comprehensions, cycle-detecting garbage collector, reference counting, memory management and support for Unicode, along with a change to the development process itself, with a shift to a more transparent and community-backed process.\nPython 3.0, a major, backwards-incompatible release, was released on December 3, 2008 after a long period of testing. Many of its major features were also backported to the backwards-compatible Python versions 2.6 and 2.7 until support for Python 2 finally ceased at the beginning of 2020. Releases of Python 3 include the 2to3 utility, which automates the translation of Python 2 code to Python 3.\nAs of 24 October 2025, Python 3.14.0 is the latest stable release. This version currently receives full bug-fix and security updates, while Python 3.13—released in October 2024—will continue to receive bug-fixes until October 2026, and after that will only receive security fixes until its end-of-life in 2029. Python 3.10 is the oldest supported version of Python (albeit in the 'security support' phase).\n\n\n== Early history ==\nVan Rossum first published the code (for Python version 0.9.1) to alt.sources in February 1991. Several features of the language were already present at this stage, among them classes with inheritance, exception handling, functions, and various core datatypes such as list, dict, and str. The initial release also contained a module system borrowed from Modula-3; Van Rossum describes the module as \"one of Python's major programming units\". Python's exception model also resembled Modula-3's, with the addition of an else clause. In 1994 comp.lang.python, the primary discussion forum for Python, was formed.\n\n\n== Version 1 ==\nPython reached version 1.0 in January 1994. The major new features included in this release were the functional programming tools lambda, map, filter and reduce. Van Rossum stated that \"Python acquired lambda, reduce(), filter() and map(), courtesy of a Lisp hacker who missed them and submitted working patches\".\nThe last version released while Van Rossum was at CWI was Python 1.2.  In 1995, Van Rossum continued his work on Python at the Corporation for National Research Initiatives (CNRI) in Reston, Virginia from where he released several versions.\nBy version 1.4, Python had acquired several new features. Notable among these are the Modula-3 inspired keyword arguments (which are also similar to Common Lisp's keyword arguments) and built-in support for complex numbers. Also included is a basic form of data hiding by name mangling, though this is easily bypassed.\nDuring Van Rossum's stay at CNRI, he launched the Computer Programming for Everybody (CP4E) initiative, intending to make programming more accessible to more people, with a basic \"literacy\" in programming languages, similar to the basic English literacy and mathematics skills required by most employers. Python served a central role in this: because of its focus on clean syntax, it was already suitable, and CP4E's goals bore similarities to its predecessor, ABC. The project was funded by DARPA. As of 2007, the CP4E project is inactive, and while Python attempts to be easily learnable and not too arcane in its syntax and semantics, outreach to non-programmers is not an active concern.\n\n\n=== BeOpen ===\nIn 2000, the Python core development team moved to BeOpen.com to form the BeOpen PythonLabs team. CNRI requested that a version 1.6 be released, summarizing Python's development up to the point at which the development team left CNRI. Consequently, the release schedules for 1.6 and 2.0 had a significant amount of overlap. Python 2.0 was the only release from BeOpen.com. After Python 2.0 was released by BeOpen.com, Guido van Rossum and the other PythonLabs developers joined Digital Creations.\nThe Python 1.6 release included a new CNRI license that was substantially longer than the CWI license that had been used for earlier releases.  The new license included a clause stating that the license was governed by the laws of the State of Virginia.  The Free Software Foundation argued that the choice-of-law clause was incompatible with the GNU General Public License.  BeOpen, CNRI and the FSF negotiated a change to Python's free-software license that would make it GPL-compatible.  Python 1.6.1 is essentially the same as Python 1.6, with a few mino",
      "url": "https://en.wikipedia.org/wiki/History_of_Python",
      "topic": "Python Programming",
      "timestamp": "2025-11-14T00:19:47.411652",
      "type": "wikipedia_content"
    },
    {
      "title": "Technology",
      "summary": "Technology is the application of conceptual knowledge to achieve practical goals, especially in a reproducible way. The word technology can also mean the products resulting from such efforts, including both tangible tools such as utensils or machines, and intangible ones such as software. Technology plays a critical role in science, engineering, and everyday life.\nTechnological advancements have led to significant changes in society. The earliest known technology is the stone tool, used during prehistory, followed by the control of fire—which in turn contributed to the growth of the human brain and the development of language during the Ice Age, according to the cooking hypothesis. The invention of the wheel in the Bronze Age allowed greater travel and the creation of more complex machines. More recent technological inventions, including the printing press, telephone, and the Internet, have lowered barriers to communication and ushered in the knowledge economy.\nWhile technology contrib",
      "content": "Technology is the application of conceptual knowledge to achieve practical goals, especially in a reproducible way. The word technology can also mean the products resulting from such efforts, including both tangible tools such as utensils or machines, and intangible ones such as software. Technology plays a critical role in science, engineering, and everyday life.\nTechnological advancements have led to significant changes in society. The earliest known technology is the stone tool, used during prehistory, followed by the control of fire—which in turn contributed to the growth of the human brain and the development of language during the Ice Age, according to the cooking hypothesis. The invention of the wheel in the Bronze Age allowed greater travel and the creation of more complex machines. More recent technological inventions, including the printing press, telephone, and the Internet, have lowered barriers to communication and ushered in the knowledge economy.\nWhile technology contributes to economic development and improves human prosperity, it can also have negative impacts like pollution and resource depletion, and can cause social harms like technological unemployment resulting from automation. As a result, philosophical and political debates about the role and use of technology, the ethics of technology, and ways to mitigate its downsides are ongoing.\n\n\n== Etymology ==\nTechnology is a term dating back to the early 17th century that meant 'systematic treatment' (from Greek Τεχνολογία, from the Greek: τέχνη, romanized: tékhnē, lit. 'craft, art' and -λογία (-logíā), 'study, knowledge'). It is predated in use by the Ancient Greek word τέχνη (tékhnē), used to mean 'knowledge of how to make things', which encompassed activities like architecture.\nStarting in the 19th century, continental Europeans started using the terms Technik (German) or technique (French) to refer to a 'way of doing', which included all technical arts, such as dancing, navigation, or printing, whether or not they required tools or instruments. At the time, Technologie (German and French) referred either to the academic discipline studying the \"methods of arts and crafts\", or to the political discipline \"intended to legislate on the functions of the arts and crafts.\" The distinction between Technik and Technologie is absent in English, and so both were translated as technology. The term was previously uncommon in English and mostly referred to the academic discipline, as in the Massachusetts Institute of Technology.\nIn the 20th century, as a result of scientific progress and the Second Industrial Revolution, technology stopped being considered a distinct academic discipline and took on the meaning: the systemic use of knowledge to practical ends.\n\n\n== History ==\n\n\n=== Prehistoric ===\n\nTools were initially developed by hominids through observation and trial and error. Around 2 Mya (million years ago), they learned to make the first stone tools by hammering flakes off a pebble, forming a sharp hand axe. This practice was refined 75 kya (thousand years ago) into pressure flaking, enabling much finer work.\nThe discovery of fire was described by Charles Darwin as \"possibly the greatest ever made by man\". Archaeological, dietary, and social evidence point to \"continuous [human] fire-use\" at least 1.5 Mya. Fire, fueled with wood and charcoal, allowed early humans to cook their food to increase its digestibility, improving its nutrient value and broadening the number of foods that could be eaten. The cooking hypothesis proposes that the ability to cook promoted an increase in hominid brain size, though some researchers find the evidence inconclusive. Archaeological evidence of hearths was dated to 790 kya; researchers believe this is likely to have intensified human socialization and may have contributed to the emergence of language.\nOther technological advances made during the Paleolithic era include clothing and shelter. No consensus exists on the approximate time of adoption of either technology, but archaeologists have found archaeological evidence of clothing 90-120 kya and shelter 450 kya. As the Paleolithic era progressed, dwellings became more sophisticated and more elaborate; as early as 380 kya, humans were constructing temporary wood huts. Clothing, adapted from the fur and hides of hunted animals, helped humanity expand into colder regions; humans began to migrate out of Africa around 200 kya, initially moving to Eurasia.\n\n\n=== Neolithic ===\n\nThe Neolithic Revolution (or First Agricultural Revolution) brought about an acceleration of technological innovation, and a consequent increase in social complexity. The invention of the polished stone axe was a major advance that allowed large-scale forest clearance and farming. This use of polished stone axes increased greatly in the Neolithic but was originally used in the preceding Mesolithic in some areas such as Ireland. Agriculture fed larger populations, and the transition to sedentism ",
      "url": "https://en.wikipedia.org/wiki/Technology",
      "topic": "Technology",
      "timestamp": "2025-11-14T00:19:51.524245",
      "type": "wikipedia_content"
    },
    {
      "title": "Information technology",
      "summary": "Information technology (IT) is the study or use of computers, telecommunication systems and other devices to create, process, store, retrieve and transmit information. While the term is commonly used to refer to computers and computer networks, it also encompasses other information distribution technologies such as television and telephones. Information technology is an application of computer science and computer engineering.\nAn information technology system (IT system) is generally an information system, a communications system, or, more specifically speaking, a computer system — including all hardware, software, and peripheral equipment — operated by a limited group of IT users, and an IT project usually refers to the commissioning and implementation of an IT system. IT systems play a vital role in facilitating efficient data management, enhancing communication networks, and supporting organizational processes across various industries. Successful IT projects require meticulous plan",
      "content": "Information technology (IT) is the study or use of computers, telecommunication systems and other devices to create, process, store, retrieve and transmit information. While the term is commonly used to refer to computers and computer networks, it also encompasses other information distribution technologies such as television and telephones. Information technology is an application of computer science and computer engineering.\nAn information technology system (IT system) is generally an information system, a communications system, or, more specifically speaking, a computer system — including all hardware, software, and peripheral equipment — operated by a limited group of IT users, and an IT project usually refers to the commissioning and implementation of an IT system. IT systems play a vital role in facilitating efficient data management, enhancing communication networks, and supporting organizational processes across various industries. Successful IT projects require meticulous planning and ongoing maintenance to ensure optimal functionality and alignment with organizational objectives.\nAlthough humans have been storing, retrieving, manipulating, analysing and communicating information since the earliest writing systems were developed, the term information technology in its modern sense first appeared in a 1958 article published in the Harvard Business Review; authors Harold J. Leavitt and Thomas L. Whisler commented that \"the new technology does not yet have a single established name. We shall call it information technology (IT).\" Their definition consists of three categories: techniques for processing, the application of statistical and mathematical methods to decision-making, and the simulation of higher-order thinking through computer programs.\n\n\n== History ==\n\nBased on the storage and processing technologies employed, it is possible to distinguish four distinct phases of IT development: pre-mechanical (3000 BC – 1450 AD), mechanical (1450 – 1840), electromechanical (1840 – 1940), and electronic (1940 to present).\nIdeas of computer science were first mentioned before the 1950s under the Massachusetts Institute of Technology (MIT) and Harvard University, where they had discussed and began thinking of computer circuits and numerical calculations. As time went on, the field of information technology and computer science became more complex and was able to handle the processing of more data. Scholarly articles began to be published from different organizations.\nDuring the mid-1900s, Alan Turing, J. Presper Eckert, and John Mauchly were some of the pioneers of early computer technology. While their main efforts focused on designing the first digital computer, Turing also began to raise questions about artificial intelligence.\nDevices have been used to aid computation for thousands of years, probably initially in the form of a tally stick. The Antikythera mechanism, dating from about the beginning of the first century BC, is generally considered the earliest known mechanical analog computer, and the earliest known geared mechanism. Comparable geared devices did not emerge in Europe until the 16th century, and it was not until 1645 that the first mechanical calculator capable of performing the four basic arithmetical operations was developed.\n\nElectronic computers, using either relays or thermionic valves, began to appear in the early 1940s. The electromechanical Zuse Z3, completed in 1941, was the world's first programmable computer, and by modern standards one of the first machines that could be considered a complete computing machine. During the Second World War, Colossus developed the first electronic digital computer to decrypt German messages. Although it was programmable, it was not general-purpose, being designed to perform only a single task. It could not also store its program in memory; programming was carried out using plugs and switches to alter the internal wiring. The first recognizably modern electronic digital stored-program computer was the Manchester Baby, which ran its first program on 21 June 1948.\nThe development of transistors in the late 1940s at Bell Laboratories allowed a new generation of computers to be designed with greatly reduced power consumption. The first commercially available stored-program computer, the Ferranti Mark I, contained 4050 valves and had a power consumption of 25 kilowatts. By comparison, the first transistorized computer developed at the University of Manchester and operational by November 1953, consumed only 150 watts in its final version.\nSeveral other breakthroughs in semiconductor technology include the integrated circuit (IC) invented by Jack Kilby at Texas Instruments and Robert Noyce at Fairchild Semiconductor in 1959, silicon dioxide surface passivation by Carl Frosch and Lincoln Derick in 1955, the first planar silicon dioxide transistors by Frosch and Derick in 1957, the MOSFET demonstration by a Bell Labs team, the planar process by Jean Hoerni in",
      "url": "https://en.wikipedia.org/wiki/Information_technology",
      "topic": "Technology",
      "timestamp": "2025-11-14T00:19:55.706692",
      "type": "wikipedia_content"
    },
    {
      "title": "Palantir Technologies",
      "summary": "Palantir Technologies Inc. is an American publicly traded company specializing in software platforms for data. Headquartered in Denver, Colorado, it was founded in 2003 by Peter Thiel, Stephen Cohen, Joe Lonsdale, Alex Karp, and Nathan Gettings.\nThe company has four main operating systems: Palantir Gotham, Palantir Foundry, Palantir Apollo, and Palantir AIP. Palantir Gotham is an intelligence tool used by police in many countries as a predictive policing system and by militaries and counter-terrorism analysts, including the United States Intelligence Community (USIC) and United States Department of Defense. Its software as a service (SaaS) is one of five offerings authorized for Mission Critical National Security Systems (IL5) by the U.S. Department of Defense. Palantir Foundry has been used for data integration and analysis by corporate clients such as Morgan Stanley, Merck KGaA, Airbus, Wejo, Lilium, PG&E and Fiat Chrysler Automobiles. Palantir Apollo is a platform to facilitate cont",
      "content": "Palantir Technologies Inc. is an American publicly traded company specializing in software platforms for data. Headquartered in Denver, Colorado, it was founded in 2003 by Peter Thiel, Stephen Cohen, Joe Lonsdale, Alex Karp, and Nathan Gettings.\nThe company has four main operating systems: Palantir Gotham, Palantir Foundry, Palantir Apollo, and Palantir AIP. Palantir Gotham is an intelligence tool used by police in many countries as a predictive policing system and by militaries and counter-terrorism analysts, including the United States Intelligence Community (USIC) and United States Department of Defense. Its software as a service (SaaS) is one of five offerings authorized for Mission Critical National Security Systems (IL5) by the U.S. Department of Defense. Palantir Foundry has been used for data integration and analysis by corporate clients such as Morgan Stanley, Merck KGaA, Airbus, Wejo, Lilium, PG&E and Fiat Chrysler Automobiles. Palantir Apollo is a platform to facilitate continuous integration/continuous delivery (CI/CD) across all environments.\nPalantir's original clients were federal agencies of the USIC. It has since expanded its customer base to serve both international, state, and local governments, and also private companies.\nPalantir's software aims to streamline data analysis rather than control data itself, but privacy concerns persist. Some criticize the company for its involvement in expanding government surveillance through AI and facial recognition technologies. Some have raised concerns about its contracts under the Trump administration, which allegedly facilitated deportations and enabled the aggregation of sensitive data on Americans. Supporters counter that Palantir does not collect or store data itself but rather provides software that helps clients analyze data they already possess, while clients retain control and rights over their own information.\n\n\n== History ==\n\n\n=== 2003–2008: Founding and early years ===\n\nPalantir was founded in 2003. Thiel named the startup after the \"seeing stone\" in Tolkien's legendarium. Likewise, Palantir's office locations have names from Tolkien: The Shire (Palo Alto, California), Rivendell (McLean, Virginia), and Minas Tirith (Washington, D.C.). In 2013, Thiel said Palantir was a \"mission-oriented company\" that could apply software similar to PayPal's fraud recognition systems to \"reduce terrorism while preserving civil liberties\". Asked what the secret of its success was, Karp said that he and Thiel pursued a \"classic German approach\" when founding the company, influenced by the idea of overcoming opposites via the Hegelian dialectic.\nIn 2004, Thiel bankrolled the creation of a prototype by PayPal engineer Nathan Gettings and Stanford University students Joe Lonsdale and Stephen Cohen. The same year, Thiel hired Alex Karp, a former colleague of his from Stanford Law School, as chief executive officer.\nThere are several versions of the story of the company's founding. According to Gilman Louie, head of In-Q-Tel (a venture capital corporation associated with the CIA and the intelligence community), after Thiel recruited Karp, the two founders came to him with some ideas but no clear problem to solve. After hearing his suggestions, they did a mock-up in two weeks. According to Anthony King, the FBI first recognized the success of PayPal's fraud detection system (named \"Igor\", after a Russian who was one of the company's most consistent abusers) and requested it for the agency's work in detecting financial crime. Palantir evolved from that software when Thiel proposed the company to Karp and Cohen. According to Wired, in 2004, Thiel and Karp met John Poindexter, a Department of Defense official who recognized their \"interesting idea\" and helped them gather \"a legion of advocates from the most influential strata of government\". They then tried to recruit investors, but no one in Silicon Valley wanted to back an \"expensive software platform for large organizations\", and \"The government was unpopular in Silicon Valley\". But an investor who turned them down recommended them to In-Q-Tel, which decided to invest the relatively small sum of £1.3 million but helped them get in touch with prospective users. The contact with In-Q-Tel also incidentally led to interest from another backer, Reed Elsevier (later REV).\nAccording to Karp, Sequoia Capital chairman Michael Moritz doodled through an entire meeting, and a Kleiner Perkins executive lectured the founders about the company's inevitable failure.\nAccording to the Wall Street Journal, when Palantir was launched in 2004, other than Thiel and Karp, there were three investors, but little interest from venture capital firms, so Thiel and his venture fund largely bankrolled the initial $30 million cost. Later In-Q-Tel invested about $2 million. According to Techcrunch, Palantir's $7.5 million Series A (June 2006) was led by Oakhouse Partners and its $10.5 million Series B (November 2006) was led by REV. In-Q-Tel an",
      "url": "https://en.wikipedia.org/wiki/Palantir_Technologies",
      "topic": "Technology",
      "timestamp": "2025-11-14T00:19:58.766242",
      "type": "wikipedia_content"
    },
    {
      "title": "Sincé",
      "summary": "Sincé, also known as San Luis de Sincé, is a town and municipality located in the Department of Sucre,  28 km (15 mi) southeast of Sincelejo, in northern Colombia. It has an average Temperature of 26,5°C (80°F).  Its main economic activities are agriculture, stockbreeding and commerce. It was founded November 10, 1775 by Antonio de Torre y Miranda.  Sincé is home to \"Hospital Local Nuestra Señora del Socorro\" and a Municipal Photo Gallery.",
      "content": "Sincé, also known as San Luis de Sincé, is a town and municipality located in the Department of Sucre,  28 km (15 mi) southeast of Sincelejo, in northern Colombia. It has an average Temperature of 26,5°C (80°F).  Its main economic activities are agriculture, stockbreeding and commerce. It was founded November 10, 1775 by Antonio de Torre y Miranda.  Sincé is home to \"Hospital Local Nuestra Señora del Socorro\" and a Municipal Photo Gallery.\n\n\n== Celebrations and Events ==\nThe biggest local celebrations are held in honor of the Virgen del Socorro, the city's patron Saint, and celebrated in September.  Other major celebrations include the Fiestas en Corralejas (Running of the Bulls) in January and La Semana de la Sinceanidad (Sincé Week), commemorating its founding in November.\n\n\n== Notable people ==\nMusician and composer Adolfo Mejía Navarro was born in Sincé.\n\n\n== Gallery ==\n\n\n== References ==\n\n\n== External links ==\n(in Spanish) Gobernacion de Sucre - Sincé\n(in Spanish) Sincé official website",
      "url": "https://en.wikipedia.org/wiki/Sinc%C3%A9",
      "topic": "Science",
      "timestamp": "2025-11-14T00:20:04.771856",
      "type": "wikipedia_content"
    },
    {
      "title": "Natural science",
      "summary": "Natural science or empirical science is a branch of science concerned with the description, understanding, and prediction of natural phenomena, based on empirical evidence from observation and experimentation. Mechanisms such as peer review and reproducibility of findings are used to try to ensure the validity of scientific advances.\nNatural science can be divided into two main branches: life science and physical science. Life science is alternatively known as biology. Physical science is subdivided into physics, astronomy, Earth science, and chemistry. These branches of natural science may be further divided into more specialized branches, also known as fields. As empirical sciences, natural sciences use tools from the formal sciences, such as mathematics and logic, converting information about nature into measurements that can be explained as clear statements of the \"laws of nature\".\nModern natural science succeeded more classical approaches to natural philosophy. Galileo Galilei, Jo",
      "content": "Natural science or empirical science is a branch of science concerned with the description, understanding, and prediction of natural phenomena, based on empirical evidence from observation and experimentation. Mechanisms such as peer review and reproducibility of findings are used to try to ensure the validity of scientific advances.\nNatural science can be divided into two main branches: life science and physical science. Life science is alternatively known as biology. Physical science is subdivided into physics, astronomy, Earth science, and chemistry. These branches of natural science may be further divided into more specialized branches, also known as fields. As empirical sciences, natural sciences use tools from the formal sciences, such as mathematics and logic, converting information about nature into measurements that can be explained as clear statements of the \"laws of nature\".\nModern natural science succeeded more classical approaches to natural philosophy. Galileo Galilei, Johannes Kepler, René Descartes, Francis Bacon, and Isaac Newton debated the benefits of a more mathematical as against a more experimental method in investigating nature. Still, philosophical perspectives, conjectures, and presuppositions, often overlooked, remain necessary in natural science. Systematic data collection, including discovery science, succeeded natural history, which emerged in the 16th century by describing and classifying plants, animals, minerals, and so on. Today, \"natural history\" suggests observational descriptions aimed at popular audiences.\n\n\n== Criteria ==\n\nPhilosophers of science have suggested several criteria, including Karl Popper's controversial falsifiability criterion, to help them differentiate scientific endeavors from non-scientific ones. Validity, accuracy, and quality control, such as peer review and reproducibility of findings, are amongst the most respected criteria in today's global scientific community.\nIn natural science, impossibility assertions come to be widely accepted as overwhelmingly probable rather than considered proven to the point of being unchallengeable. The basis for this strong acceptance is a combination of extensive evidence of something not occurring, combined with an underlying theory, very successful in making predictions, whose assumptions lead logically to the conclusion that something is impossible. While an impossibility assertion in natural science can never be proved, it could be refuted by the observation of a single counterexample. Such a counterexample would require that the assumptions underlying the theory that implied the impossibility be re-examined.\n\n\n== Branches of natural science ==\n\n\n=== Biology ===\n\nThis field encompasses a diverse set of disciplines that examine phenomena related to living organisms. The scale of study can range from sub-component biophysics up to complex ecologies. Biology is concerned with the characteristics, classification and behaviors of organisms, as well as how species were formed and their interactions with each other and the environment.\nThe biological fields of botany, zoology, and medicine date back to early periods of civilization, while microbiology was introduced in the 17th century with the invention of the microscope. However, it was not until the 19th century that biology became a unified science. Once scientists discovered commonalities between all living things, it was decided they were best studied as a whole.\nSome key developments in biology were the discovery of genetics, evolution through natural selection, the germ theory of disease, and the application of the techniques of chemistry and physics at the level of the cell or organic molecule.\nModern biology is divided into subdisciplines by the type of organism and by the scale being studied. Molecular biology is the study of the fundamental chemistry of life, while cellular biology is the examination of the cell; the basic building block of all life. At a higher level, anatomy and physiology look at the internal structures, and their functions, of an organism, while ecology looks at how various organisms interrelate.\n\n\n=== Earth science ===\n\nEarth science (also known as geoscience) is an all-embracing term for the sciences related to the planet Earth, including geology, geography, geophysics, geochemistry, climatology, glaciology, hydrology, meteorology and oceanography.\nAlthough mining and precious stones have been human interests throughout the history of civilization, the development of the related sciences of economic geology and mineralogy did not occur until the 18th century. The study of the earth, particularly paleontology, blossomed in the 19th century. The growth of other disciplines, such as geophysics, in the 20th century led to the development of the theory of plate tectonics in the 1960s, which has had a similar effect on the Earth sciences as the theory of evolution had on biology. Earth sciences today are closely linked to petroleum and minera",
      "url": "https://en.wikipedia.org/wiki/Natural_science",
      "topic": "Science",
      "timestamp": "2025-11-14T00:20:09.715250",
      "type": "wikipedia_content"
    },
    {
      "title": "Science of team science",
      "summary": "Science of Team Science (SciTS) is a field of methodology that focuses on understanding and improving cross-disciplinary collaboration in research. The field encompasses conceptual and methodological strategies to understand how scientific teams can be organized to work more effectively. SciTS initiatives aim to understand and manage factors that affect collaborative science and evaluate its outcomes.",
      "content": "Science of Team Science (SciTS) is a field of methodology that focuses on understanding and improving cross-disciplinary collaboration in research. The field encompasses conceptual and methodological strategies to understand how scientific teams can be organized to work more effectively. SciTS initiatives aim to understand and manage factors that affect collaborative science and evaluate its outcomes.\n\n\n== History ==\nSince the 1990s, interest and large-scale funding for team-based research initiatives has increased, driven by efforts to tackle complex problems through cross-disciplinary collaboration. Some argue that this trend reflects the growing recognition that addressing multifaceted challenges, such as climate change and public health issues, benefit from partnerships among scientists and practitioners from diverse fields. One SciTS literature review highlighted team science as essential to inter-professional collaborative research. The report called for its integration into health professions education and clinical practice at the University of Minnesota's National Center for Interprofessional Practice and Education.\nThe interdisciplinary nature of SciTS initially emerged from concerns raised by funding agencies, which sought to assess the performance of team science, understand its added value, evaluate the return on investment in large research initiatives, and inform science policy. The term \"science of team science\" was first introduced in October 2006 at a conference titled The Science of Team Science: Assessing the Value of Transdisciplinary Research, hosted by the National Cancer Institute in Bethesda, Maryland. The SciTS field was further treated in a supplement to the American Journal of Preventive Medicine published in July 2008. The First Annual International Science of Team Science (SciTS) Conference was held on April 22–24, 2010, in Chicago, Illinois, organized by the Northwestern University Clinical and Translational Sciences (NUCATS) Institute.\nIn 2013, the National Academy of Sciences established a National Research Council Committee on the Science of Team Science to evaluate the current state of knowledge and practice in SciTS. A committee report was published in 2015.\nIn 2023, Patrick Forscher and colleagues published a review identifying the benefits of big team science, noting that innovations facilitate the collection of larger samples and support efforts toward reproducibility and generalizability. However, concerns exist that team science could increasingly influence funding priorities, potentially shifting emphasis from applied science to more theoretical research areas, as well as leading to unsuccessful large-scale projects. Forscher's recommendations included creating an advisory board and structured bylaws, formalizing feedback mechanisms from contributors, engaging in mentoring, and separating idea generation from project implementation.\n\n\n== Methods ==\nThe definition of a successful team may vary, depending on stakeholders. SciTS uses both qualitative and quantitative methods to evaluate the antecedent conditions, collaborative processes, and outcomes associated with team science. It also considers the organizational, social, and political context that influences team science.\nA 2018 review of literature on SciTS published between 2006 and 2016 identified 109 articles. It reported that 75% of these articles used pre-existing data (e.g., archival data), 62% used bibliometrics, over 40% used surveys, and over 10% used interview and observational data.\n\n\n== See also ==\nIntegrative learning\nInteractional expertise\nInterdisciplinarity\nMultidisciplinary\nMultidimensional network\nTransdisciplinary\nGlobal brain\n\n\n== References ==\n\n\n== Further reading ==\nAzoulay P, Joshua S, Zivin JW (2010). \"Superstar Extinction\". The Quarterly Journal of Economics. 125 (2): 549–589.\nBennett LM, Gadlin H, Levine-Finley S (2010). \"Collaboration and team science: a field guide\" (PDF). Bethesda, Maryland: National Institutes of Health. Accessed May 28, 2010.\nBörner, Katy; Dall'Asta, Luca; Ke, Weimao; Vespignani, Alessandro (2005). \"Studying the emerging global brain: Analyzing and visualizing the impact of co-authorship teams\" (PDF). Complexity. 10 (4): 57–67. arXiv:cond-mat/0502147. Bibcode:2005Cmplx..10d..57B. doi:10.1002/cplx.20078. ISSN 1076-2787. S2CID 2190589.\nContractor, Noshir (2009). \"The Emergence of Multidimensional Networks\". Journal of Computer-Mediated Communication. 14 (3): 743–747. doi:10.1111/j.1083-6101.2009.01465.x. ISSN 1083-6101.\nCummings JN. \"A socio-technical framework for identifying team science collaborations that could benefit from cyberinfrastructure\". VOSS: National Science Foundation; 2009.\nPatel MM, Moseley TW, Nia ES, Perez F, Kapoor MM, Whitman GJ. \"Team Science: A Practical Approach to Starting Collaborative Projects.\" J Breast Imaging. 2021 Jun 16;3(6):721-726. doi: 10.1093/jbi/wbab034. PMID: 34805982; PMCID: PMC8599160.\nStokols D, Taylor B, Hall K, Moser R (2006).",
      "url": "https://en.wikipedia.org/wiki/Science_of_team_science",
      "topic": "Science",
      "timestamp": "2025-11-14T00:20:12.149158",
      "type": "wikipedia_content"
    },
    {
      "title": "History",
      "summary": "History is the systematic study of the past, focusing primarily on the human past. As an academic discipline, it analyses and interprets evidence to construct narratives about what happened and explain why it happened. Some theorists categorize history as a social science, while others see it as part of the humanities or consider it a hybrid discipline. Similar debates surround the purpose of history—for example, whether its main aim is theoretical, to uncover the truth, or practical, to learn lessons from the past. In a more general sense, the term history refers not to an academic field but to the past itself, times in the past, or to individual texts about the past.\nHistorical research relies on primary and secondary sources to reconstruct past events and validate interpretations. Source criticism is used to evaluate these sources, assessing their authenticity, content, and reliability. Historians strive to integrate the perspectives of several sources to develop a coherent narrativ",
      "content": "History is the systematic study of the past, focusing primarily on the human past. As an academic discipline, it analyses and interprets evidence to construct narratives about what happened and explain why it happened. Some theorists categorize history as a social science, while others see it as part of the humanities or consider it a hybrid discipline. Similar debates surround the purpose of history—for example, whether its main aim is theoretical, to uncover the truth, or practical, to learn lessons from the past. In a more general sense, the term history refers not to an academic field but to the past itself, times in the past, or to individual texts about the past.\nHistorical research relies on primary and secondary sources to reconstruct past events and validate interpretations. Source criticism is used to evaluate these sources, assessing their authenticity, content, and reliability. Historians strive to integrate the perspectives of several sources to develop a coherent narrative. Different schools of thought, such as positivism, the Annales school, Marxism, and postmodernism, have distinct methodological approaches.\nHistory is a broad discipline encompassing many branches. Some focus on specific time periods, such as ancient history, while others concentrate on particular geographic regions, such as the history of Africa. Thematic categorizations include political history, military history, social history, and economic history. Branches associated with specific research methods and sources include quantitative history, comparative history, and oral history.\nHistory emerged as a field of inquiry in antiquity to replace myth-infused narratives, with influential early traditions originating in Greece, China, and later in the Islamic world. Historical writing evolved throughout the ages and became increasingly professional, particularly during the 19th century, when a rigorous methodology and various academic institutions were established. History is related to many fields, including historiography, philosophy, education, and politics.\n\n\n== Definition ==\nAs an academic discipline, history is the study of the past with the main focus on the human past. It conceptualizes and describes what happened by collecting and analysing evidence to construct narratives. These narratives cover not only how events developed over time but also why they happened and in which contexts, providing an explanation of relevant background conditions and causal mechanisms. History further examines the meaning of historical events and the underlying human motives driving them.\nIn a slightly different sense, history refers to the past events themselves. Under this interpretation, history is what happened rather than the academic field studying what happened. When used as a countable noun, a history is a representation of the past in the form of a history text. History texts are cultural products involving active interpretation and reconstruction. The narratives presented in them can change as historians discover new evidence or reinterpret already-known sources. The past itself, by contrast, is static and unchangeable. Some historians focus on the interpretative and explanatory aspects to distinguish histories from chronicles, arguing that chronicles only catalogue events in chronological order, whereas histories aim at a comprehensive understanding of their causes, contexts, and consequences.\nHistory has been primarily concerned with written documents. It focused on recorded history since the invention of writing, leaving prehistory to other fields, such as archaeology. Its scope broadened in the 20th century as historians became interested in the human past before the invention of writing.\nHistorians debate whether history is a social science or forms part of the humanities. Like social scientists, historians formulate hypotheses, gather objective evidence, and present arguments based on this evidence. At the same time, history aligns closely with the humanities because of its reliance on subjective aspects associated with interpretation, storytelling, human experience, and cultural heritage. Some historians strongly support one or the other classification while others characterize history as a hybrid discipline that does not belong to one category at the exclusion of the other. History contrasts with pseudohistory, a label used to describe practices that deviate from historiographical standards by relying on disputed historical evidence, selectively ignoring genuine evidence, or using other means to distort the historical record. Often motivated by specific ideological agendas, pseudohistorical practices mimic historical methodology to promote biased, misleading narratives that lack rigorous analysis and scholarly consensus.\n\n\n=== Purpose ===\nVarious suggestions about the purpose or value of history have been made. Some historians propose that its primary function is the pure discovery of truth about the past. This view emphas",
      "url": "https://en.wikipedia.org/wiki/History",
      "topic": "History",
      "timestamp": "2025-11-14T00:20:17.277414",
      "type": "wikipedia_content"
    },
    {
      "title": "HIStory: Past, Present and Future, Book I",
      "summary": "HIStory: Past, Present and Future, Book I is a double album by the American singer-songwriter Michael Jackson, released on June 20, 1995. It consists of the greatest hits album, HIStory Begins, in addition to his ninth studio album, HIStory Continues. It was Jackson's fifth album released through Epic Records, and the first on his label MJJ Productions. The album includes appearances by Janet Jackson, Shaquille O'Neal, Slash, and the Notorious B.I.G. Its genres span R&B, pop, and hip hop with elements of hard rock and funk rock. The themes include environmental awareness, isolation, greed, and injustice. \nSeveral of the songs on HIStory Continues pertain to the child sexual abuse allegations made against Jackson in 1993 and Jackson's perceived mistreatment by the media. Jackson embarked on the HIStory World Tour, which was his third and final concert tour as a solo artist. The tour grossed $165 million, making it the highest-grossing solo concert tour of the 1990s. HIStory topped the c",
      "content": "HIStory: Past, Present and Future, Book I is a double album by the American singer-songwriter Michael Jackson, released on June 20, 1995. It consists of the greatest hits album, HIStory Begins, in addition to his ninth studio album, HIStory Continues. It was Jackson's fifth album released through Epic Records, and the first on his label MJJ Productions. The album includes appearances by Janet Jackson, Shaquille O'Neal, Slash, and the Notorious B.I.G. Its genres span R&B, pop, and hip hop with elements of hard rock and funk rock. The themes include environmental awareness, isolation, greed, and injustice. \nSeveral of the songs on HIStory Continues pertain to the child sexual abuse allegations made against Jackson in 1993 and Jackson's perceived mistreatment by the media. Jackson embarked on the HIStory World Tour, which was his third and final concert tour as a solo artist. The tour grossed $165 million, making it the highest-grossing solo concert tour of the 1990s. HIStory topped the charts in 20 countries, including the US Billboard 200 chart, where it sold over 391,000 copies in its first week.\nFive singles from HIStory were released. The first single of the album, a double A-side of \"Scream\" (a duet between Jackson and his sister Janet) and \"Childhood\", was a Top 5 hit on the Billboard Hot 100. \"You Are Not Alone\" became the first song in history to debut at number 1 on the Hot 100 and was also Jackson's final US number 1 single. Later singles included the protest songs \"Earth Song\" and \"They Don't Care About Us\", the latter of which drew accusations of antisemitism. Jackson vehemently denied these accusations. \nWhile HIStory Begins received widespread acclaim, critical response to the new material, HIStory Continues, was mixed. The album has sold over 20 million copies worldwide, making it one of the best-selling albums of all time, and was certified 8× Platinum by the Recording Industry Association of America (RIAA) in 2018. HIStory was nominated for five Grammy Awards at the 1996 Grammy Awards, including Jackson's third Album of the Year nomination. It won Best Music Video – Short Form for \"Scream\".  \n\n\n== Background ==\nStarting in the late 1980s, Jackson and the tabloid press had a difficult relationship. In 1986, tabloids claimed that Jackson slept in a hyperbaric oxygen chamber and had offered to buy the bones of Joseph Merrick (the \"Elephant Man\"), both of which Jackson vehemently denied. These stories inspired the derogatory nickname \"Wacko Jacko\", which Jackson despised. He stopped leaking untruths to the press, and the media began creating their own stories. In 1989, Jackson released \"Leave Me Alone\", a song about the victimization he felt by the press.\nIn 1993, the relationship between Jackson and the press collapsed when he was accused of child sexual abuse. Although he was not charged, Jackson was subject to intense media scrutiny while the criminal investigation took place. Media coverage included misleading and sensational headlines; paying for stories of Jackson's alleged criminal activity and confidential material from the police investigation; using unflattering pictures of Jackson; and using headlines that strongly implied Jackson's guilt. In 1993, a Daily Express headline read \"Drug Treatment Star Faces Life on the Run\", while a News of the World headline accused Jackson of being a fugitive; these tabloids also falsely alleged that Jackson had traveled to Europe to have cosmetic surgery that would make him unrecognizable on his return. The same year, the Daily Mirror held a \"Spot the Jacko\" contest, offering readers a trip to Disney World if they could correctly predict where Jackson would appear next. In early November 1993, talk show host Geraldo Rivera set up a mock trial with a jury of audience members, though Jackson had not been charged with a crime. In 1994, Jackson said of the media coverage: \"I am particularly upset by the handling of the matter by the incredible, terrible mass media. At every opportunity, the media has dissected and manipulated these allegations to reach their own conclusions.\"\nJackson began taking painkillers, Valium, Xanax and Ativan to deal with the stress of the allegations. A few months after the allegations became news, Jackson stopped eating. Soon after, Jackson's health deteriorated to the extent that he canceled the remainder of his Dangerous World Tour and went into rehabilitation. Jackson booked the whole fourth floor of a clinic and was put on Valium IV to wean him from painkillers.\n\n\n== Content ==\nHIStory was Jackson's first studio album since his 1991 album Dangerous and his first new material after being accused of child sexual abuse. The album comprises two discs. The first, HIStory Begins, is a compilation of songs from Jackson's albums Off the Wall (1979), Thriller (1982), Bad (1987) and Dangerous (1991). The second, HIStory Continues, comprises new material recorded from January 1994 to March 1995, although one of the songs (a cover of the",
      "url": "https://en.wikipedia.org/wiki/HIStory:_Past,_Present_and_Future,_Book_I",
      "topic": "History",
      "timestamp": "2025-11-14T00:20:20.739833",
      "type": "wikipedia_content"
    },
    {
      "title": "History of bitcoin",
      "summary": "Bitcoin is a cryptocurrency, a digital asset that uses cryptography to control its creation and management rather than relying on central authorities. Originally designed as a medium of exchange, Bitcoin is now primarily regarded as a store of value. The history of bitcoin started with its invention and implementation by Satoshi Nakamoto, who integrated many existing ideas from the cryptography community. Over the course of bitcoin's history, it has undergone rapid growth to become a significant store of value both on- and offline. From the mid-2010s, some businesses began accepting bitcoin in addition to traditional currencies.\n\n",
      "content": "Bitcoin is a cryptocurrency, a digital asset that uses cryptography to control its creation and management rather than relying on central authorities. Originally designed as a medium of exchange, Bitcoin is now primarily regarded as a store of value. The history of bitcoin started with its invention and implementation by Satoshi Nakamoto, who integrated many existing ideas from the cryptography community. Over the course of bitcoin's history, it has undergone rapid growth to become a significant store of value both on- and offline. From the mid-2010s, some businesses began accepting bitcoin in addition to traditional currencies.\n\n\n== Background ==\nPrior to the release of bitcoin, there were a number of digital cash technologies, starting with the issuer-based ecash protocols of David Chaum and Stefan Brands. The idea that solutions to computational puzzles could have some value was first proposed by cryptographers Cynthia Dwork and Moni Naor in 1992.\n\n\n=== 31 October 1996 NSA paper ===\n12 years prior to creating Bitcoin the NSA published the white paper \"How To Make A Mint: The Cryptography of Anonymous Electronic Cash\" \n\n\n=== Adam Back ===\nThe idea was independently rediscovered by Adam Back who developed hashcash, a proof-of-work scheme for spam control in 1997. The first proposals for distributed digital scarcity-based cryptocurrencies were Wei Dai's b-money and Nick Szabo's bit gold. Hal Finney developed reusable proof of work (RPOW) using hashcash as proof of work algorithm.\nIn the bit gold proposal which proposed a collectible market-based mechanism for inflation control, Nick Szabo also investigated some additional aspects including a Byzantine fault-tolerant agreement protocol based on quorum addresses to store and transfer the chained proof-of-work solutions, which was vulnerable to Sybil attacks, though.\n\n\n== Creation ==\nOn 18 August 2008, the domain name bitcoin.org was registered. Later that year, on 31 October, a link to a paper authored by Satoshi Nakamoto titled Bitcoin: A Peer-to-Peer Electronic Cash System was posted to a cryptography mailing list. This paper detailed methods of using a peer-to-peer network to generate what was described as \"a system for electronic transactions without relying on trust\". On 3 January 2009, the bitcoin network came into existence with Satoshi Nakamoto mining the genesis block of bitcoin (block number 0), which had a reward of 50 bitcoins. Embedded in the genesis block was the text:\n\nThe Times 03/Jan/2009 Chancellor on brink of second bailout for banks\nThe text refers to a headline in The Times published on 3 January 2009. This note has been interpreted as both a timestamp of the genesis date and a derisive comment on the instability caused by fractional-reserve banking.\nThe first open source bitcoin client was released on 9 January 2009, hosted at SourceForge.\nOne of the first supporters, adopters, contributors to bitcoin and receiver of the first bitcoin transaction was programmer Hal Finney. Finney downloaded the bitcoin software the day it was released, and received 10 bitcoins from Nakamoto in the world's first bitcoin transaction on 12 January 2009 (block 170). Other early supporters were Wei Dai, creator of bitcoin predecessor b-money, and Nick Szabo, creator of bitcoin predecessor bit gold. One of the first miners included James Howells, who subsequently lost thousands of Bitcoin to a landfill in Newport.\nIn the early days, Nakamoto is estimated to have mined 1 million bitcoins. Before disappearing from any involvement in bitcoin, Nakamoto in a sense handed over the reins to developer Gavin Andresen, who then became the bitcoin lead developer at the Bitcoin Foundation, the 'anarchic' bitcoin community's closest thing to an official public face.\n\n\n=== Satoshi Nakamoto ===\n\n\"Satoshi Nakamoto\" is presumed to be a pseudonym for the person or people who designed the original bitcoin protocol in 2007 then released the whitepaper in 2008 and finally launched the network in 2009. Nakamoto was responsible for creating the majority of the official bitcoin software and was active in making modifications and posting technical information on the bitcoin forum. There has been much speculation as to the identity of Satoshi Nakamoto with suspects including Dai, Szabo, and Finney –  and accompanying denials. The possibility that Satoshi Nakamoto was a computer collective in the European financial sector has also been discussed.\nInvestigations into the real identity of Satoshi Nakamoto were attempted by The New Yorker and Fast Company. The New Yorker's investigation brought up at least two possible candidates: Michael Clear and Vili Lehdonvirta. Fast Company's investigation brought up circumstantial evidence linking an encryption patent application filed by Neal King, Vladimir Oksman and Charles Bry on 15 August 2008, and the bitcoin.org domain name which was registered 72 hours later. The patent application (#20100042841) contained networking and encryption technologi",
      "url": "https://en.wikipedia.org/wiki/History_of_bitcoin",
      "topic": "History",
      "timestamp": "2025-11-14T00:20:24.251719",
      "type": "wikipedia_content"
    },
    {
      "title": "Geography",
      "summary": "Geography (from Ancient Greek γεωγραφία geōgraphía; combining gê 'Earth' and gráphō 'write', literally 'Earth writing') is the study of the lands, features, inhabitants, and phenomena of Earth. Geography is an all-encompassing discipline that seeks an understanding of Earth and its human and natural complexities—not merely where objects are, but also how they have changed and come to be. While geography is specific to Earth, many concepts can be applied more broadly to other celestial bodies in the field of planetary science. Geography has been called \"a bridge between natural science and social science disciplines.\"\nThe history of geography as a discipline spans cultures and millennia, being independently developed by multiple groups, and cross-pollinated by trade between these groups. Geography as a discipline dates back to the earliest attempts to understand the world spatially, with the earliest example of an attempted world map dating to the 9th century BCE in ancient Babylon. Ori",
      "content": "Geography (from Ancient Greek γεωγραφία geōgraphía; combining gê 'Earth' and gráphō 'write', literally 'Earth writing') is the study of the lands, features, inhabitants, and phenomena of Earth. Geography is an all-encompassing discipline that seeks an understanding of Earth and its human and natural complexities—not merely where objects are, but also how they have changed and come to be. While geography is specific to Earth, many concepts can be applied more broadly to other celestial bodies in the field of planetary science. Geography has been called \"a bridge between natural science and social science disciplines.\"\nThe history of geography as a discipline spans cultures and millennia, being independently developed by multiple groups, and cross-pollinated by trade between these groups. Geography as a discipline dates back to the earliest attempts to understand the world spatially, with the earliest example of an attempted world map dating to the 9th century BCE in ancient Babylon. Origins of many of the concepts in geography can be traced to Greek Eratosthenes of Cyrene, who may have coined the term \"geographia\" (c. 276 BC – c. 195/194 BC). The first recorded use of the word γεωγραφία was as the title of a book by Greek scholar Claudius Ptolemy (100 – 170 AD). During the Middle Ages, geography was influenced by Islamic scholars, like Muhammad al-Idrisi, producing detailed maps of the world. The Age of Discovery was influential in the development of geography, as European explorers mapped the New World. Modern developments include the development of geomatics and geographic information science.\nThe core concepts of geography consistent between all approaches are a focus on space, place, time, and scale. Today, geography is an extremely broad discipline with multiple approaches and modalities. The main branches of geography are physical geography, human geography, and technical geography. Physical geography focuses on the natural environment, human geography focuses on how humans interact with the Earth, and technical geography focuses on the development of tools for understanding geography. Techniques employed can generally be broken down into quantitative and qualitative approaches, with many studies taking mixed-methods approaches. Common techniques include cartography, remote sensing, interviews, and surveying.\n\n\n== Fundamentals ==\n\nGeography is a systematic study of the Earth (other celestial bodies are specified, such as \"geography of Mars\", or given another name, such as areography in the case of Mars, or selenography in the case of the Moon, or planetography for the general case), its features, and phenomena that take place on it. For something to fall into the domain of geography, it generally needs some sort of spatial component that can be placed on a map, such as coordinates, place names, or addresses. This has led to geography being associated with cartography and place names. Although many geographers are trained in toponymy and cartology, this is not their main preoccupation. Geographers study the Earth's spatial and temporal distribution of phenomena, processes, and features as well as the interaction of humans and their environment. Because space and place affect a variety of topics, such as economics, health, climate, plants, and animals, geography is highly interdisciplinary. The interdisciplinary nature of the geographical approach depends on an attentiveness to the relationship between physical and human phenomena and their spatial patterns.\nWhile narrowing down geography to a few key concepts is extremely challenging, and subject to tremendous debate within the discipline, several sources have approached the topic. The 1st edition of the book \"Key Concepts in Geography\" broke down this into chapters focusing on \"Space,\" \"Place,\" \"Time,\" \"Scale,\" and \"Landscape.\" The 2nd edition of the book expanded on these key concepts by adding \"Environmental systems,\" \"Social Systems,\" \"Nature,\" \"Globalization,\" \"Development,\" and \"Risk,\" demonstrating how challenging narrowing the field can be. Another approach used extensively in teaching geography are the Five themes of geography established by \"Guidelines for Geographic Education: Elementary and Secondary Schools,\" published jointly by the National Council for Geographic Education and the Association of American Geographers in 1984. These themes are Location, place, relationships within places (often summarized as Human-Environment Interaction), movement, and regions. The five themes of geography have shaped how American education approaches the topic in the years since.\n\n\n=== Space ===\n\nJust as all phenomena exist in time and thus have a history, they also exist in space and have a geography.\nFor something to exist in the realm of geography, it must be able to be described spatially. Thus, space is the most fundamental concept at the foundation of geography. The concept is so basic, that geographers often have difficulty defining exactly what it",
      "url": "https://en.wikipedia.org/wiki/Geography",
      "topic": "Geography",
      "timestamp": "2025-11-14T00:20:27.608685",
      "type": "wikipedia_content"
    },
    {
      "title": "Geography (Front 242 album)",
      "summary": "Geography is the debut album released in 1982 by Belgian electronic music group Front 242.",
      "content": "Geography is the debut album released in 1982 by Belgian electronic music group Front 242.\n\n\n== Critical reception ==\nDave Thompson, in Alternative Rock, wrote that the album \"boasts three dancey gems still being sampled (or spun) today and a clutch of other crucial songs which would be equally influential outside the club scene.\"\n\n\n== Track listing ==\n\nGEOGRAPHY - VINTAGE REISSUE - LIMITED EDITION (2 CD)\n(This double-CD was completely remastered and rebuilt by Daniel Bressanutti. Some tracks differ notably in sound)\n\n\n=== Samples ===\nThe 1971 science fiction film THX 1138 was sampled in the song \"Operating Tracks\".\n\n\n== References ==",
      "url": "https://en.wikipedia.org/wiki/Geography_(Front_242_album)",
      "topic": "Geography",
      "timestamp": "2025-11-14T00:20:34.255618",
      "type": "wikipedia_content"
    },
    {
      "title": "Physical geography",
      "summary": "Physical geography (also known as physiography) is one of the three main branches of geography. Physical geography is the branch of natural science which deals with the processes and patterns in the natural environment such as the atmosphere, hydrosphere, biosphere, and geosphere. This focus is in contrast with the branch of human geography, which focuses on the built environment, and technical geography, which focuses on using, studying, and creating tools to obtain, analyze, interpret, and understand spatial information. The three branches have significant overlap, however.\n\n",
      "content": "Physical geography (also known as physiography) is one of the three main branches of geography. Physical geography is the branch of natural science which deals with the processes and patterns in the natural environment such as the atmosphere, hydrosphere, biosphere, and geosphere. This focus is in contrast with the branch of human geography, which focuses on the built environment, and technical geography, which focuses on using, studying, and creating tools to obtain, analyze, interpret, and understand spatial information. The three branches have significant overlap, however.\n\n\n== Sub-branches ==\n\nPhysical geography can be divided into several branches or related fields, as follows:\n\nGeomorphology is concerned with understanding the surface of the Earth and the processes by which it is shaped, both at the present as well as in the past. Geomorphology as a field has several sub-fields that deal with the specific landforms of various environments, e.g. desert geomorphology and fluvial geomorphology; however, these sub-fields are united by the core processes which cause them, mainly tectonic or climatic processes. Geomorphology seeks to understand landform history and dynamics, and predict future changes through a combination of field observation, physical experiment, and numerical modeling (Geomorphometry). Early studies in geomorphology are the foundation for pedology, one of two main branches of soil science.\n\nHydrology is predominantly concerned with the amounts and quality of water moving and accumulating on the land surface and in the soils and rocks near the surface and is typified by the hydrological cycle. Thus the field encompasses water in rivers, lakes, aquifers and to an extent glaciers, in which the field examines the process and dynamics involved in these bodies of water. Hydrology has historically had an important connection with engineering and has thus developed a largely quantitative method in its research; however, it does have an earth science side that embraces the systems approach. Similar to most fields of physical geography it has sub-fields that examine the specific bodies of water or their interaction with other spheres e.g. limnology and ecohydrology.\nGlaciology is the study of glaciers and ice sheets, or more commonly the cryosphere or ice and phenomena that involve ice. Glaciology groups the latter (ice sheets) as continental glaciers and the former (glaciers) as alpine glaciers. Although research in the areas is similar to research undertaken into both the dynamics of ice sheets and glaciers, the former tends to be concerned with the interaction of ice sheets with the present climate and the latter with the impact of glaciers on the landscape. Glaciology also has a vast array of sub-fields examining the factors and processes involved in ice sheets and glaciers e.g. snow hydrology and glacial geology.\nBiogeography is the science which deals with geographic patterns of species distribution and the processes that result in these patterns. Biogeography emerged as a field of study as a result of the work of Alfred Russel Wallace, although the field prior to the late twentieth century had largely been viewed as historic in its outlook and descriptive in its approach. The main stimulus for the field since its founding has been that of evolution, plate tectonics and the theory of island biogeography. The field can largely be divided into five sub-fields: island biogeography, paleobiogeography, phylogeography, zoogeography and phytogeography.\nClimatology is the study of the climate, scientifically defined as weather conditions averaged over a long period of time. Climatology examines both the nature of micro (local) and macro (global) climates and the natural and anthropogenic influences on them. The field is also sub-divided largely into the climates of various regions and the study of specific phenomena or time periods e.g. tropical cyclone rainfall climatology and paleoclimatology.\nSoil geography deals with the distribution of soils across the terrain. This discipline, between geography and soil science, is fundamental to both physical geography and pedology. Pedology is the study of soils in their natural environment. It deals with pedogenesis, soil morphology, soil classification. Soil geography studies the spatial distribution of soils as it relates to topography, climate (water, air, temperature), soil life (micro-organisms, plants, animals) and mineral materials within soils (biogeochemical cycles).\nPalaeogeography is a cross-disciplinary study that examines the preserved material in the stratigraphic record to determine the distribution of the continents through geologic time. Almost all the evidence for the positions of the continents comes from geology in the form of fossils or paleomagnetism. The use of these data has resulted in evidence for continental drift, plate tectonics, and supercontinents. This, in turn, has supported palaeogeographic theories such as the Wilson cycle",
      "url": "https://en.wikipedia.org/wiki/Physical_geography",
      "topic": "Geography",
      "timestamp": "2025-11-14T00:20:37.503422",
      "type": "wikipedia_content"
    },
    {
      "title": "Mathematics",
      "summary": "Mathematics is a field of study that discovers and organizes methods, theories, and theorems that are developed and proved for the needs of empirical sciences and mathematics itself. There are many areas of mathematics, which include number theory (the study of numbers), algebra (the study of formulas and related structures), geometry (the study of shapes and spaces that contain them), analysis (the study of continuous changes), and set theory (presently used as a foundation for all mathematics).\nMathematics involves the description and manipulation of abstract objects that consist of either abstractions from nature or—in modern mathematics—purely abstract entities that are stipulated to have certain properties, called axioms.  Mathematics uses pure reason to prove properties of objects, a proof consisting of a succession of applications of deductive rules to already established results. These results, called theorems, include previously proved theorems, axioms, and—in case of abstract",
      "content": "Mathematics is a field of study that discovers and organizes methods, theories, and theorems that are developed and proved for the needs of empirical sciences and mathematics itself. There are many areas of mathematics, which include number theory (the study of numbers), algebra (the study of formulas and related structures), geometry (the study of shapes and spaces that contain them), analysis (the study of continuous changes), and set theory (presently used as a foundation for all mathematics).\nMathematics involves the description and manipulation of abstract objects that consist of either abstractions from nature or—in modern mathematics—purely abstract entities that are stipulated to have certain properties, called axioms.  Mathematics uses pure reason to prove properties of objects, a proof consisting of a succession of applications of deductive rules to already established results. These results, called theorems, include previously proved theorems, axioms, and—in case of abstraction from nature—some basic properties that are considered true starting points of the theory under consideration.\nMathematics is essential in the natural sciences, engineering, medicine, finance, computer science, and the social sciences. Although mathematics is extensively used for modeling phenomena, the fundamental truths of mathematics are independent of any scientific experimentation. Some areas of mathematics, such as statistics and game theory, are developed in close correlation with their applications and are often grouped under applied mathematics. Other areas are developed independently from any application (and are therefore called pure mathematics) but often later find practical applications.\nHistorically, the concept of a proof and its associated mathematical rigour first appeared in Greek mathematics, most notably in Euclid's Elements. Since its beginning, mathematics was primarily divided into geometry and arithmetic (the manipulation of natural numbers and fractions), until the 16th and 17th centuries, when algebra and infinitesimal calculus were introduced as new fields. Since then, the interaction between mathematical innovations and scientific discoveries has led to a correlated increase in the development of both. At the end of the 19th century, the foundational crisis of mathematics led to the systematization of the axiomatic method, which heralded a dramatic increase in the number of mathematical areas and their fields of application. The contemporary Mathematics Subject Classification lists more than sixty first-level areas of mathematics.\n\n\n== Areas of mathematics ==\n\nBefore the Renaissance, mathematics was divided into two main areas: arithmetic, regarding the manipulation of numbers, and geometry, regarding the study of shapes. Some types of pseudoscience, such as numerology and astrology, were not then clearly distinguished from mathematics.\nDuring the Renaissance, two more areas appeared. Mathematical notation led to algebra which, roughly speaking, consists of the study and the manipulation of formulas. Calculus, consisting of the two subfields differential calculus and integral calculus, is the study of continuous functions, which model the typically nonlinear relationships between varying quantities, as represented by variables. This division into four main areas—arithmetic, geometry, algebra, and calculus—endured until the end of the 19th century. Areas such as celestial mechanics and solid mechanics were then studied by mathematicians, but now are considered as belonging to physics. The subject of combinatorics has been studied for much of recorded history, yet did not become a separate branch of mathematics until the seventeenth century.\nAt the end of the 19th century, the foundational crisis in mathematics and the resulting systematization of the axiomatic method led to an explosion of new areas of mathematics. The 2020 Mathematics Subject Classification contains no less than sixty-three first-level areas. Some of these areas correspond to the older division, as is true regarding number theory (the modern name for higher arithmetic) and geometry. Several other first-level areas have \"geometry\" in their names or are otherwise commonly considered part of geometry. Algebra and calculus do not appear as first-level areas but are respectively split into several first-level areas. Other first-level areas emerged during the 20th century or had not previously been considered as mathematics, such as mathematical logic and foundations.\n\n\n=== Number theory ===\n\nNumber theory began with the manipulation of numbers, that is, natural numbers \n  \n    \n      \n        (\n        \n          N\n        \n        )\n        ,\n      \n    \n    {\\displaystyle (\\mathbb {N} ),}\n  \n and later expanded to integers \n  \n    \n      \n        (\n        \n          Z\n        \n        )\n      \n    \n    {\\displaystyle (\\mathbb {Z} )}\n  \n and rational numbers \n  \n    \n      \n        (\n        \n          Q\n        \n        )\n        ",
      "url": "https://en.wikipedia.org/wiki/Mathematics",
      "topic": "Mathematics",
      "timestamp": "2025-11-14T00:20:41.147048",
      "type": "wikipedia_content"
    },
    {
      "title": "Set (mathematics)",
      "summary": "In mathematics, a set is a collection of different things; the things are elements or members of the set and are typically mathematical objects: numbers, symbols, points in space, lines, other geometric shapes, variables, or other sets.  A set may be finite or infinite. There is a unique set with no elements, called the empty set; a set with a single element is a singleton.  \nSets are ubiquitous in modern mathematics. Indeed, set theory, more specifically Zermelo–Fraenkel set theory, has been the standard way to provide rigorous foundations for all branches of mathematics since the first half of the 20th century.\n\n",
      "content": "In mathematics, a set is a collection of different things; the things are elements or members of the set and are typically mathematical objects: numbers, symbols, points in space, lines, other geometric shapes, variables, or other sets.  A set may be finite or infinite. There is a unique set with no elements, called the empty set; a set with a single element is a singleton.  \nSets are ubiquitous in modern mathematics. Indeed, set theory, more specifically Zermelo–Fraenkel set theory, has been the standard way to provide rigorous foundations for all branches of mathematics since the first half of the 20th century.\n\n\n== Context ==\nBefore the end of the 19th century, sets were not studied specifically, and were not clearly distinguished from sequences. Most mathematicians considered infinity as potential—meaning that it is the result of an endless process—and were reluctant to consider infinite sets, that is sets whose number of members is not a natural number. Specifically, a line was not considered as the set of its points, but as a locus where points may be located. \nThe mathematical study of infinite sets began with Georg Cantor (1845–1918). This provided some counterintuitive facts and paradoxes. For example, the number line has an infinite number of elements that is strictly larger than the infinite number of natural numbers, and any line segment has the same number of elements as the whole space. Also, Russell's paradox implies that the phrase \"the set of all sets\" is self-contradictory.\nTogether with other counterintuitive results, this led to the foundational crisis of mathematics, which was eventually resolved with the general adoption of Zermelo–Fraenkel set theory as a robust foundation of set theory and all mathematics. \nMeanwhile, sets started to be widely used in all mathematics. In particular, algebraic structures and mathematical spaces are typically defined in terms of sets. Also, many older mathematical results are restated in terms of sets. For example, Euclid's theorem is often stated as \"the set of the prime numbers is infinite\". This wide use of sets in mathematics was prophesied by David Hilbert when saying: \"No one will drive us from the paradise which Cantor created for us.\"\nGenerally, the common usage of sets in mathematics does not require the full power of Zermelo–Fraenkel set theory. In mathematical practice, sets can be manipulated independently of the logical framework of this theory.\nThe object of this article is to summarize the manipulation rules and properties of sets that are commonly used in mathematics, without reference to any logical framework. For the branch of mathematics that studies sets, see Set theory; for an informal presentation of the corresponding logical framework, see Naive set theory; for a more formal presentation, see Axiomatic set theory and Zermelo–Fraenkel set theory.\n\n\n== Basic notions ==\nIn mathematics, a set is a collection of different things. These things are called elements or members of the set and are typically mathematical objects of any kind such as numbers, symbols, points in space, lines, other geometrical shapes, variables, functions, or even other sets. A set may also be called a collection or family, especially when its elements are themselves sets; this may avoid the confusion between the set and its members, and may make reading easier. A set may be specified either by listing its elements or by a property that characterizes its elements, such as for the set of the prime numbers or the set of all students in a given class.\nIf ⁠\n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n⁠ is an element of a set ⁠\n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n⁠, one says that ⁠\n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n⁠ belongs to ⁠\n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n⁠ or is in ⁠\n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n⁠, and this is written as ⁠\n  \n    \n      \n        x\n        ∈\n        S\n      \n    \n    {\\displaystyle x\\in S}\n  \n⁠. The statement \"⁠\n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n⁠ is not in ⁠\n  \n    \n      \n        S\n        \n      \n    \n    {\\displaystyle S\\,}\n  \n⁠\" is written as ⁠\n  \n    \n      \n        y\n        ∉\n        S\n      \n    \n    {\\displaystyle y\\not \\in S}\n  \n⁠, which can also be read as \"y is not in S\". For example, if ⁠\n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \n⁠ is the set of the integers, one has ⁠\n  \n    \n      \n        −\n        3\n        ∈\n        \n          Z\n        \n      \n    \n    {\\displaystyle -3\\in \\mathbb {Z} }\n  \n⁠ and ⁠\n  \n    \n      \n        1.5\n        ∉\n        \n          Z\n        \n      \n    \n    {\\displaystyle 1.5\\not \\in \\mathbb {Z} }\n  \n⁠. Each set is uniquely characterized by its elements. In particular, two sets that have precisely the same elements are equal (they are the same set). This property, called extensionality, can b",
      "url": "https://en.wikipedia.org/wiki/Set_(mathematics)",
      "topic": "Mathematics",
      "timestamp": "2025-11-14T00:20:44.087435",
      "type": "wikipedia_content"
    },
    {
      "title": "Matrix (mathematics)",
      "summary": "In mathematics, a matrix (pl.: matrices) is a rectangular array of numbers or other mathematical objects with elements or entries arranged in rows and columns, usually satisfying certain properties of addition and multiplication. \nFor example, \n\n  \n    \n      \n        \n          \n            [\n            \n              \n                \n                  1\n                \n                \n                  9\n                \n                \n                  −\n                  13\n                \n              \n              \n                \n                  20\n                \n                \n                  5\n                \n                \n                  −\n                  6\n                \n              \n            \n            ]\n          \n        \n      \n    \n    {\\displaystyle {\\begin{bmatrix}1&9&-13\\\\20&5&-6\\end{bmatrix}}}\n  \n\ndenotes a matrix with two rows and three columns. This is often referred to as a \"two-by-three matrix\", a 2 × 3 matrix, or a matrix of d",
      "content": "In mathematics, a matrix (pl.: matrices) is a rectangular array of numbers or other mathematical objects with elements or entries arranged in rows and columns, usually satisfying certain properties of addition and multiplication. \nFor example, \n\n  \n    \n      \n        \n          \n            [\n            \n              \n                \n                  1\n                \n                \n                  9\n                \n                \n                  −\n                  13\n                \n              \n              \n                \n                  20\n                \n                \n                  5\n                \n                \n                  −\n                  6\n                \n              \n            \n            ]\n          \n        \n      \n    \n    {\\displaystyle {\\begin{bmatrix}1&9&-13\\\\20&5&-6\\end{bmatrix}}}\n  \n\ndenotes a matrix with two rows and three columns. This is often referred to as a \"two-by-three matrix\", a 2 × 3 matrix, or a matrix of dimension 2 × 3.\nIn linear algebra, matrices are used as linear maps. In geometry, matrices are used for geometric transformations (for example rotations) and coordinate changes. In numerical analysis, many computational problems are solved by reducing them to a matrix computation, and this often involves computing with matrices of huge dimensions. Matrices are used in most areas of mathematics and scientific fields, either directly, or through their use in geometry and numerical analysis.\nSquare matrices, matrices with the same number of rows and columns, play a major role in matrix theory. The determinant of a square matrix is a number associated with the matrix, which is fundamental for the study of a square matrix; for example, a square matrix is invertible if and only if it has a nonzero determinant and the eigenvalues of a square matrix are the roots of its characteristic polynomial, \n  \n    \n      \n        det\n        (\n        λ\n        I\n        −\n        A\n        )\n      \n    \n    {\\displaystyle \\det(\\lambda I-A)}\n  \n.\nMatrix theory is the branch of mathematics that focuses on the study of matrices. It was initially a sub-branch of linear algebra, but soon grew to include subjects related to graph theory, algebra, combinatorics and statistics.\n\n\n== Definition ==\nA matrix is a rectangular array of numbers (or other mathematical objects), called the \"entries\" of the matrix. Matrices are subject to standard operations such as addition and multiplication. Most commonly, a matrix over a field \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n is a rectangular array of elements of ⁠\n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n⁠. A real matrix and a complex matrix are matrices whose entries are respectively real numbers or complex numbers. More general types of entries are discussed below. For instance, this is a real matrix:\n\n  \n    \n      \n        \n          A\n        \n        =\n        \n          \n            [\n            \n              \n                \n                  −\n                  1.3\n                \n                \n                  0.6\n                \n              \n              \n                \n                  20.4\n                \n                \n                  5.5\n                \n              \n              \n                \n                  9.7\n                \n                \n                  −\n                  6.2\n                \n              \n            \n            ]\n          \n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {A} ={\\begin{bmatrix}-1.3&0.6\\\\20.4&5.5\\\\9.7&-6.2\\end{bmatrix}}.}\n  \n\nThe numbers (or other objects) in the matrix are called its entries or its elements. The horizontal and vertical lines of entries in a matrix are respectively called rows and columns.\n\n\n=== Size ===\nThe size of a matrix is defined by the number of rows and columns it contains. There is no limit to the number of rows and columns that a matrix (in the usual sense) can have as long as they are positive integers. A matrix with m rows and n columns is called an m × n matrix, or m-by-n matrix, where m and n are called its dimensions. For example, the matrix \n  \n    \n      \n        \n          \n            A\n          \n        \n      \n    \n    {\\displaystyle {\\mathbf {A} }}\n  \n above is a 3 × 2 matrix.\nMatrices with a single row are called row matrices or row vectors, and those with a single column are called column matrices or column vectors. A matrix with the same number of rows and columns is called a square matrix. A matrix with an infinite number of rows or columns (or both) is called an  infinite matrix. In some contexts, such as computer algebra programs, it is useful to consider a matrix with no rows or no columns, called an  empty matrix.\n\n\n== Notation ==\nThe specifics of symbolic matrix notation vary widely, with some prevailing trends.  Matrices are commonly written in square brackets or parentheses, so that an m × n matrix \n  \n    \n      \n       ",
      "url": "https://en.wikipedia.org/wiki/Matrix_(mathematics)",
      "topic": "Mathematics",
      "timestamp": "2025-11-14T00:20:47.382873",
      "type": "wikipedia_content"
    },
    {
      "title": "Physical examination",
      "summary": "In a physical examination, medical examination, clinical examination, or medical checkup, a medical practitioner examines a patient for any possible medical signs or symptoms of a medical condition. It generally consists of a series of questions about the patient's medical history followed by an examination based on the reported symptoms. Together, the medical history and the physical examination help to determine a diagnosis and devise the treatment plan. These data then become part of the medical record.",
      "content": "In a physical examination, medical examination, clinical examination, or medical checkup, a medical practitioner examines a patient for any possible medical signs or symptoms of a medical condition. It generally consists of a series of questions about the patient's medical history followed by an examination based on the reported symptoms. Together, the medical history and the physical examination help to determine a diagnosis and devise the treatment plan. These data then become part of the medical record.\n\n\n== Types ==\n\n\n=== Routine ===\nThe routine physical, also known as general medical examination, periodic health evaluation, annual physical, comprehensive medical exam, general health check, preventive health examination, medical check-up, or simply medical, is a physical examination performed on an asymptomatic patient for medical screening purposes.  These are normally performed by a pediatrician, family practice physician, a physical therapist, physician assistant, a certified nurse practitioner or other primary care provider. This routine physical exam usually includes the HEENT evaluation. Nursing professionals such as Registered Nurse, Licensed Practical Nurses can develop a baseline assessment to identify normal versus abnormal findings. These are reported to the primary care provider. If necessary, the patient may be sent to a medical specialist for further, more detailed examinations.\nThe term is generally not meant to include visits for the purpose of newborn checks, Pap smears for cervical cancer, or regular visits for people with certain chronic medical disorders (for example, diabetes). The general medical examination generally involves a medical history, a (brief or complete) physical examination and sometimes laboratory tests. Some more advanced tests include ultrasound and mammography.\nIf done for a group of people the routine physical is a form of screening, as the aim of the examination is to detect early signs of diseases to prevent them.\n\n\n==== Evidence ====\nAlthough annual medical examinations are a routine practice in several countries, examinations performed on an asymptomatic patient are poorly supported by scientific evidence in the majority of the population. A Cochrane Collaboration meta-study found that routine annual physicals did not measurably reduce the risk of illness or death, and conversely, could lead to overdiagnosis and over-treatment; however, this article does not conclude that being in regular communication with a doctor is not important, simply that an actual physical examination may not be necessary.\nSome notable general health organisations recommend against annual examinations, and propose a frequency adapted to age and previous examination results (risk factors). The specialist American Cancer Society recommends a cancer-related health check-up annually in men and women older than 40, and every three years for those older than 20.\nA systematic review of studies until September 2006 concluded that the examination does result in better delivery of some other screening interventions (such as Pap smears, cholesterol screening, and faecal occult blood tests) and less patient worry. Evidence supports several of these individual screening interventions. The effects of annual check-ups on overall costs, patient disability and mortality, disease detection, and intermediate end points such a blood pressure or cholesterol, are inconclusive. A recent study found that the examination is associated with increased participation in cancer screening.\nSome employers  require a mandatory health checkup before hiring a candidate, even though it is now well known that some of the components of the prophylactic annual visit may actually cause harm. For example, lab tests and exams that are performed on healthy patients (as opposed to people with symptoms or known illnesses) are statistically more likely to be \"false positives\"—that is, when test results suggest a problem that does not exist. Disadvantages cited include the time and money that could be saved by targeted screening (health economics argument), increased anxiety over health risks (medicalisation), overdiagnosis, wrong diagnosis (for example athletic heart syndrome misdiagnosed as hypertrophic cardiomyopathy) and harm, or even death, resulting from unnecessary testing to detect or confirm, often non-existent, medical problems or while performing routine procedures as a followup after screening.\n\nThe lack of good evidence contrasts with population surveys showing that the general public is fond of these examinations, especially when they are free of charge. Despite guidelines recommending against routine annual examinations, many family physicians perform them. A fee-for-service healthcare system has been suggested to promote this practice. An alternative would be to tailor the screening interval to the age, sex, medical conditions and risk factors of each patient. This means choosing between a wide variety of tests.\n\n\n",
      "url": "https://en.wikipedia.org/wiki/Physical_examination",
      "topic": "Physics",
      "timestamp": "2025-11-14T00:20:52.621646",
      "type": "wikipedia_content"
    },
    {
      "title": "Particle physics",
      "summary": "Particle physics or high-energy physics is the study of fundamental particles and forces that constitute matter and radiation. The field also studies combinations of elementary particles up to the scale of protons and neutrons, while the study of combinations of protons and neutrons is called nuclear physics.\nThe fundamental particles in the universe are classified in the Standard Model as fermions (matter particles) and bosons (force-carrying particles). There are three generations of fermions, although ordinary matter is made only from the first fermion generation. The first generation consists of up and down quarks which form protons and neutrons, and electrons and electron neutrinos. The three fundamental interactions known to be mediated by bosons are electromagnetism, the weak interaction, and the strong interaction.\nQuarks form hadrons, but cannot exist on their own. Hadrons that contain an odd number of quarks are called baryons and those that contain an even number are called ",
      "content": "Particle physics or high-energy physics is the study of fundamental particles and forces that constitute matter and radiation. The field also studies combinations of elementary particles up to the scale of protons and neutrons, while the study of combinations of protons and neutrons is called nuclear physics.\nThe fundamental particles in the universe are classified in the Standard Model as fermions (matter particles) and bosons (force-carrying particles). There are three generations of fermions, although ordinary matter is made only from the first fermion generation. The first generation consists of up and down quarks which form protons and neutrons, and electrons and electron neutrinos. The three fundamental interactions known to be mediated by bosons are electromagnetism, the weak interaction, and the strong interaction.\nQuarks form hadrons, but cannot exist on their own. Hadrons that contain an odd number of quarks are called baryons and those that contain an even number are called mesons. Two baryons, the proton and the neutron, make up most of the mass of ordinary matter. Mesons are unstable and the longest-lived last for only a few hundredths of a microsecond. They occur after collisions between particles made of quarks, such as fast-moving protons and neutrons in cosmic rays. Mesons are also produced in cyclotrons or other particle accelerators.\nParticles have corresponding antiparticles with the same mass but with opposite electric charges. For example, the antiparticle of the electron is the positron. The electron has a negative electric charge, the positron has a positive charge. These antiparticles can theoretically form a corresponding form of matter called antimatter. Some particles, such as the photon, are their own antiparticle.\nThese elementary particles are excitations of the quantum fields that also govern their interactions. The dominant theory explaining these fundamental particles and fields, along with their dynamics, is called the Standard Model. The reconciliation of gravity to the current particle physics theory is not solved; many theories have addressed this problem, such as loop quantum gravity, string theory and supersymmetry theory.\nExperimental particle physics is the study of these particles in radioactive processes and in particle accelerators such as the Large Hadron Collider. Theoretical particle physics is the study of these particles in the context of cosmology and quantum theory. The two are closely interrelated: the Higgs boson was postulated theoretically before being confirmed by experiments.\n\n\n== History ==\n\nThe idea that all matter is fundamentally composed of elementary particles dates from at least the 6th century BC. In the 19th century, John Dalton, through his work on stoichiometry, concluded that each element of nature was composed of a single, unique type of particle. The word atom, after the Greek word atomos meaning \"indivisible\", has since then denoted the smallest particle of a chemical element, but physicists later discovered that atoms are not, in fact, the fundamental particles of nature, but are conglomerates of even smaller particles, such as the electron. The early 20th century explorations of nuclear physics and quantum physics led to proofs of nuclear fission in 1939 by Lise Meitner (based on experiments by Otto Hahn), and nuclear fusion by Hans Bethe in that same year; both discoveries also led to the development of nuclear weapons. Bethe's 1947 calculation of the Lamb shift is credited with having \"opened the way to the modern era of particle physics\".\nThroughout the 1950s and 1960s, a bewildering variety of particles was found in collisions of particles from beams of increasingly high energy. It was referred to informally as the \"particle zoo\". Important discoveries such as the CP violation by James Cronin and Val Fitch brought new questions to matter-antimatter imbalance. After the formulation of the Standard Model during the 1970s, physicists clarified the origin of the particle zoo. The large number of particles was explained as combinations of a (relatively) small number of more fundamental particles and framed in the context of quantum field theories. This reclassification marked the beginning of modern particle physics.\n\n\n== Standard Model ==\n\nThe current state of the classification of all elementary particles is explained by the Standard Model, which gained widespread acceptance in the mid-1970s after experimental confirmation of the existence of quarks. It describes the strong, weak, and electromagnetic fundamental interactions, using mediating gauge bosons. The species of gauge bosons are eight gluons, W−, W+ and Z bosons, and the photon. The Standard Model also contains 24 fundamental fermions (12 particles and their associated anti-particles), which are the constituents of all matter. Finally, the Standard Model also predicted the existence of a type of boson known as the Higgs boson. On 4 July 2012, physicists with the Large Hadron",
      "url": "https://en.wikipedia.org/wiki/Particle_physics",
      "topic": "Physics",
      "timestamp": "2025-11-14T00:20:56.678904",
      "type": "wikipedia_content"
    },
    {
      "title": "Chemistry",
      "summary": "Chemistry is the scientific study of the properties and behavior of matter. It is a physical science within the natural sciences that studies the chemical elements that make up matter and compounds made of atoms, molecules and ions: their composition, structure, properties, behavior and the changes they undergo during reactions with other substances. Chemistry also addresses the nature of chemical bonds in chemical compounds.\nIn the scope of its subject, chemistry occupies an intermediate position between physics and biology. It is sometimes called the central science because it provides a foundation for understanding both basic and applied scientific disciplines at a fundamental level. For example, chemistry explains aspects of plant growth (botany), the formation of igneous rocks (geology), how atmospheric ozone is formed and how environmental pollutants are degraded (ecology), the properties of the soil on the Moon (cosmochemistry), how medications work (pharmacology), and how to co",
      "content": "Chemistry is the scientific study of the properties and behavior of matter. It is a physical science within the natural sciences that studies the chemical elements that make up matter and compounds made of atoms, molecules and ions: their composition, structure, properties, behavior and the changes they undergo during reactions with other substances. Chemistry also addresses the nature of chemical bonds in chemical compounds.\nIn the scope of its subject, chemistry occupies an intermediate position between physics and biology. It is sometimes called the central science because it provides a foundation for understanding both basic and applied scientific disciplines at a fundamental level. For example, chemistry explains aspects of plant growth (botany), the formation of igneous rocks (geology), how atmospheric ozone is formed and how environmental pollutants are degraded (ecology), the properties of the soil on the Moon (cosmochemistry), how medications work (pharmacology), and how to collect DNA evidence at a crime scene (forensics).\nChemistry has existed under various names since ancient times. It has evolved, and now chemistry encompasses various areas of specialisation, or subdisciplines, that continue to increase in number and interrelate to create further interdisciplinary fields of study. The applications of various fields of chemistry are used frequently for economic purposes in the chemical industry.\n\n\n== Etymology ==\n\nThe word chemistry comes from a modification during the Renaissance of the word alchemy, which referred to an earlier set of practices that encompassed elements of chemistry, metallurgy, philosophy, astrology, astronomy, mysticism, and medicine. Alchemy is often associated with the quest to turn lead or other base metals into gold, though alchemists were also interested in many of the questions of modern chemistry.\nThe modern word alchemy in turn is derived from the Arabic word al-kīmīā (الكیمیاء). This may have Egyptian origins since al-kīmīā is derived from the Ancient Greek χημία, which is in turn derived from the word Kemet, which is the ancient name of Egypt in the Egyptian language. Alternately, al-kīmīā may derive from χημεία 'cast together'.\n\n\n== Modern principles ==\n\nThe current model of atomic structure is the quantum mechanical model. Traditional chemistry starts with the study of elementary particles, atoms, molecules, substances, metals, crystals and other aggregates of matter. Matter can be studied in solid, liquid, gas and plasma states, in isolation or in combination. The interactions, reactions and transformations that are studied in chemistry are usually the result of interactions between atoms, leading to rearrangements of the chemical bonds which hold atoms together. Such behaviors are studied in a chemistry laboratory.\nThe chemistry laboratory stereotypically uses various forms of laboratory glassware. However glassware is not central to chemistry, and a great deal of experimental (as well as applied/industrial) chemistry is done without it.\n\nA chemical reaction is a transformation of some substances into one or more different substances. The basis of such a chemical transformation is the rearrangement of electrons in the chemical bonds between atoms. It can be symbolically depicted through a chemical equation, which usually involves atoms as subjects. The number of atoms on the left and the right in the equation for a chemical transformation is equal. (When the number of atoms on either side is unequal, the transformation is referred to as a nuclear reaction or radioactive decay.) The type of chemical reactions a substance may undergo and the energy changes that may accompany it are constrained by certain basic rules, known as chemical laws.\nEnergy and entropy considerations are invariably important in almost all chemical studies. Chemical substances are classified in terms of their structure, phase, as well as their chemical compositions. They can be analyzed using the tools of chemical analysis, e.g. spectroscopy and chromatography. Scientists engaged in chemical research are known as chemists. Most chemists specialize in one or more sub-disciplines. Several concepts are essential for the study of chemistry; some of them are:\n\n\n=== Matter ===\n\nIn chemistry, matter is defined as anything that has rest mass and volume (it takes up space) and is made up of particles. The particles that make up matter have rest mass as well – not all particles have rest mass, such as the photon. Matter can be a pure chemical substance or a mixture of substances.\n\n\n==== Atom ====\n\nThe atom is the basic unit of chemistry. It consists of a dense core called the atomic nucleus surrounded by a space occupied by an electron cloud. The nucleus is made up of positively charged protons and uncharged neutrons (together called nucleons), while the electron cloud consists of negatively charged electrons which orbit the nucleus. In a neutral atom, the negatively charged electrons balance out the",
      "url": "https://en.wikipedia.org/wiki/Chemistry",
      "topic": "Chemistry",
      "timestamp": "2025-11-14T00:21:01.972446",
      "type": "wikipedia_content"
    },
    {
      "title": "Chemistry (band)",
      "summary": "Chemistry (styled as CHEMISTRY) is a Japanese pop duo, consisting of Yoshikuni Dōchin (堂珍 嘉邦; born November 17, 1978) and Kaname Kawabata (川畑 要; born January 28, 1979).",
      "content": "Chemistry (styled as CHEMISTRY) is a Japanese pop duo, consisting of Yoshikuni Dōchin (堂珍 嘉邦; born November 17, 1978) and Kaname Kawabata (川畑 要; born January 28, 1979).\n\n\n== History ==\nThey were the winners of the Asayan audition (similar to the American Idol series) in 2000 organized by Sony Music Entertainment Japan.\nTheir first single \"Pieces of a Dream\" was released on March 3, 2001, and was the best selling single that year (over 2 million). Most of their singles have reached #1 on the Oricon charts; all five albums have reached #1 the day they were released. Their #1 streak was broken by the KinKi Kids' album H Album: Hand, scoring them a #2 rank for Fo(u)r.\nChemistry is also known in Korea for the popular collaboration song \"Let's Get Together Now,\" featuring talents from both Korea and Japan and for collaborating with Korean singer Lena Park who appears in the B-side \"Dance with Me\" on the \"Kimi ga Iru\" single.\nTheir song \"Tookage\" plays during the credits of the Japanese dub of Open Season.\nOn March 6, 2008, Kaname Kawabata married model Miki Takahashi. They met after she appeared in the PV for \"This Night.\"\nTheir single \"Period\" was selected as the fourth opening for the anime series Fullmetal Alchemist: Brotherhood.\nIn 2010, Chemistry worked together with the 4-person dance group Synergy to release \"Shawty\". Another joint work of the two groups was released November 3, 2010, titled \"Keep Your Love\".\nIn 2011, Chemistry was tapped by Bandai Visual to record a song for the OVA series, Mobile Suit Gundam Unicorn, due to be the title song for the 3rd episode, \"The Ghost of Laplace\". \"Merry-go-round\" is due for release on March 2, 2011, as a follow-up before the OVA's actual release on March 5, 2011.\nTheir 15th single \"Wings of Words\" was used as the fourth opening theme for Mobile Suit Gundam SEED Destiny from PHASE-38 to 49.  Chemistry performed this song live in collaboration with the two-time Olympic champion in figure skating, Yuzuru Hanyu, at the 2018 Fantasy on Ice in Makuhari and Kanazawa. Kawabata made a solo appearance in the 2016 edition of the ice show as well.\nAfter going on hiatus in 2012 so that both members could focus on pursuing solo careers, the pair resumed activities as a musical duo in 2017. Their new single \"Windy\" was used as the second ending theme song for the anime adaptation of Altair: A Record of Battles.\n\n\n== Discography ==\n\n\n=== Albums ===\n\n\n=== Singles ===\n\n\n=== Videos ===\n\n\n== References ==\n\n\n== External links ==\n\nOfficial website (in Japanese)\nChemistry at Sony Music Japan  (in Japanese)\nChemistry at Sony Music Japan  (in Japanese)\nChemistry Notes",
      "url": "https://en.wikipedia.org/wiki/Chemistry_(band)",
      "topic": "Chemistry",
      "timestamp": "2025-11-14T00:21:04.240782",
      "type": "wikipedia_content"
    },
    {
      "title": "Bioorganic chemistry",
      "summary": "Bioorganic chemistry is a scientific discipline that combines organic chemistry and biochemistry. It is the branch of life science that deals with the study of biological processes using chemical methods. Protein and enzyme function are examples of these processes.\nSometimes biochemistry is used interchangeably for bioorganic chemistry; the distinction being that bioorganic chemistry is organic chemistry that is focused on the biological aspects. While biochemistry aims at understanding biological processes using chemistry, bioorganic chemistry attempts to expand organic-chemical researches (that is, structures, synthesis, and kinetics) toward biology. When investigating metalloenzymes and cofactors, bioorganic chemistry overlaps bioinorganic chemistry.",
      "content": "Bioorganic chemistry is a scientific discipline that combines organic chemistry and biochemistry. It is the branch of life science that deals with the study of biological processes using chemical methods. Protein and enzyme function are examples of these processes.\nSometimes biochemistry is used interchangeably for bioorganic chemistry; the distinction being that bioorganic chemistry is organic chemistry that is focused on the biological aspects. While biochemistry aims at understanding biological processes using chemistry, bioorganic chemistry attempts to expand organic-chemical researches (that is, structures, synthesis, and kinetics) toward biology. When investigating metalloenzymes and cofactors, bioorganic chemistry overlaps bioinorganic chemistry.\n\n\n== Sub disciplines ==\nBiophysical organic chemistry is a term used when attempting to describe intimate details of molecular recognition by bioorganic chemistry.\nNatural product chemistry is the process of Identifying compounds found in nature to determine their properties. Compound discoveries have and often lead to medicinal uses, development of herbicides and insecticides.\n\n\n== References ==",
      "url": "https://en.wikipedia.org/wiki/Bioorganic_chemistry",
      "topic": "Chemistry",
      "timestamp": "2025-11-14T00:21:07.397495",
      "type": "wikipedia_content"
    },
    {
      "title": "Geology",
      "summary": "Geology is a branch of natural science concerned with the Earth and other astronomical bodies, the rocks of which they are composed, and the processes by which they change over time. The name comes from Ancient Greek  γῆ (gê) 'earth' and  λoγία (-logía) 'study of, discourse'. Modern geology significantly overlaps all other Earth sciences, including hydrology. It is integrated with Earth system science and planetary science.\nGeology describes the structure of the Earth on and beneath its surface and the processes that have shaped that structure. Geologists study the mineralogical composition of rocks in order to get insight into their history of formation. Geology determines the relative ages of rocks found at a given location; geochemistry (a branch of geology) determines their absolute ages. By combining various petrological, crystallographic, and paleontological tools, geologists are able to chronicle the geological history of the Earth as a whole. One aspect is to demonstrate the ag",
      "content": "Geology is a branch of natural science concerned with the Earth and other astronomical bodies, the rocks of which they are composed, and the processes by which they change over time. The name comes from Ancient Greek  γῆ (gê) 'earth' and  λoγία (-logía) 'study of, discourse'. Modern geology significantly overlaps all other Earth sciences, including hydrology. It is integrated with Earth system science and planetary science.\nGeology describes the structure of the Earth on and beneath its surface and the processes that have shaped that structure. Geologists study the mineralogical composition of rocks in order to get insight into their history of formation. Geology determines the relative ages of rocks found at a given location; geochemistry (a branch of geology) determines their absolute ages. By combining various petrological, crystallographic, and paleontological tools, geologists are able to chronicle the geological history of the Earth as a whole. One aspect is to demonstrate the age of the Earth. Geology provides evidence for plate tectonics, the evolutionary history of life, and the Earth's past climates.\nGeologists broadly study the properties and processes of Earth and other terrestrial planets. Geologists use a wide variety of methods to understand the Earth's structure and evolution, including fieldwork, rock description, geophysical techniques, chemical analysis, physical experiments, and numerical modelling. In practical terms, geology is important for mineral and hydrocarbon exploration and exploitation, evaluating water resources, understanding natural hazards, remediating environmental problems, and providing insights into past climate change. Geology is a major academic discipline, and it is central to geological engineering and plays an important role in geotechnical engineering.\n\n\n== Geological material ==\n\nThe majority of geological data comes from research on solid Earth materials. Meteorites and other extraterrestrial natural materials are also studied by geological methods.\n\n\n=== Minerals ===\n\nMinerals are naturally occurring elements and compounds with a definite homogeneous chemical composition and an ordered atomic arrangement. Amorphous substances that resemble a mineral are sometimes referred to as mineraloids, although there are exceptions such as georgeite and autunite. Some amorphous substances formed by geological processes are considered minerals if the original substance was a mineral before metamictisation.\nEach mineral has distinct physical properties, and there are many tests to determine each of them. Minerals are often identified through these tests. The specimens can be tested for:\n\nColor: Minerals are grouped by their color. Mostly diagnostic but impurities can change a mineral's color.\nStreak: Performed by scratching the sample on a porcelain plate. The color of the streak can help identify the mineral.\nHardness: The resistance of a mineral to scratching or indentation.\nBreakage pattern: A mineral can either show fracture or cleavage, the former being breakage of uneven surfaces, and the latter a breakage along closely spaced parallel planes.\nLuster: Quality of light reflected from the surface of a mineral. Examples are metallic, pearly, waxy, dull.\nSpecific gravity: the weight of a specific volume of a mineral.\nEffervescence: Involves dripping hydrochloric acid on the mineral to test for fizzing.\nMagnetism: Involves using a magnet to test for magnetism.\nTaste: Minerals can have a distinctive taste such as halite (which tastes like table salt).\n\n\n=== Rock ===\n\nA rock is any naturally occurring solid mass or aggregate of minerals or mineraloids. Most research in geology is associated with the study of rocks, as they provide the primary record of the majority of the geological history of the Earth. There are three major types of rock: igneous, sedimentary, and metamorphic. The rock cycle\nillustrates the relationships among them (see diagram).\nWhen a rock solidifies or crystallizes from melt (magma or lava), it is an igneous rock. The active flow of molten rock is closely studied in volcanology, and igneous petrology aims to determine the history of igneous rocks from their original molten source to their final crystallization.\nRocks can be weathered and eroded, then redeposited and lithified into a sedimentary rock. Sedimentary rocks are mainly divided into four categories: sandstone, shale, carbonate, and evaporite. This group of classifications focuses partly on the size of sedimentary particles (sandstone and shale), and partly on mineralogy and formation processes (carbonation and evaporation). Igneous and sedimentary rocks can then be turned into metamorphic rocks by heat and pressure that change its mineral content, resulting in a characteristic fabric. All three types may melt again, and when this happens, new magma is formed, from which an igneous rock may once again solidify. Organic matter, such as coal, bitumen, oil, and natural gas, is linked mainly to organ",
      "url": "https://en.wikipedia.org/wiki/Geology",
      "topic": "Biology",
      "timestamp": "2025-11-14T00:21:11.057826",
      "type": "wikipedia_content"
    },
    {
      "title": "Taxonomy (biology)",
      "summary": "In biology, taxonomy (from Ancient Greek  τάξις (taxis) 'arrangement' and  -νομία (-nomia) 'method') is the scientific study of naming, defining (circumscribing) and classifying groups of biological organisms based on shared characteristics. Organisms are grouped into taxa (singular: taxon), and these groups are given a taxonomic rank; groups of a given rank can be aggregated to form a more inclusive group of higher rank, thus creating a taxonomic hierarchy. The principal ranks in modern use are domain, kingdom, phylum (division is sometimes used in botany in place of phylum), class, order, family, genus, and species. The Swedish botanist Carl Linnaeus is regarded as the founder of the current system of taxonomy, having developed a ranked system known as Linnaean taxonomy for categorizing organisms.\nWith advances in the theory, data and analytical technology of biological systematics, the Linnaean system has transformed into a system of modern biological classification intended to refl",
      "content": "In biology, taxonomy (from Ancient Greek  τάξις (taxis) 'arrangement' and  -νομία (-nomia) 'method') is the scientific study of naming, defining (circumscribing) and classifying groups of biological organisms based on shared characteristics. Organisms are grouped into taxa (singular: taxon), and these groups are given a taxonomic rank; groups of a given rank can be aggregated to form a more inclusive group of higher rank, thus creating a taxonomic hierarchy. The principal ranks in modern use are domain, kingdom, phylum (division is sometimes used in botany in place of phylum), class, order, family, genus, and species. The Swedish botanist Carl Linnaeus is regarded as the founder of the current system of taxonomy, having developed a ranked system known as Linnaean taxonomy for categorizing organisms.\nWith advances in the theory, data and analytical technology of biological systematics, the Linnaean system has transformed into a system of modern biological classification intended to reflect the evolutionary relationships among organisms, both living and extinct.\n\n\n== Definition ==\nThe exact definition of taxonomy varies from source to source, but the core of the discipline remains: the conception, naming, and classification of groups of organisms. As points of reference, recent definitions of taxonomy are presented below:\n\nTheory and practice of grouping individuals into species, arranging species into larger groups, and giving those groups names, thus producing a classification.\nA field of science (and a major component of systematics) that encompasses description, identification, nomenclature, and classification\nThe science of classification, in biology the arrangement of organisms into a classification\n\"The science of classification as applied to living organisms, including the study of means of formation of species, etc.\"\n\"The analysis of an organism's characteristics for the purpose of classification\"\n\"Systematics studies phylogeny to provide a pattern that can be translated into the classification and names of the more inclusive field of taxonomy\" (listed as a desirable but unusual definition)\nThe varied definitions either place taxonomy as a sub-area of systematics (definition 2), invert that relationship (definition 6), or appear to consider the two terms synonymous. There is some disagreement as to whether biological nomenclature is considered a part of taxonomy (definitions 1 and 2), or a part of systematics outside taxonomy. For example, definition 6 is paired with the following definition of systematics that places nomenclature outside taxonomy:\n\nSystematics: \"The study of the identification, taxonomy, and nomenclature of organisms, including the classification of living things with regard to their natural relationships and the study of variation and the evolution of taxa\".\nIn 1970, Michener et al. defined \"systematic biology\" and \"taxonomy\" in relation to one another as follows:\n\nSystematic biology (hereafter called simply systematics) is the field that\n\n(a) provides scientific names for organisms,\n(b) describes them,\n(c) preserves collections of them,\n(d) provides classifications for the organisms, keys for their identification, and data on their distributions,\n(e) investigates their evolutionary histories, and\n(f) considers their environmental adaptations.\nThis is a field with a long history that in recent years has experienced a notable renaissance, principally with respect to theoretical content. Part of the theoretical material has to do with evolutionary areas (topics e and f above), the rest relates especially to the problem of classification. Taxonomy is that part of Systematics concerned with topics (a) to (d) above.\n\nA whole set of terms including taxonomy, systematic biology, systematics, scientific classification, biological classification, and phylogenetics have at times had overlapping meanings – sometimes the same, sometimes slightly different, but always related and intersecting. The broadest meaning of \"taxonomy\" is used here. The term itself was introduced in 1813 by de Candolle, in his Théorie élémentaire de la botanique. John Lindley provided an early definition of systematics in 1830, although he wrote of \"systematic botany\" rather than using the term \"systematics\". Europeans tend to use the terms \"systematics\" and \"biosystematics\" for the study of biodiversity as a whole, whereas North Americans tend to use \"taxonomy\" more frequently. However, taxonomy, and in particular alpha taxonomy, is more specifically the identification, description, and naming (i.e., nomenclature) of organisms, while \"classification\" focuses on placing organisms within hierarchical groups that show their relationships to other organisms.\n\n\n=== Monograph and taxonomic revision ===\nA taxonomic revision or taxonomic review is a novel analysis of the variation patterns in a particular taxon. This analysis may be executed on the basis of any combination of the various available kinds of characters, such as",
      "url": "https://en.wikipedia.org/wiki/Taxonomy_(biology)",
      "topic": "Biology",
      "timestamp": "2025-11-14T00:21:13.789676",
      "type": "wikipedia_content"
    },
    {
      "title": "Molecular biology",
      "summary": "Molecular biology  is a branch of biology that seeks to understand the molecular basis of biological activity in and between cells, including biomolecular synthesis, modification, mechanisms, and interactions.\nThough cells and other microscopic structures had been observed in organisms as early as the 18th century, a detailed understanding of the mechanisms and interactions governing their behavior did not emerge until the 20th century, when technologies used in physics and chemistry had advanced sufficiently to permit their application in the biological sciences. The term 'molecular biology' was first used in 1945 by the English physicist William Astbury, who described it as an approach focused on discerning the underpinnings of biological phenomena—i.e. uncovering the physical and chemical structures and properties of biological molecules, as well as their interactions with other molecules and how these interactions explain observations of so-called classical biology, which instead s",
      "content": "Molecular biology  is a branch of biology that seeks to understand the molecular basis of biological activity in and between cells, including biomolecular synthesis, modification, mechanisms, and interactions.\nThough cells and other microscopic structures had been observed in organisms as early as the 18th century, a detailed understanding of the mechanisms and interactions governing their behavior did not emerge until the 20th century, when technologies used in physics and chemistry had advanced sufficiently to permit their application in the biological sciences. The term 'molecular biology' was first used in 1945 by the English physicist William Astbury, who described it as an approach focused on discerning the underpinnings of biological phenomena—i.e. uncovering the physical and chemical structures and properties of biological molecules, as well as their interactions with other molecules and how these interactions explain observations of so-called classical biology, which instead studies biological processes at larger scales and higher levels of organization. In 1953, Francis Crick, James Watson, Rosalind Franklin, and their colleagues at the Medical Research Council Unit, Cavendish Laboratory, were the first to describe the double helix model for the chemical structure of deoxyribonucleic acid (DNA), which is often considered a landmark event for the nascent field because it provided a physico-chemical basis by which to understand the previously nebulous idea of nucleic acids as the primary substance of biological inheritance. They proposed this structure based on previous research done by Franklin, which was conveyed to them by Maurice Wilkins and Max Perutz. Their work led to the discovery of DNA in other microorganisms, plants, and animals.\nThe field of molecular biology includes techniques which enable scientists to learn about molecular processes. These techniques are used to efficiently target new drugs, diagnose disease, and better understand cell physiology. Some clinical research and medical therapies arising from molecular biology are covered under gene therapy, whereas the use of molecular biology or molecular cell biology in medicine is now referred to as molecular medicine.\n\n\n== History of molecular biology ==\n\nMolecular biology sits at the intersection of biochemistry and genetics; as these scientific disciplines emerged and evolved in the 20th century, it became clear that they both sought to determine the molecular mechanisms which underlie vital cellular functions. Advances in molecular biology have been closely related to the development of new technologies and their optimization.\nThe field of genetics arose from attempts to understand the set of rules underlying reproduction and heredity, and the nature of the hypothetical units of heredity known as genes. Gregor Mendel pioneered this work in 1866, when he first described the laws of inheritance he observed in his studies of mating crosses in pea plants. One such law of genetic inheritance is the law of segregation, which states that diploid individuals with two alleles for a particular gene will pass one of these alleles to their offspring. Because of his critical work, the study of genetic inheritance is commonly referred to as Mendelian genetics.\nA major milestone in molecular biology was the discovery of the structure of DNA. This work began in 1869 by Friedrich Miescher, a Swiss biochemist who first proposed a structure called nuclein, which we now know to be (deoxyribonucleic acid), or DNA. He discovered this unique substance by studying the components of pus-filled bandages, and noting the unique properties of the \"phosphorus-containing substances\". Another notable contributor to the DNA model was Phoebus Levene, who proposed the \"polynucleotide model\" of DNA in 1919 as a result of his biochemical experiments on yeast. In 1950, Erwin Chargaff expanded on the work of Levene and elucidated a few critical properties of nucleic acids: first, the sequence of nucleic acids varies across species. Second, the total concentration of purines (adenine and guanine) is always equal to the total concentration of pyrimidines (cytosine and thymine). This is now known as Chargaff's rule. In 1953, James Watson and Francis Crick published the double helical structure of DNA, based on the X-ray crystallography work done by Rosalind Franklin which was conveyed to them by Maurice Wilkins and Max Perutz. Watson and Crick described the structure of DNA and conjectured about the implications of this unique structure for possible mechanisms of DNA replication. Watson and Crick were awarded the Nobel Prize in Physiology or Medicine in 1962, along with Wilkins, for proposing a model of the structure of DNA.\nIn 1961, it was demonstrated that when a gene encodes a protein, three sequential bases of a gene's DNA specify each successive amino acid of the protein. Thus the genetic code is a triplet code, where each triplet (called a codon) specifies a particu",
      "url": "https://en.wikipedia.org/wiki/Molecular_biology",
      "topic": "Biology",
      "timestamp": "2025-11-14T00:21:16.353953",
      "type": "wikipedia_content"
    },
    {
      "title": "Computer science",
      "summary": "Computer science is the study of computation, information, and automation. Included broadly in the sciences, computer science spans theoretical disciplines (such as algorithms, theory of computation, and information theory) to applied disciplines (including the design and implementation of hardware and software). An expert in the field is known as a computer scientist. \nAlgorithms and data structures are central to computer science.\nThe theory of computation concerns abstract models of computation and general classes of problems that can be solved using them. The fields of cryptography and computer security involve studying the means for secure communication and preventing security vulnerabilities. Computer graphics and computational geometry address the generation of images. Programming language theory considers different ways to describe computational processes, and database theory concerns the management of repositories of data. Human–computer interaction investigates the interfaces",
      "content": "Computer science is the study of computation, information, and automation. Included broadly in the sciences, computer science spans theoretical disciplines (such as algorithms, theory of computation, and information theory) to applied disciplines (including the design and implementation of hardware and software). An expert in the field is known as a computer scientist. \nAlgorithms and data structures are central to computer science.\nThe theory of computation concerns abstract models of computation and general classes of problems that can be solved using them. The fields of cryptography and computer security involve studying the means for secure communication and preventing security vulnerabilities. Computer graphics and computational geometry address the generation of images. Programming language theory considers different ways to describe computational processes, and database theory concerns the management of repositories of data. Human–computer interaction investigates the interfaces through which humans and computers interact, and software engineering focuses on the design and principles behind developing software. Areas such as operating systems, networks and embedded systems investigate the principles and design behind complex systems. Computer architecture describes the construction of computer components and computer-operated equipment. Artificial intelligence and machine learning aim to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, planning and learning found in humans and animals. Within artificial intelligence, computer vision aims to understand and process image and video data, while natural language processing aims to understand and process textual and linguistic data.\nThe fundamental concern of computer science is determining what can and cannot be automated. The Turing Award is generally recognized as the highest distinction in computer science.\n\n\n== History ==\n\nThe earliest foundations of what would become computer science predate the invention of the modern digital computer. Machines for calculating fixed numerical tasks such as the abacus have existed since antiquity, aiding in computations such as multiplication and division. Algorithms for performing computations have existed since antiquity, even before the development of sophisticated computing equipment.\nWilhelm Schickard designed and constructed the first working mechanical calculator in 1623. In 1673, Gottfried Leibniz demonstrated a digital mechanical calculator, called the Stepped Reckoner. Leibniz may be considered the first computer scientist and information theorist, because of various reasons, including the fact that he documented the binary number system. In 1820, Thomas de Colmar launched the mechanical calculator industry when he invented his simplified arithmometer, the first calculating machine strong enough and reliable enough to be used daily in an office environment. Charles Babbage started the design of the first automatic mechanical calculator, his Difference Engine, in 1822, which eventually gave him the idea of the first programmable mechanical calculator, his Analytical Engine. He started developing this machine in 1834, and \"in less than two years, he had sketched out many of the salient features of the modern computer\". \"A crucial step was the adoption of a punched card system derived from the Jacquard loom\" making it infinitely programmable. In 1843, during the translation of a French article on the Analytical Engine, Ada Lovelace wrote, in one of the many notes she included, an algorithm to compute the Bernoulli numbers, which is considered to be the first published algorithm ever specifically tailored for implementation on a computer. Around 1885, Herman Hollerith invented the tabulator, which used punched cards to process statistical information; eventually his company became part of IBM. Following Babbage, although unaware of his earlier work, Percy Ludgate in 1909 published the 2nd of the only two designs for mechanical analytical engines in history. In 1914, the Spanish engineer Leonardo Torres Quevedo published his Essays on Automatics, and designed, inspired by Babbage, a theoretical electromechanical calculating machine which was to be controlled by a read-only program. The paper also introduced the idea of floating-point arithmetic. In 1920, to celebrate the 100th anniversary of the invention of the arithmometer, Torres presented in Paris the Electromechanical Arithmometer, a prototype that demonstrated the feasibility of an electromechanical analytical engine, on which commands could be typed and the results printed automatically. In 1937, one hundred years after Babbage's impossible dream, Howard Aiken convinced IBM, which was making all kinds of punched card equipment and was also in the calculator business to develop his giant programmable calculator, the ASCC/Harvard Mark I, based on Babbage's Analytical Engine, which itself used cards and",
      "url": "https://en.wikipedia.org/wiki/Computer_science",
      "topic": "Computer Science",
      "timestamp": "2025-11-14T00:21:20.200321",
      "type": "wikipedia_content"
    },
    {
      "title": "Foobar",
      "summary": "The terms foobar, foo, bar, baz, quux, and others are used as metasyntactic variables  in computer programming or computer-related documentation. They have been used to name entities such as variables, functions, and commands whose exact identity is unimportant and serve only to demonstrate a concept.",
      "content": "The terms foobar, foo, bar, baz, quux, and others are used as metasyntactic variables  in computer programming or computer-related documentation. They have been used to name entities such as variables, functions, and commands whose exact identity is unimportant and serve only to demonstrate a concept.\n\n\n== History and etymology ==\nIt is possible that foobar is a playful allusion to the World War II-era military slang FUBAR (fucked up beyond all recognition).\nAccording to a RFC from the Internet Engineering Task Force, the word FOO originated as a nonsense word with its earliest documented use in the 1930s comic Smokey Stover by Bill Holman. Holman states that he used the word due to having seen it on the bottom of a jade Chinese figurine in San Francisco Chinatown, purportedly signifying \"good luck\". If true, this is presumably related to the Chinese word fu (\"福\", sometimes transliterated foo, as in foo dog), which can mean happiness or blessing.\nThe first known use of the terms in print in a programming context appears in a 1965 edition of MIT's Tech Engineering News. The use of foo in a programming context is generally credited to the Tech Model Railroad Club (TMRC) of MIT from c. 1960. In the complex model system, there were scram switches located at multiple places around the room that could be thrown if something undesirable was about to occur, such as a train moving at full power towards an obstruction. Another feature of the system was a digital clock on the dispatch board. When someone hit a scram switch, the clock stopped and the display was replaced with the word \"FOO\"; at TMRC the scram switches are, therefore, called \"Foo switches\". Because of this, an entry in the 1959 Dictionary of the TMRC Language went something like this: \"FOO: The first syllable of the misquoted sacred chant phrase 'foo mane padme hum.' Our first obligation is to keep the foo counters turning.\" One book describing the MIT train room describes two buttons by the door labeled \"foo\" and \"bar\". These were general-purpose buttons and were often repurposed for whatever fun idea the MIT hackers had at the time, hence the adoption of foo and bar as general-purpose variable names. An entry in the Abridged Dictionary of the TMRC Language states:\n\nMultiflush: stop-all-trains-button. Next \nthing to the red door button. Also called FOO. Displays \"FOO\" on the clock when used.\nFoobar was used as a variable name in the Fortran code of Colossal Cave Adventure (1977 Crowther and Woods version). The variable FOOBAR was used to contain the player's progress in saying the magic phrase \"Fee Fie Foe Foo\", a phrase from an historical quatrain in the classic English fairy tale Jack and the Beanstalk. Intel also used the term foo in their programming documentation in 1978.\n\n\n== Examples in culture ==\nFoo Camp is an annual hacker convention.\nBarCamp, an international network of user-generated conferences.\nDuring the United States v. Microsoft Corp. trial, evidence was presented that Microsoft had tried to use the Web Services Interoperability organization (WS-I) as a means to stifle competition, including e-mails in which top executives including Bill Gates and Steve Ballmer referred to the WS-I using the codename \"foo\".\nfoobar2000 is an audio player.\n\n\n== See also ==\n\nAlice and Bob\nFoo fighter\nFoo was here\nFu (character)\nLorem ipsum, similar placeholder text used outside programming\nxyzzy\nCategory:Variable (computer science)\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\n\nGoogle developer documentation style guide word list\nThe Jargon File entry on \"foobar\", catb.org\nRFC 1639 – FTP Operation Over Big Address Records (FOOBAR)",
      "url": "https://en.wikipedia.org/wiki/Foobar",
      "topic": "Computer Science",
      "timestamp": "2025-11-14T00:21:22.514974",
      "type": "wikipedia_content"
    },
    {
      "title": "Assignment (computer science)",
      "summary": "In computer programming, an assignment statement sets and/or re-sets the value stored in the storage location(s) denoted by a variable name; in other words, it copies a value into the variable. In most imperative programming languages, the assignment statement (or  expression) is a fundamental construct.\nToday, the most commonly used notation for this operation is x = expr (originally Superplan 1949–51, popularized by Fortran 1957 and C). The second most commonly used notation is x := expr (originally ALGOL 1958, popularised by Pascal). Many other notations are also in use. In some languages, the symbol used is regarded as an operator (meaning that the assignment statement as a whole returns a value). Other languages define assignment as a statement (meaning that it cannot be used in an expression).\nAssignments typically allow a variable to hold different values at different times during its life-span and scope. However, some languages (primarily strictly functional languages) do not a",
      "content": "In computer programming, an assignment statement sets and/or re-sets the value stored in the storage location(s) denoted by a variable name; in other words, it copies a value into the variable. In most imperative programming languages, the assignment statement (or  expression) is a fundamental construct.\nToday, the most commonly used notation for this operation is x = expr (originally Superplan 1949–51, popularized by Fortran 1957 and C). The second most commonly used notation is x := expr (originally ALGOL 1958, popularised by Pascal). Many other notations are also in use. In some languages, the symbol used is regarded as an operator (meaning that the assignment statement as a whole returns a value). Other languages define assignment as a statement (meaning that it cannot be used in an expression).\nAssignments typically allow a variable to hold different values at different times during its life-span and scope. However, some languages (primarily strictly functional languages) do not allow that kind of \"destructive\" reassignment, as it might imply changes of non-local state. The purpose is to enforce referential transparency, i.e. functions that do not depend on the state of some variable(s), but produce the same results for a given set of parametric inputs at any point in time. Modern programs in other languages also often use similar strategies, although less strict, and only in certain parts, in order to reduce complexity, normally in conjunction with complementing methodologies such as data structuring, structured programming and object orientation.\n\n\n== Semantics ==\nAn assignment operation is a process in imperative programming in which different values are associated with a particular variable name as time passes. The program, in such model, operates by changing its state using successive assignment statements. Primitives of imperative programming languages rely on assignment to do iteration. At the lowest level, assignment is implemented using machine operations such as MOVE or STORE.\nVariables are containers for values. It is possible to put a value into a variable and later replace it with a new one. An assignment operation modifies the current state of the executing program. Consequently, assignment is dependent on the concept of variables. In an assignment:\n\nThe expression is evaluated in the current state of the program.\nThe variable is assigned the computed value, replacing the prior value of that variable.\nExample: Assuming that a is a numeric variable, the assignment a := 2*a means that the content of the variable a is doubled after the execution of the statement.\nAn example segment of C code:\n\nIn this sample, the variable x is first declared as an int, and is then assigned the value of 10. Notice that the declaration and assignment occur in the same statement. In the second line, y is declared without an assignment. In the third line, x is reassigned the value of 23. Finally, y is assigned the value of 32.4.\nFor an assignment operation, it is necessary that the value of the expression is well-defined (it is a valid rvalue) and that the variable represents a modifiable entity (it is a valid modifiable (non-const) lvalue). In some languages, typically dynamic ones, it is not necessary to declare a variable prior to assigning it a value. In such languages, a variable is automatically declared the first time it is assigned to, with the scope it is declared in varying by language.\n\n\n== Single assignment ==\n\nAny assignment that changes an existing value (e.g. x := x + 1) is disallowed in purely functional languages. In functional programming, assignment is discouraged in favor of single assignment, more commonly known as initialization. Single assignment is an example of name binding and differs from assignment as described in this article in that it can only be done once, usually when the variable is created; no subsequent reassignment is allowed.\nAn evaluation of an expression does not have a side effect if it does not change an observable state of the machine, other than producing the result, and always produces same value for the same input. Imperative assignment can introduce side effects while destroying and making the old value unavailable while substituting it with a new one, and is referred to as destructive assignment for that reason in LISP and functional programming, similar to destructive updating.\nSingle assignment is the only form of assignment available in purely functional languages, such as Haskell, which do not have variables in the sense of imperative programming languages but rather named constant values possibly of compound nature, with their elements progressively defined on-demand, for the lazy languages. Purely functional languages can provide an opportunity for computation to be performed in parallel, avoiding the von Neumann bottleneck of sequential one step at a time execution, since values are independent of each other.\nImpure functional languages provide both single a",
      "url": "https://en.wikipedia.org/wiki/Assignment_(computer_science)",
      "topic": "Computer Science",
      "timestamp": "2025-11-14T00:21:25.091586",
      "type": "wikipedia_content"
    },
    {
      "title": "Economy of India",
      "summary": "The economy of India is a developing mixed economy with a notable public sector in strategic sectors. It is the world's fourth-largest economy by nominal GDP and the third-largest by purchasing power parity (PPP); on a per capita income basis, India ranked 136th by GDP (nominal) and 119th by GDP (PPP). From independence in 1947 until 1991, successive governments followed the Soviet model and promoted protectionist economic policies, with extensive Sovietization, state intervention, demand-side economics, natural resources, bureaucrat-driven enterprises and economic regulation. This was a form of the Licence Raj. The end of the Cold War and an acute balance of payments crisis in 1991 led to the adoption of a broad economic liberalisation in India and indicative planning. India has about 1,900 public sector companies, with the Indian state having complete control and ownership of railways and highways. The Indian government has major control over banking, insurance, farming, fertilizers ",
      "content": "The economy of India is a developing mixed economy with a notable public sector in strategic sectors. It is the world's fourth-largest economy by nominal GDP and the third-largest by purchasing power parity (PPP); on a per capita income basis, India ranked 136th by GDP (nominal) and 119th by GDP (PPP). From independence in 1947 until 1991, successive governments followed the Soviet model and promoted protectionist economic policies, with extensive Sovietization, state intervention, demand-side economics, natural resources, bureaucrat-driven enterprises and economic regulation. This was a form of the Licence Raj. The end of the Cold War and an acute balance of payments crisis in 1991 led to the adoption of a broad economic liberalisation in India and indicative planning. India has about 1,900 public sector companies, with the Indian state having complete control and ownership of railways and highways. The Indian government has major control over banking, insurance, farming, fertilizers and chemicals, airports, essential utilities. The state also exerts substantial control over digitalization, telecommunication, supercomputing, space, port and shipping industries, which were effectively nationalised in the mid-1950s but has seen the emergence of key corporate players.\nNearly 70% of India's GDP is driven by domestic consumption; the country remains the world's third-largest consumer market. Aside private consumption, India's GDP is also fueled by government spending, investments, and exports. In 2022, India was the world's 10th-largest importer and the 8th-largest exporter. India has been a member of the World Trade Organization since 1 January 1995. It ranks 63rd on the ease of doing business index and 40th on the Global Competitiveness Index. India has one of the world's highest number of billionaires along with extreme income inequality.  Economists and social scientists often consider India a welfare state. India's overall social welfare spending stood at 8.6% of GDP in 2021-22, which is much lower than the average for OECD nations. With 586 million workers, the Indian labour force is the world's second-largest. Despite having some of the longest working hours, India has one of the lowest workforce productivity levels in the world. Economists say that due to structural economic problems, India is experiencing jobless economic growth.\nDuring the Great Recession, the economy faced a mild slowdown. India endorsed Keynesian policy and initiated stimulus measures (both fiscal and monetary) to boost growth and generate demand. In subsequent years, economic growth revived.\nIn 2021–22, the foreign direct investment (FDI) in India was $82 billion. The leading sectors for FDI inflows were the Finance, Banking, Insurance and R&D. India has free trade agreements with several nations and blocs, including ASEAN, SAFTA, Mercosur, South Korea, Japan, Australia, the United Arab Emirates, and several others which are in effect or under negotiating stage.\nThe service sector makes up more than 50% of GDP and remains the fastest growing sector, while the industrial sector and the agricultural sector employs a majority of the labor force. The Bombay Stock Exchange and National Stock Exchange are some of the world's largest stock exchanges by market capitalisation. India is the world's sixth-largest manufacturer, representing 2.6% of global manufacturing output. Nearly 65% of India's population is rural, and contributes about 50% of India's GDP. India faces high unemployment, rising income inequality, and a drop in aggregate demand. India's gross domestic savings rate stood at 29.3% of GDP in 2022.\n\n\n== History ==\n\nFor a continuous duration of nearly 1700 years from the year 1 CE, India was the world's largest economy, constituting 35 to 40% of the world GDP. The combination of protectionist, import-substitution, Fabian socialism, and social democratic-inspired policies governed India for sometime after the end of British rule. The economy was then characterised as Dirigism, It had extensive regulation, protectionism, public ownership of large monopolies, pervasive corruption and slow growth. Since 1991, continuing economic liberalisation has moved the country towards a market-based economy. By 2008, India had established itself as one of the world's faster-growing economies.\n\n\n=== Ancient and medieval eras ===\n\n\n==== Indus Valley Civilisation ====\nThe citizens of the Indus Valley civilisation, a permanent settlement that flourished between 2800 BCE and 1800 BCE, practised agriculture, domesticated animals, used uniform weights and measures, made tools and weapons, and traded with other cities. Evidence of well-planned streets, a drainage system, and water supply reveals their knowledge of urban planning, which included the first-known urban sanitation systems and the existence of a form of municipal government.\n\n\n==== West Coast ====\nMaritime trade was carried out extensively between southern regions of India and Southeast Asia",
      "url": "https://en.wikipedia.org/wiki/Economy_of_India",
      "topic": "India",
      "timestamp": "2025-11-14T00:21:34.587582",
      "type": "wikipedia_content"
    },
    {
      "title": "News of the World",
      "summary": "The News of the World was a weekly national \"red top\" tabloid newspaper published every Sunday in the United Kingdom from 1843 to 2011. It was at one time the world's highest-selling English-language newspaper, and at closure still had one of the highest English-language circulations. It was originally established as a broadsheet by John Browne Bell, who identified crime, sensation and vice as the themes that would sell most copies. The Bells sold to Henry Lascelles Carr in 1891; in 1969, it was bought from the Carrs by Rupert Murdoch's media firm News Limited. In 1984, as News Limited reorganised into News International, a subsidiary of News Corporation, the newspaper transformed into a tabloid  and became the Sunday sister paper of The Sun.\nThe News of the World concentrated in particular on celebrity scoops, gossip and populist news. Its somewhat prurient focus on sex scandals gained it the nickname Screws of the World. In its last decade it had a reputation for exposing celebrities",
      "content": "The News of the World was a weekly national \"red top\" tabloid newspaper published every Sunday in the United Kingdom from 1843 to 2011. It was at one time the world's highest-selling English-language newspaper, and at closure still had one of the highest English-language circulations. It was originally established as a broadsheet by John Browne Bell, who identified crime, sensation and vice as the themes that would sell most copies. The Bells sold to Henry Lascelles Carr in 1891; in 1969, it was bought from the Carrs by Rupert Murdoch's media firm News Limited. In 1984, as News Limited reorganised into News International, a subsidiary of News Corporation, the newspaper transformed into a tabloid  and became the Sunday sister paper of The Sun.\nThe News of the World concentrated in particular on celebrity scoops, gossip and populist news. Its somewhat prurient focus on sex scandals gained it the nickname Screws of the World. In its last decade it had a reputation for exposing celebrities' drug use, sexual peccadilloes, or criminal acts, by using insiders and journalists in disguise to provide video or photographic evidence, and covert phone hacking in ongoing police investigations. Sales averaged 2,812,005 copies per week in October 2010.\nFrom 2006, allegations of phone hacking began to engulf the newspaper. These culminated in the revelation on 4 July 2011 that, nearly a decade earlier, a private investigator hired by the newspaper had intercepted the voicemail of missing British teenager Milly Dowler, who was later found murdered.\nAmid a public backlash and the withdrawal of advertising, News International announced the closure of the newspaper on 7 July 2011. The scandal deepened when the paper was alleged to have hacked into the phones of families of British service personnel killed in action. Senior figures on the newspaper have been held for questioning by police investigating the phone hacking and corruption allegations, alongside former Daily Mirror editor Piers Morgan. Arrested on 8 July 2011 were former editor Andy Coulson and former News of the World royal editor Clive Goodman, the latter jailed for phone hacking in 2007. The former executive editor Neil Wallis was arrested on 15 July 2011 and former editor Rebekah Brooks, the tenth person held in custody, on 17 July 2011.\nDuring a visit to London on 17 February 2012, Murdoch announced he was soon to launch a Sunday edition of The Sun, which acted as a replacement to the News of the World. On 19 February 2012, it was announced that the first edition of The Sun on Sunday would be printed on 26 February 2012. It would employ some former News of the World journalists.\n\n\n== History ==\n\n\n=== 1843 to 1968 ===\nThe newspaper was first published as The News of the World on 1 October 1843, by John Browne Bell in London. Priced at three pence (equal to £1.55 in 2023), even before the repeal of the Stamp act (1855) or paper duty (1861), it was the cheapest newspaper of its time and was aimed directly at the newly literate working classes. It quickly established itself as a purveyor of titillation, shock, and criminal news. Much of the source material came from coverage of vice prosecutions, including lurid transcripts of police descriptions of alleged brothels, streetwalkers, and \"immoral\" women. In 1924 the newspaper sponsored the 1924 Women's Olympiad held at Stamford Bridge in London.\nBefore long, the News of the World established itself as the most widely read Sunday paper, with initial sales of around 12,000 copies a week. Circulation had grown to 24,100 by 1845 and was 109,100 in 1854. Sales then suffered because the price was not cut following the abolition of newspaper taxes and the paper was soon no longer among the leading Sunday titles, selling around 30,000 by 1880, a greater number but a smaller proportion, as newspaper sales had grown hugely. The title was sold by the Bell family in 1891 to Henry Lascelles Carr who owned the Welsh Western Mail. As editor, he installed his nephew Emsley Carr, who held the post for 50 years. The real engine of the paper's now quick commercial success, however, was George Riddell, who reorganised its national distribution using local agents. Matthew Engel, in his book Tickle the Public: One Hundred Years of the Popular Press (Gollancz, 1996), says that the News of the World of the 1890s was \"a very fine paper indeed\". The paper was not without its detractors, though. As one writer later related:\n\nFrederick Greenwood, editor of  The Pall Mall Gazette, met in his club one day Lord Riddell, who died a few years ago, and in the course of conversation Riddell said to him, \"You know, I own a paper.\"\n\"Oh, do you?\" said Greenwood, \"what is it?\"\n\"It's called the News of the World—I'll send you a copy\", replied Riddell, and in due course did so. Next time they met Riddell said, \"Well Greenwood, what do you think of my paper?\"\n\"I looked at it\", replied Greenwood, \"and then I put it in the waste-paper basket. And then I thought",
      "url": "https://en.wikipedia.org/wiki/News_of_the_World",
      "topic": "World News",
      "timestamp": "2025-11-14T00:21:38.709983",
      "type": "wikipedia_content"
    },
    {
      "title": "Yeshiva World News",
      "summary": "Yeshiva World News (YWN) is an Orthodox Jewish online news publication.",
      "content": "Yeshiva World News (YWN) is an Orthodox Jewish online news publication.\n\n\n== History ==\nYeshiva World News started in 2003 as a news aggregation blog by its founder Judah (Yehudah) Eckstein. It has since grown to an independent news source with freelance reporters and photographers, in addition to continuing as a news aggregator.\nThe website was redesigned in 2010, and again in 2017. It has sections containing general news items and Israeli news, as well as religious news, and news tailored around Jewish life cycle events and the Jewish calendar. Features relevant to Jewish observance, include articles about Torah and Jewish law (halakha), kosher recipes, and a streaming radio feature.\n\n\n== References ==",
      "url": "https://en.wikipedia.org/wiki/Yeshiva_World_News",
      "topic": "World News",
      "timestamp": "2025-11-14T00:21:42.797325",
      "type": "wikipedia_content"
    },
    {
      "title": "Sincé",
      "summary": "Sincé, also known as San Luis de Sincé, is a town and municipality located in the Department of Sucre,  28 km (15 mi) southeast of Sincelejo, in northern Colombia. It has an average Temperature of 26,5°C (80°F).  Its main economic activities are agriculture, stockbreeding and commerce. It was founded November 10, 1775 by Antonio de Torre y Miranda.  Sincé is home to \"Hospital Local Nuestra Señora del Socorro\" and a Municipal Photo Gallery.",
      "content": "Sincé, also known as San Luis de Sincé, is a town and municipality located in the Department of Sucre,  28 km (15 mi) southeast of Sincelejo, in northern Colombia. It has an average Temperature of 26,5°C (80°F).  Its main economic activities are agriculture, stockbreeding and commerce. It was founded November 10, 1775 by Antonio de Torre y Miranda.  Sincé is home to \"Hospital Local Nuestra Señora del Socorro\" and a Municipal Photo Gallery.\n\n\n== Celebrations and Events ==\nThe biggest local celebrations are held in honor of the Virgen del Socorro, the city's patron Saint, and celebrated in September.  Other major celebrations include the Fiestas en Corralejas (Running of the Bulls) in January and La Semana de la Sinceanidad (Sincé Week), commemorating its founding in November.\n\n\n== Notable people ==\nMusician and composer Adolfo Mejía Navarro was born in Sincé.\n\n\n== Gallery ==\n\n\n== References ==\n\n\n== External links ==\n(in Spanish) Gobernacion de Sucre - Sincé\n(in Spanish) Sincé official website",
      "url": "https://en.wikipedia.org/wiki/Sinc%C3%A9",
      "topic": "Space",
      "timestamp": "2025-11-14T00:21:47.540890",
      "type": "wikipedia_content"
    },
    {
      "title": "Gas",
      "summary": "Gas is a state of matter with neither fixed volume nor fixed shape. It is a compressible form of fluid. A pure gas consists of individual atoms (e.g. a noble gas like neon), or molecules (e.g. oxygen (O2) or carbon dioxide). Pure gases can also be mixed together such as in the air. What distinguishes gases from liquids and solids is the vast separation of the individual gas particles. This separation can make some gases invisible to the human observer.\nThe gaseous state of matter occurs between the liquid and plasma states, the latter of which provides the upper-temperature boundary for gases. Bounding the lower end of the temperature scale lie degenerative quantum gases which are gaining increasing attention.\nHigh-density atomic gases super-cooled to very low temperatures are classified by their statistical behavior as either Bose gases or Fermi gases. For a comprehensive listing of these exotic states of matter, see list of states of matter.",
      "content": "Gas is a state of matter with neither fixed volume nor fixed shape. It is a compressible form of fluid. A pure gas consists of individual atoms (e.g. a noble gas like neon), or molecules (e.g. oxygen (O2) or carbon dioxide). Pure gases can also be mixed together such as in the air. What distinguishes gases from liquids and solids is the vast separation of the individual gas particles. This separation can make some gases invisible to the human observer.\nThe gaseous state of matter occurs between the liquid and plasma states, the latter of which provides the upper-temperature boundary for gases. Bounding the lower end of the temperature scale lie degenerative quantum gases which are gaining increasing attention.\nHigh-density atomic gases super-cooled to very low temperatures are classified by their statistical behavior as either Bose gases or Fermi gases. For a comprehensive listing of these exotic states of matter, see list of states of matter.\n\n\n== Elemental gases ==\nThe only chemical elements that are stable diatomic homonuclear molecular gases at STP are hydrogen (H2), nitrogen (N2), oxygen (O2), and two halogens: fluorine (F2) and chlorine (Cl2). When grouped with the monatomic noble gases – helium (He), neon (Ne), argon (Ar), krypton (Kr), xenon (Xe), and radon (Rn) – these gases are referred to as \"elemental gases\".\n\n\n== Etymology ==\nThe word gas was first used by the early 17th-century Flemish chemist Jan Baptist van Helmont. He identified carbon dioxide, the first known gas other than air. Van Helmont's word appears to have been simply a phonetic transcription of the Ancient Greek word χάος 'chaos' – the g in Dutch being pronounced like ch in \"loch\" (voiceless velar fricative, ) – in which case Van Helmont simply was following the established alchemical usage first attested in the works of Paracelsus. According to Paracelsus's terminology, chaos meant something like 'ultra-rarefied water'.\nAn alternative story is that Van Helmont's term was derived from \"gahst (or geist), which signifies a ghost or spirit\". That story is given no credence by the editors of the Oxford English Dictionary. In contrast, the French-American historian Jacques Barzun speculated that Van Helmont had borrowed the word from the German Gäscht, meaning the froth resulting from fermentation.\n\n\n== Physical characteristics ==\nBecause most gases are difficult to observe directly, they are described through the use of four physical properties or macroscopic characteristics: pressure, volume, number of particles (chemists group them by moles) and temperature. These four characteristics were repeatedly observed by scientists such as Robert Boyle, Jacques Charles, John Dalton, Joseph Gay-Lussac and Amedeo Avogadro for a variety of gases in various settings. Their detailed studies ultimately led to a mathematical relationship among these properties expressed by the ideal gas law (see § Ideal and perfect gas section below).\nGas particles are widely separated from one another, and consequently, have weaker intermolecular bonds than liquids or solids. These intermolecular forces result from electrostatic interactions between gas particles. Like-charged areas of different gas particles repel, while oppositely charged regions of different gas particles attract one another; gases that contain permanently charged ions are known as plasmas. Gaseous compounds with polar covalent bonds contain permanent charge imbalances and so experience relatively strong intermolecular forces, although the compound's net charge remains neutral. Transient, randomly induced charges exist across non-polar covalent bonds of molecules and electrostatic interactions caused by them are referred to as Van der Waals forces. The interaction of these intermolecular forces varies within a substance which determines many of the physical properties unique to each gas. A comparison of boiling points for compounds formed by ionic and covalent bonds leads us to this conclusion.\nCompared to the other states of matter, gases have low density and viscosity. Pressure and temperature influence the particles within a certain volume. This variation in particle separation and speed is referred to as compressibility. This particle separation and size influences optical properties of gases as can be found in the following list of refractive indices. Finally, gas particles spread apart or diffuse in order to homogeneously distribute themselves throughout any container.\n\n\n== Macroscopic view of gases ==\n\nWhen observing gas, it is typical to specify a frame of reference or length scale. A larger length scale corresponds to a macroscopic or global point of view of the gas. This region (referred to as a volume) must be sufficient in size to contain a large sampling of gas particles. The resulting statistical analysis of this sample size produces the \"average\" behavior (i.e. velocity, temperature or pressure) of all the gas particles within the region. In contrast, a smaller length scale corres",
      "url": "https://en.wikipedia.org/wiki/Gas",
      "topic": "Space",
      "timestamp": "2025-11-14T00:21:54.394351",
      "type": "wikipedia_content"
    },
    {
      "title": "Natural environment",
      "summary": "The natural environment or natural world encompasses all biotic and abiotic things occurring naturally, meaning in this case not artificial. The term is most often applied to Earth or some parts of Earth. This environment encompasses the interaction of all living species, climate, weather and natural resources that affect human survival and economic activity.\nThe concept of the natural environment can be distinguished as components:\n\nComplete ecological units that function as natural systems without massive civilized human intervention, including all vegetation, microorganisms, soil, rocks, plateaus, mountains, the atmosphere and natural phenomena that occur within their boundaries and their nature.\nUniversal natural resources and physical phenomena that lack clear-cut boundaries, such as air, water and climate, as well as energy, radiation, electric charge and magnetism, not originating from civilized human actions.\nIn contrast to the natural environment is the built environment. Buil",
      "content": "The natural environment or natural world encompasses all biotic and abiotic things occurring naturally, meaning in this case not artificial. The term is most often applied to Earth or some parts of Earth. This environment encompasses the interaction of all living species, climate, weather and natural resources that affect human survival and economic activity.\nThe concept of the natural environment can be distinguished as components:\n\nComplete ecological units that function as natural systems without massive civilized human intervention, including all vegetation, microorganisms, soil, rocks, plateaus, mountains, the atmosphere and natural phenomena that occur within their boundaries and their nature.\nUniversal natural resources and physical phenomena that lack clear-cut boundaries, such as air, water and climate, as well as energy, radiation, electric charge and magnetism, not originating from civilized human actions.\nIn contrast to the natural environment is the built environment. Built environments are where humans have fundamentally transformed landscapes such as urban settings and agricultural land conversion, the natural environment is greatly changed into a simplified human environment. Even acts which seem less extreme, such as building a mud hut or a photovoltaic system in the desert, the modified environment becomes an artificial one. Though many animals build things to provide a better environment for themselves, they are not human, hence beaver dams and the works of mound-building termites are thought of as natural.\nThere are no absolutely natural environments on Earth. Naturalness usually varies in a continuum, from 100% natural in one extreme to 0% natural in the other. The massive environmental changes of humanity in the Anthropocene have fundamentally affected all natural environments including: climate change, biodiversity loss and pollution from plastic and other chemicals in the air and water. More precisely, we can consider the different aspects or components of an environment, and see that their degree of naturalness is not uniform. If, for instance, we take an agricultural field, and consider the mineralogic composition and the structure of its soil, we will find that whereas the first is quite similar to that of an undisturbed forest soil, the structure is quite different.\n\n\n== Composition ==\n\nEarth science generally recognizes four spheres, the lithosphere, the hydrosphere, the atmosphere and the biosphere as correspondent to rocks, water, air and life respectively. Some scientists include as part of the spheres of the Earth, the cryosphere (corresponding to ice) as a distinct portion of the hydrosphere, as well as the pedosphere (to soil) as an active and intermixed sphere. Earth science (also known as geoscience, the geographical sciences or the Earth Sciences), is an all-embracing term for the sciences related to the planet Earth. There are four major disciplines in earth sciences, namely geography, geology, geophysics and geodesy. These major disciplines use physics, chemistry, biology, chronology and mathematics to build a qualitative and quantitative understanding of the principal areas or spheres of Earth.\n\n\n== Geological activity ==\n\nThe Earth's crust or lithosphere, is the outermost solid surface of the planet and is chemically, physically and mechanically different from underlying mantle. It has been generated greatly by igneous processes in which magma cools and solidifies to form solid rock. Beneath the lithosphere lies the mantle which is heated by the decay of radioactive elements. The mantle though solid is in a state of rheic convection. This convection process causes the lithospheric plates to move, albeit slowly. The resulting process is known as plate tectonics. Volcanoes result primarily from the melting of subducted crust material or of rising mantle at mid-ocean ridges and mantle plumes.\n\n\n== Water on Earth ==\n\nMost water is found in various kinds of natural body of water.\n\n\n=== Oceans ===\n\nAn ocean is a major body of saline water and a component of the hydrosphere. Approximately 71% of the surface of the Earth (an area of some 362 million square kilometers) is covered by ocean, a continuous body of water that is customarily divided into several principal oceans and smaller seas. More than half of this area is over 3,000 meters (9,800 ft) deep. Average oceanic salinity is around 35 parts per thousand (ppt) (3.5%), and nearly all seawater has a salinity in the range of 30 to 38 ppt. Though generally recognized as several separate oceans, these waters comprise one global, interconnected body of salt water often referred to as the World Ocean or global ocean. The deep seabeds are more than half the Earth's surface, and are among the least-modified natural environments. The major oceanic divisions are defined in part by the continents, various archipelagos and other criteria, these divisions are, in descending order of size, the Pacific Ocean, the Atlantic Ocean, the ",
      "url": "https://en.wikipedia.org/wiki/Natural_environment",
      "topic": "Environment",
      "timestamp": "2025-11-14T00:22:00.405247",
      "type": "wikipedia_content"
    },
    {
      "title": "Natural environment",
      "summary": "The natural environment or natural world encompasses all biotic and abiotic things occurring naturally, meaning in this case not artificial. The term is most often applied to Earth or some parts of Earth. This environment encompasses the interaction of all living species, climate, weather and natural resources that affect human survival and economic activity.\nThe concept of the natural environment can be distinguished as components:\n\nComplete ecological units that function as natural systems without massive civilized human intervention, including all vegetation, microorganisms, soil, rocks, plateaus, mountains, the atmosphere and natural phenomena that occur within their boundaries and their nature.\nUniversal natural resources and physical phenomena that lack clear-cut boundaries, such as air, water and climate, as well as energy, radiation, electric charge and magnetism, not originating from civilized human actions.\nIn contrast to the natural environment is the built environment. Buil",
      "content": "The natural environment or natural world encompasses all biotic and abiotic things occurring naturally, meaning in this case not artificial. The term is most often applied to Earth or some parts of Earth. This environment encompasses the interaction of all living species, climate, weather and natural resources that affect human survival and economic activity.\nThe concept of the natural environment can be distinguished as components:\n\nComplete ecological units that function as natural systems without massive civilized human intervention, including all vegetation, microorganisms, soil, rocks, plateaus, mountains, the atmosphere and natural phenomena that occur within their boundaries and their nature.\nUniversal natural resources and physical phenomena that lack clear-cut boundaries, such as air, water and climate, as well as energy, radiation, electric charge and magnetism, not originating from civilized human actions.\nIn contrast to the natural environment is the built environment. Built environments are where humans have fundamentally transformed landscapes such as urban settings and agricultural land conversion, the natural environment is greatly changed into a simplified human environment. Even acts which seem less extreme, such as building a mud hut or a photovoltaic system in the desert, the modified environment becomes an artificial one. Though many animals build things to provide a better environment for themselves, they are not human, hence beaver dams and the works of mound-building termites are thought of as natural.\nThere are no absolutely natural environments on Earth. Naturalness usually varies in a continuum, from 100% natural in one extreme to 0% natural in the other. The massive environmental changes of humanity in the Anthropocene have fundamentally affected all natural environments including: climate change, biodiversity loss and pollution from plastic and other chemicals in the air and water. More precisely, we can consider the different aspects or components of an environment, and see that their degree of naturalness is not uniform. If, for instance, we take an agricultural field, and consider the mineralogic composition and the structure of its soil, we will find that whereas the first is quite similar to that of an undisturbed forest soil, the structure is quite different.\n\n\n== Composition ==\n\nEarth science generally recognizes four spheres, the lithosphere, the hydrosphere, the atmosphere and the biosphere as correspondent to rocks, water, air and life respectively. Some scientists include as part of the spheres of the Earth, the cryosphere (corresponding to ice) as a distinct portion of the hydrosphere, as well as the pedosphere (to soil) as an active and intermixed sphere. Earth science (also known as geoscience, the geographical sciences or the Earth Sciences), is an all-embracing term for the sciences related to the planet Earth. There are four major disciplines in earth sciences, namely geography, geology, geophysics and geodesy. These major disciplines use physics, chemistry, biology, chronology and mathematics to build a qualitative and quantitative understanding of the principal areas or spheres of Earth.\n\n\n== Geological activity ==\n\nThe Earth's crust or lithosphere, is the outermost solid surface of the planet and is chemically, physically and mechanically different from underlying mantle. It has been generated greatly by igneous processes in which magma cools and solidifies to form solid rock. Beneath the lithosphere lies the mantle which is heated by the decay of radioactive elements. The mantle though solid is in a state of rheic convection. This convection process causes the lithospheric plates to move, albeit slowly. The resulting process is known as plate tectonics. Volcanoes result primarily from the melting of subducted crust material or of rising mantle at mid-ocean ridges and mantle plumes.\n\n\n== Water on Earth ==\n\nMost water is found in various kinds of natural body of water.\n\n\n=== Oceans ===\n\nAn ocean is a major body of saline water and a component of the hydrosphere. Approximately 71% of the surface of the Earth (an area of some 362 million square kilometers) is covered by ocean, a continuous body of water that is customarily divided into several principal oceans and smaller seas. More than half of this area is over 3,000 meters (9,800 ft) deep. Average oceanic salinity is around 35 parts per thousand (ppt) (3.5%), and nearly all seawater has a salinity in the range of 30 to 38 ppt. Though generally recognized as several separate oceans, these waters comprise one global, interconnected body of salt water often referred to as the World Ocean or global ocean. The deep seabeds are more than half the Earth's surface, and are among the least-modified natural environments. The major oceanic divisions are defined in part by the continents, various archipelagos and other criteria, these divisions are, in descending order of size, the Pacific Ocean, the Atlantic Ocean, the ",
      "url": "https://en.wikipedia.org/wiki/Natural_environment",
      "topic": "Environment",
      "timestamp": "2025-11-14T00:22:02.269269",
      "type": "wikipedia_content"
    },
    {
      "title": "Destructible environment",
      "summary": "In video games, destructible environments or deformable terrains are environments that can be destroyed by the player. It may refer to any part of the environment, including terrain, buildings and other man-made structures. A game may feature destructible environments to demonstrate its graphical prowess, underscore the potency of the player character's given abilities, and/or require the player to leverage them to solve problems or discover new paths and/or secrets.\nEarly examples include the Taito shooter games Gun Fight (1975) and Space Invaders (1978), where the players could take cover behind destructible objects. An early example of a fully destructible environment can be found in Namco's 1982 game Dig Dug, in which the whole of each level is destructible, though enemies can usually only follow the player through a combination of pre-made tracks and paths made by the player. A similar game released that same year was Mr. Do! by Universal. In most games that feature destructible t",
      "content": "In video games, destructible environments or deformable terrains are environments that can be destroyed by the player. It may refer to any part of the environment, including terrain, buildings and other man-made structures. A game may feature destructible environments to demonstrate its graphical prowess, underscore the potency of the player character's given abilities, and/or require the player to leverage them to solve problems or discover new paths and/or secrets.\nEarly examples include the Taito shooter games Gun Fight (1975) and Space Invaders (1978), where the players could take cover behind destructible objects. An early example of a fully destructible environment can be found in Namco's 1982 game Dig Dug, in which the whole of each level is destructible, though enemies can usually only follow the player through a combination of pre-made tracks and paths made by the player. A similar game released that same year was Mr. Do! by Universal. In most games that feature destructible terrain, it is more common for only part of the environment to be destructible to prevent players from cutting their way directly to the goal.\n\nAn early example of a shooter game that featured fully destructible environments was Kagirinaki Tatakai, an early run and gun shooter developed by Hiroshi Ishikawa for the Sharp X1 computer and released by Enix in 1983. The Worms series, starting in 1995, also features terrain which can be completely obliterated.\nThe earliest first-person shooter example may be Ghen War, released in 1995 for the Sega Saturn, which featured a 3D terrain map generator that allows fully destructible environments. However, the trend to make more and more items and environmental features destroyable by the player hearkens back to the explosive barrels in Doom (1993). Games like Blood II: The Chosen (1998) also featured large numbers of destroyable objects; in that game a room filled with objects could be turned into an empty room filled only with debris.\n\n\n== See also ==\nDeformable body\nDynamic terrain\nTerrain rendering\n\n\n== References ==",
      "url": "https://en.wikipedia.org/wiki/Destructible_environment",
      "topic": "Environment",
      "timestamp": "2025-11-14T00:22:04.898244",
      "type": "wikipedia_content"
    }
  ],
  "last_updated": "2025-11-14T00:38:40.764194"
}